<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>willsnell</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on willsnell</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 25 Jul 2024 12:19:22 +1200</lastBuildDate><atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Navigating Hyperspace</title>
      <link>http://localhost:1313/posts/hyperspace/</link>
      <pubDate>Thu, 25 Jul 2024 12:19:22 +1200</pubDate>
      
      <guid>http://localhost:1313/posts/hyperspace/</guid>
      <description>Why explore hyperspace? Hyperspace might seem exotic - and it is - but learning better ways to explore it can be both useful and (dare I say) fun.
Spaces with dimensionality higher than 3 or 4 might be outside of our lived experience, but that doesn&amp;rsquo;t mean they don&amp;rsquo;t exist, or that they can&amp;rsquo;t be useful. For example, hyperspaces frequently shows up in neural networks. By learning to explore hyperspace, we can try gain a better understanding of how they work.</description>
      <content>&lt;h1 id=&#34;why-explore-hyperspace&#34;&gt;Why explore hyperspace?&lt;/h1&gt;
&lt;p&gt;Hyperspace might seem exotic - and it is - but learning better ways to explore it can be both useful
and (dare I say) fun.&lt;/p&gt;
&lt;p&gt;Spaces with dimensionality higher than 3 or 4 might be outside of our lived experience, but
that doesn&amp;rsquo;t mean they don&amp;rsquo;t exist, or that they can&amp;rsquo;t be useful.
For example, hyperspaces frequently shows up in neural networks. By
learning to explore hyperspace, we can try gain a better understanding
of how they work.&lt;/p&gt;
&lt;p&gt;The motivating
example for this article comes from the sub-field of &lt;a href=&#34;https://developers.google.com/machine-learning/gan&#34;&gt;Generative Adversarial Networks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following portraits were generated by StyleGAN2 &lt;a href=&#34;https://github.com/NVlabs/stylegan2-ada-pytorch&#34;&gt;(Karras, et. al)&lt;/a&gt;:&lt;/p&gt;
&lt;hr&gt;
&lt;div style=&#34;display: flex; justify-content: space-around;&#34;&gt;
&lt;img src=&#34;near_origin_scale/lerp/0.jpg&#34;
alt=&#34;A painting of a woman, looking to the left&#34; style=&#34;box-sizing: border-box; width: calc(min(45%, 400px))&#34;/&gt;
&lt;img src=&#34;near_origin_scale/lerp/1.jpg&#34;
alt=&#34;A painting of a man, looking to the right&#34; style=&#34;box-sizing: border-box; width: calc(min(45%, 400px))&#34;/&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;To dramatically oversimplify, these neural networks take an input vector,
do some transformations on it, and produce an image. The input vector
is typically random noise, and the vector is often quite long - hundreds or thousands of elements long.&lt;/p&gt;
&lt;p&gt;These vectors make up the &lt;strong&gt;latent space&lt;/strong&gt; of the model. Because these
vectors are long, the latent space is high dimensional.
Manipulating the outputs of these models relies on us
being able to chart paths through their latent space.&lt;/p&gt;
&lt;p&gt;For example, if we want to smoothly blend from the first painting above to the second,
we need a way to traverse from the vector representing one image
to the vector representing the other.&lt;/p&gt;
&lt;h2 id=&#34;the-obvious-answer-is-wrong&#34;&gt;The obvious answer (is wrong)&lt;/h2&gt;
&lt;p&gt;To get from point A to point B, the obvious answer is to go in as straight a
line as possible. The simplest answer here is also the shortest.
Indeed, when working with latent spaces, going in a straight line does generally work,
with varying degrees of success. This is known as linear interpolation (lerp), and
would be written something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lerp&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start_vec)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;script src=&#34;https://cdn.plot.ly/plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;observer.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;math_lib.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;charts.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;vector_math.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;interp.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;In 3D-space, this looks like:&lt;/p&gt;
&lt;div id=&#34;3d_lerp&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const demo_start = [-0.5012528962436638, -0.9103151253007502, 0.5048315888047492];
const demo_stop = [0.905189016060779, -0.28742159270964684, -0.0913802767988876];
const vec_space_1000 = rand(10_000, 1000);
spawn_plot(&#34;3d_lerp&#34;, (div_id) =&gt; {
    let redraw_3d_lerp = get_interpolated_chart(vec_space_1000, div_id, lerp, demo_start, demo_stop,
                                          identity_transform);
    redraw_3d_lerp(3, 0, identity_transform);
}
);
&lt;/script&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Most of the plots on this page are interactive! Have a play!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While exploring this topic, I came across a &lt;a href=&#34;https://github.com/soumith/dcgan.torch/issues/14&#34;&gt;befuddling thread&lt;/a&gt;
which suggested that the best path was &lt;strong&gt;not, in fact, a straight line&lt;/strong&gt;. Rather, a function called
&lt;code&gt;slerp&lt;/code&gt;, or &amp;ldquo;spherical linear interpolation&amp;rdquo;, was suggested. This has the rather complicated
functional form:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;slerp&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec), stop_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec)), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Revert to linear interpolation if the two vectors are pi radians apart&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; fraction) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_vec &lt;span style=&#34;color:#75715e&#34;&gt;# L&amp;#39;Hopital&amp;#39;s rule/LERP&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fraction)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_vec
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Even more confusingly, when plotted in 3D space, this function gives a path that looks like
this:&lt;/p&gt;
&lt;div id=&#34;3d_slerp&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot(&#34;3d_slerp&#34;, (div_id) =&gt; {
let redraw_3d_slerp = get_interpolated_chart(vec_space_1000, div_id, slerp, demo_start, demo_stop,
                                          identity_transform);
redraw_3d_slerp(3, 0, identity_transform);
});
&lt;/script&gt;
&lt;p&gt;When thinking about what a &amp;ldquo;good&amp;rdquo; interpolation path might look like, a few
different ideas come to mind. We want it to be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Smooth&lt;/em&gt; - in my experience, jagged, jerky paths do not work well
for blending between two latent vectors.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Relatively short&lt;/em&gt;, since we care about capturing the changes
between two specific points, rather than going sightseeing
to irrelevant destinations&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Well-trodden&lt;/em&gt; - We&amp;rsquo;ve trained our neural net on a limited set of data.
If our interpolation takes us far outside anything the neural net
has ever seen, it&amp;rsquo;s unlikely to perform well.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looking at slerp, we can see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is &lt;em&gt;smooth&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;It doesn&amp;rsquo;t look particularly short. In fact, it&amp;rsquo;s much &lt;em&gt;longer&lt;/em&gt;
than our straight-line path.&lt;/li&gt;
&lt;li&gt;It doesn&amp;rsquo;t seem to stick particularly closely to the data we&amp;rsquo;ve
trained the network on. In fact, it sometimes goes &lt;strong&gt;outside
of our (-1, 1) domain&lt;/strong&gt; entirely!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In 2D and 3D space, linear interpolation simply doesn&amp;rsquo;t have the issues
that slerp does. &lt;strong&gt;Yet, slerp is consistently recommended.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Clearly, something about hyperspace behaves very non-intuitively!&lt;/p&gt;
&lt;p&gt;Strap in&amp;hellip; because it&amp;rsquo;s time to go exploring.&lt;/p&gt;
&lt;h1 id=&#34;windows-into-hyperspace&#34;&gt;Windows into Hyperspace&lt;/h1&gt;
&lt;p&gt;Let&amp;rsquo;s start with the concept of vectors.&lt;/p&gt;
&lt;p&gt;A vector is just a collection of numbers,
arranged in a single column or row, like so:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{3} = \begin{bmatrix}
        1.9 \\
        4.7 \\
        -3.1 \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;An n-dimensional vector is \(n\) items long:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{n} = \begin{bmatrix}
        x_{1} \\
        \vdots \\
        x_{n}
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;Vectors can be used to represent all sorts of things, but here we&amp;rsquo;re
going to use them to represent &lt;em&gt;cartesian coordinates&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;1-space&#34;&gt;1-space&lt;/h2&gt;
&lt;p&gt;If we had only 1 spatial dimension to play with, we could represent every
possible position with a 1-dimensional vector:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{1} = \begin{bmatrix}
        x_{1} \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;If we were to fill our space with lots of random points, uniformly
distributed from -1 to 1, it would look like this:&lt;/p&gt;
&lt;div id=&#34;1d_space_chart&#34; class=&#34;plotly&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const vec_space = rand(1000, 1);
spawn_plot(&#34;1d_space_chart&#34;, (div_id) =&gt; {
    get_2d_chart(vec_space, div_id, 0, [&#34;&#34;, &#34;&#34;, &#34;&#34;]);
});
&lt;/script&gt;
&lt;p&gt;Hopefully, this result is pretty unsurprising.&lt;/p&gt;
&lt;h2 id=&#34;2-space&#34;&gt;2-space&lt;/h2&gt;
&lt;p&gt;If we extend our vectors into two dimensions, and perform the same exercise, we&amp;rsquo;ll get
something like this:&lt;/p&gt;
&lt;div id=&#34;2d_space_chart&#34; class=&#34;plotly&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const vec_space_2 = rand(1_000, 2);
spawn_plot(&#34;2d_space_chart&#34;, (div_id) =&gt; {
    get_2d_chart(vec_space_2, div_id, 0, [&#34;&#34;, &#34;&#34;, &#34;&#34;]);
});
&lt;/script&gt;
&lt;p&gt;For every possible location in this space, we can
define an exact point through something like:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{2} = \begin{bmatrix}
        -0.85 \\
        0.24 \\
    \end{bmatrix}
\end{align}
\]
&lt;h2 id=&#34;3-space&#34;&gt;3-space&lt;/h2&gt;
&lt;p&gt;Extending up to 3D is quite straightforward, where we
now have 3-long vectors like this:&lt;/p&gt;
&lt;div id=&#34;3_vec&#34;&gt;
\[
\begin{align}
    \vec{v}_{3} = \begin{bmatrix}
        0.26 \\
        -0.88 \\
        -0.9 \\
    \end{bmatrix}
\end{align}
\]
&lt;/div&gt;
&lt;p&gt;Let&amp;rsquo;s again scatter some points uniformly between -1 and 1,
this time in 3 dimensions:&lt;/p&gt;
&lt;div id=&#34;3d_space_chart&#34; style=&#34;width: 100%;&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const vec_space_3 = rand(10_000, 3);
spawn_plot(&#34;3d_space_chart&#34;, (div_id) =&gt; {
    get_3d_chart(vec_space_3, div_id, 0, [&#34;&#34;, &#34;&#34;, &#34;&#34;]);
});
&lt;/script&gt;
&lt;p&gt;We&amp;rsquo;re very used to looking at 3D space through these kinds of visualizations, where
our brain can reconstruct a series of 2D images into a 3D representation.&lt;/p&gt;
&lt;h2 id=&#34;flattening-space&#34;&gt;Flattening Space&lt;/h2&gt;
&lt;p&gt;What if we wanted to look at &lt;strong&gt;this 4D&lt;/strong&gt; vector
inside its vector space:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{4} = \begin{bmatrix}
        0.93  \\
        -0.43 \\
        0.67  \\
        0.12  \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;We could &lt;em&gt;try&lt;/em&gt; using time as an extra dimension,
but we&amp;rsquo;ve already run out of spatial dimensions.&lt;/p&gt;
&lt;p&gt;Of course, we want to go far beyond a mere &lt;em&gt;four&lt;/em&gt; dimensions.
Even if we used time, how would we visualize something like this?&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{1000} = \begin{bmatrix}
        x_{1}      \\
        x_{2}      \\
        \vdots     \\
        x_{1000}   \\
    \end{bmatrix}
\end{align}
\]
&lt;h2 id=&#34;projecting&#34;&gt;Projecting&lt;/h2&gt;
&lt;p&gt;To glimpse higher dimensions, we&amp;rsquo;re
necessarily going to need to make compromises.
With &lt;em&gt;up to&lt;/em&gt; 3 dimensions to play with, any given
viewport will need to choose what information to show and what to hide.&lt;/p&gt;
&lt;p&gt;A natural way to project higher dimensions is to just take
the first \(n\) dimensions we can display, and ignore the rest.&lt;/p&gt;
&lt;p&gt;We can visualize what this looks like by creating a vector space
in three dimensions, and visualizing it with two.&lt;/p&gt;
&lt;p&gt;If we want to display the vector:&lt;/p&gt;
\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        0.21   \\
        -0.85  \\
        -0.32  \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;We can display the first 2 elements, i.e.:&lt;/p&gt;
\[
\begin{align}
    \vec{c}_2 = \begin{bmatrix}
        0.21  \\
        -0.85 \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;Where \(\vec{c}_2\) represents a &lt;strong&gt;cartesian projection&lt;/strong&gt;
down to 2 dimensions.&lt;/p&gt;
&lt;p&gt;We can write this as an equation:&lt;/p&gt;
\[
    \vec{v}_3 \mapsto \vec{c}_2
\]
&lt;p&gt;Where the arrow \(\mapsto\) means
&amp;ldquo;maps to&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Visualized, it looks like so:&lt;/p&gt;
&lt;div id=&#34;3d_into_2d&#34; style=&#34;width: 100%;&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot(&#34;3d_into_2d&#34;, (div_id) =&gt; {
    get_2d_3d_chart(vec_space_3, div_id);
});
&lt;/script&gt;
&lt;p&gt;We can pick any 2 elements to display, of course.
Representing our 3-space in 2 dimensions could
be done equally validly by picking two different
elements, such as the last element \(x_{3}\)
and the second element \(x_{2}\):&lt;/p&gt;
\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        -0.32 \\
        -0.85 \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;What does our 2D projection tell us about the 3D space?
Well, we effectively get the same view as if we rotated
our 3D view until we were just looking at one face.&lt;/p&gt;
&lt;p&gt;If we&amp;rsquo;re plotting, say, \(x_{1}\) and \(x_{2}\),
we get a perfect understanding of how our points are
distributed in those two dimensions.&lt;/p&gt;
&lt;p&gt;Should we want to know
what portion of points have \(x_{1}\) &amp;gt; 0
and \(x_{2}\) &amp;lt; 0, we can
look at the 2D chart and easily see the answer is
~25%.&lt;/p&gt;
&lt;p&gt;However, we get absolutely no information about the
rest of our vector. It wouldn&amp;rsquo;t matter if we were
plotting a vector of length 3 or a vector of length
3000 - from this viewpoint, they all look the same.&lt;/p&gt;
&lt;h2 id=&#34;different-projections&#34;&gt;Different Projections&lt;/h2&gt;
&lt;p&gt;So far, we&amp;rsquo;ve been exploring space with &lt;em&gt;cartesian&lt;/em&gt; coordinates.&lt;/p&gt;
&lt;p&gt;Without completely justifying it, I&amp;rsquo;m going to introduce
a completely different coordinate system - &lt;a href=&#34;https://en.wikipedia.org/wiki/Spherical_coordinate_system&#34;&gt;spherical coordinates&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most people are used to &amp;ldquo;cartesian&amp;rdquo; coordinates. In the following
image, it seems natural to define the position of the red cross based
on two distances, which we typically call x and y.
&lt;img src=&#34;xy.svg&#34;&gt;&lt;/p&gt;
&lt;p&gt;We could represent this point as a vector:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_2 = \begin{bmatrix}
        x \\
        y \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;In higher dimensions, we can add more directions, provided they are
perpendicular to all the other directions. Hence, for 3d, we might
use (x, y, z).&lt;/p&gt;
&lt;p&gt;In a spherical coordinate system, however, a point in space is defined
not by \(n\) orthogonal coordinates (e.g. x, y, and z), but rather
as a &lt;em&gt;radial distance&lt;/em&gt; \(r\), and then a series of angles.&lt;/p&gt;
&lt;p&gt;To fully describe any point in 2D-space, we need two coordinates.
Since we already have one (the distance from the origin \(r\)),
we need one more. Hence, a 2D spherical coordinate system would have
one angle, \(\theta_1\).&lt;/p&gt;
&lt;img src=&#34;radial.svg&#34;&gt;
&lt;p&gt;We can also represent this point as a vector:&lt;/p&gt;
\[
\begin{align}
    \vec{s}_2 = \begin{bmatrix}
        r          \\
        \theta_{1} \\
    \end{bmatrix}
\end{align}
\]
&lt;p&gt;Notice that &lt;strong&gt;both \(\vec{v}_2\) and \(\vec{s}_2\)&lt;/strong&gt; refer to
the exact same point in space. The actual numbers inside the vectors,
and the coordinate &lt;strong&gt;system&lt;/strong&gt; used are very different, but the point
in space is the same.&lt;/p&gt;
&lt;h3 id=&#34;adding-dimensions&#34;&gt;Adding Dimensions&lt;/h3&gt;
&lt;p&gt;In 3-space, we need a third coordinate. For cartesian coordinates, we add z
to our existing x and y. For spherical coordinates, we add
another angle \(\theta_2\).&lt;/p&gt;
&lt;p&gt;These two vectors represent the same position:&lt;/p&gt;
\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        0.54  \\
        -0.87 \\
        0.26  \\
    \end{bmatrix}_{[x,y,z]}
    = \vec{s} = \begin{bmatrix}
        1.06  \\
        -1.02 \\
        1.32  \\
    \end{bmatrix}_{[r, \theta_1, \theta_2]}
\end{align}
\]
&lt;h3 id=&#34;why-bother-with-spherical-coordinates&#34;&gt;Why bother with spherical coordinates?&lt;/h3&gt;
&lt;p&gt;How does this help us? After all, you still
need an n-length vector to represent a point in n-space.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s interesting, however, is when you start looking at
higher dimensions. Since the length \(r\) takes into account
the entire vector, plotting the first 2 or 3 elements in the
spherical vector gives us a different view on higher dimensions.&lt;/p&gt;
&lt;p&gt;Importantly, &lt;strong&gt;we always keep the magnitude of the full vector&lt;/strong&gt;
when using spherical coordinates.&lt;/p&gt;
&lt;p&gt;We then get to select 1 angle (for a 2D plot) or 2 angles (for
a 3D plot). These angles represent the relative positioning
between &lt;strong&gt;some, but not all&lt;/strong&gt; elements of the vector.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://localhost:1313/posts/hyperspace/#projecting&#34;&gt;Earlier, we projected higher-dimensional space&lt;/a&gt; into 2D and 3D
cartesian plots. We got to pick 2 elements from our larger vector, and had to
throw away the rest.&lt;/p&gt;
&lt;p&gt;We have to do a similar thing in spherical coordinates. However, we &lt;em&gt;always&lt;/em&gt;
keep the magnitude. This means that we&amp;rsquo;re left with the ability to pick
one angle (for a 2d plot) or 2 angles (for a 3d plot) from our larger
vector.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Below, you can increase the dimensionality of the space being
visualized.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Before you do&lt;/strong&gt;, make a guess about what you think
will happen as the number of dimensions increases.&lt;/p&gt;
&lt;p&gt;Remember, we&amp;rsquo;re keeping the &lt;em&gt;vector magnitude&lt;/em&gt;, but
can only keep one angle (for the 2D plot) or 2
angles (for the 3D plot).&lt;/p&gt;
&lt;p&gt;How many dimensions do you think we can plot before
the spherical projection will start to look different
to the cartesian projection?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;spherical&#34; style=&#34;width: 100%;&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;spherical_vec&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;tooltip-1space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 1-space&lt;/p&gt;
&lt;p&gt;1-space is boring as ever&amp;hellip;&lt;/p&gt;
&lt;p&gt;Jump to the next space with the &amp;ldquo;Dimensions (+)&amp;rdquo; button.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-2space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 2-space&lt;/p&gt;
&lt;p&gt;In 2-space, both the 2D and the 3D plot display the same
thing. This is also the exact same view we would get if we were
using cartesian coordinates. Because any 2-length vector losslessly
describes this space, we can freely switch between them without issue.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-3space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: understanding the 2D and 3D plots at for a 3D space
is critical to understanding the rest of this article. Take the time
to try and wrap your head around the link between these two plots.&lt;/p&gt;
&lt;p&gt;// 3-space&lt;/p&gt;
&lt;p&gt;Our &lt;strong&gt;3D plot&lt;/strong&gt; still holds enough
dimensionality to perfectly represent our vector, and so our view is
identical to the cartesian plot we had earlier. That is,
our mapping \(\vec{v} \mapsto \vec{s}\) is lossless.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;2D plot&lt;/strong&gt;, however, is different. We&amp;rsquo;re fundamentally
losing some information when projecting from \(\vec{v}_3\) to \(\vec{s}_2\).
Notably, even though our points are randomly
distributed between -1 and 1, we are starting to see points shift outside
of that range.&lt;/p&gt;
&lt;p&gt;Remember that the distance from the origin (0, 0) in our 2D plot now
represents the absolute distance from the origin in &lt;strong&gt;n-space&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Looking at the 3D view of the cube, which points do you think
have a distance to
the origin (a &lt;em&gt;vector magnitude&lt;/em&gt;) greater than 1?&lt;/p&gt;
&lt;p&gt;Interestingly, a hole has started to appear in the centre of the plot.
Why do you think this is?&lt;/p&gt;
&lt;p&gt;What might you expect to see happen as we continue to increase the dimensionality
of our space?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-4space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 4-space&lt;/p&gt;
&lt;p&gt;This is the first space that cannot be fully represented by the
spatial dimensions we have at hand. If you&amp;rsquo;ve been watching the 2D
plot over the last few dimensionalities, you should be able to guess
what&amp;rsquo;s coming for our 3-space plot.&lt;/p&gt;
&lt;p&gt;This is also the first dimensionality where we get multiple 3D and 2D
plots to hop between. By pressing the &amp;ldquo;Elements (-)&amp;rdquo; or &amp;ldquo;Elements (+)&amp;rdquo;
buttons, we can move through the vector, choosing different elements
to act as the &amp;ldquo;direction&amp;rdquo; component of our spherical projection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-5space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 5-space and beyond&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll leave you be as you explore the next few dimensions.&lt;/p&gt;
&lt;p&gt;Have a play around, and try and build an intuition for
what these charts are telling you about the spaces.&lt;/p&gt;
&lt;p&gt;Remember, the &lt;strong&gt;Dimensions&lt;/strong&gt; buttons change the dimensionality
of the underlying vector space, and the &lt;strong&gt;Elements&lt;/strong&gt; buttons
change which elements of \(\vec{v}\) we&amp;rsquo;re using to calculate
\(\theta_1\) and \(\theta_2\).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;p&gt;You can also change the noise distribution to:
&lt;span&gt;&lt;button id=&#34;noise_gaussian&#34; style=&#34;display: block;&#34; onclick=&#34;
// change which button is displayed
document.getElementById(&#39;noise_uniform&#39;).style.display = &#39;block&#39;;
document.getElementById(&#39;noise_gaussian&#39;).style.display = &#39;none&#39;;
// redraw the last chart
selected_space = gaussian_space_1000;
redraw_proj(selected_space);
&#34;&gt;gaussian&lt;/button&gt;&lt;/span&gt;
&lt;span&gt;&lt;button id=&#34;noise_uniform&#34; style=&#34;display: none;&#34; onclick=&#34;
// change which button is displayed
document.getElementById(&#39;noise_gaussian&#39;).style.display = &#39;block&#39;;
document.getElementById(&#39;noise_uniform&#39;).style.display = &#39;none&#39;;
// redraw the last chart
let selected_space = vec_space_1000;
redraw_proj(selected_space);
&#34;&gt;uniform&lt;/button&gt;&lt;/span&gt;&lt;/p&gt;
&lt;script&gt;
let dims_with_text = [1, 2, 3, 4, 5];
let gaussian_space_1000 = randn(10000, 1000);
// keep the button and plots in sync through despawn/respawn
let selected_space = vec_space_1000;
function redraw_proj(vector_space) {
    document.getElementById(&#39;spherical&#39;).innerHTML = &#39;&#39;;
    document.getElementById(&#39;spherical_vec&#39;).innerHTML = &#39;&#39;;

    let redraw_spherical = get_projected_chart(vector_space, &#39;spherical&#39;, [&#34;&#34;, &#34;&#34;, &#34;&#34;], vecs_to_spherical);
    let callback = (dimensions, slice_offset) =&gt; {
        for (let dim of dims_with_text) {
            if (dim == dimensions) {
                document.getElementById(`tooltip-${dimensions}space`).style.display = &#34;block&#34;;
            } else if (dimensions &gt; dims_with_text[dims_with_text.length - 1]) {
                document.getElementById(`tooltip-${dims_with_text[dims_with_text.length - 1]}space`).style.display = &#34;block&#34;;
            } else {
                document.getElementById(`tooltip-${dim}space`).style.display = &#34;none&#34;;
            }
        }
        redraw_spherical(dimensions, slice_offset);
    }
    let widget = get_vector_widget(vector_space[0], &#39;spherical_vec&#39;, callback, 1);
}
spawn_plot(&#34;spherical&#34;, 
    // spawn
    (div_id) =&gt; {
        redraw_proj(selected_space);
    },
    // custom teardown
    (div_id) =&gt; {
        document.getElementById(&#39;spherical&#39;).innerHTML = &#39;&#39;;
        document.getElementById(&#39;spherical_vec&#39;).innerHTML = &#39;&#39;;
    });
&lt;/script&gt;
&lt;h2 id=&#34;whats-going-on&#34;&gt;What&amp;rsquo;s going on?&lt;/h2&gt;
&lt;p&gt;Our projection has shown us an unintuitive, but true, fact about
hyperspace - as the dimensionality increases, our points converge
to a hyperspherical shell. The radius of this shell scales with
the square root of our initial distribution&amp;rsquo;s variance, \(\sqrt{\sigma^2} = \sigma\),
and with the square root of our dimensionality, \(\sqrt{n}\).&lt;/p&gt;
&lt;p&gt;The exact formula for the radius varies depending on the type of
noise used (results for a &lt;a href=&#34;https://stats.stackexchange.com/questions/317095/expectation-of-square-root-of-sum-of-independent-squared-uniform-random-variable/317475#317475&#34;&gt;uniform distribution&lt;/a&gt;
and this &lt;a href=&#34;https://www.johndcook.com/blog/2011/09/01/multivariate-normal-shell/&#34;&gt;great post with results for normal distributions&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For both uniform and normal distributions, the hyperspherical
shell has a relatively constant thickness as the dimensionality
increases, leading to an increasingly shell-like distribution of points.&lt;/p&gt;
&lt;h3 id=&#34;what-does-this-mean&#34;&gt;What does this mean?&lt;/h3&gt;
&lt;p&gt;In lower dimension spaces (2D, 3D, etc.) the radius of our hypershell
is of the same order as the variance of the distribution. This means
that, in general, there isn&amp;rsquo;t much of a &amp;ldquo;hole&amp;rdquo; at the origin. However,
even in 3D (using our 2D plot), we start to see a gap open up near the
origin.&lt;/p&gt;
&lt;p&gt;Below are two expandable sections with different ways to interpret the
existence of a hyperspherical shell.&lt;/p&gt;
&lt;hr&gt;
&lt;details&gt;
    &lt;summary&gt;Geometric Interpretation&lt;/summary&gt;
&lt;p&gt;As explained in &lt;a href=&#34;https://www.johndcook.com/blog/2011/09/01/multivariate-normal-shell/&#34;&gt;John D. Cook&amp;rsquo;s post&lt;/a&gt;,
volume &lt;strong&gt;grows faster&lt;/strong&gt; in higher dimensions.
For our uniform distribution, our probability density is constant between its bounds of (-1, 1),
and so we can pretty much ignore it.&lt;/p&gt;
&lt;p&gt;Volume, however, is proportional to \(r^n\), where \(r\) is the distance
from the origin and \(n\) is the dimensionality of our space.
If \(n = 1000\) dimensions, the difference between a sphere of radius
0.999 and radius 1.000 is&lt;/p&gt;
\[
1.000^{1000} - 0.99^{1000} \approx 0.9999
\]
&lt;p&gt;In other words, &amp;gt;99% of all of our volume is contained in an outer shell, with
thickness of 1% the radius of our space.
The reason this collosal growth of volume with radius is not intuitive, is because
in 3D, the same calculation would give around 3% of the volume in the outermost
shell of our sphere:&lt;/p&gt;
\[
1.000^3 - 0.99^3 \approx 0.03 
\]
&lt;p&gt;Hence, even though our probability density function is constant in space,
when we go to higher dimensions, &lt;strong&gt;the amount of space near the origin is astronomically
low, and the amount at the outer perimeter is astronomically high.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Because so much space is so far out, our points will inevitably &amp;ldquo;cluster&amp;rdquo;
there.&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
    &lt;summary&gt;Statistical Interpretation&lt;/summary&gt;
&lt;p&gt;We can also think about this result statistically.&lt;/p&gt;
&lt;p&gt;All the elements in our vectors are independent and identically distributed.
The more elements we have, the more we will expect to see strong statistical
trends in the overall properties of our vector, even while individual
elements remain random.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s imagine we&amp;rsquo;re rolling a fair die, with sides labelled 0, 1, 2, 3, 4, and 5.
The expected value of our roll is 2.5, but we wouldn&amp;rsquo;t be surprised with a 0
or a 5.&lt;/p&gt;
&lt;p&gt;If we now roll 2 dice, make a graph, and plot our first roll on the x axis
and our second on the y axis, we again get a fairly even distribution.&lt;/p&gt;
&lt;p&gt;However, if we instead added the total of our two dice together, we
would be looking at a score between 0 and 10, with 5 being our expected value.
Already, our sum is starting to cluster, with 5 much more likely than
either 0 or 10.&lt;/p&gt;
&lt;p&gt;The more dice we roll:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The bigger we expect our total score to be, and&lt;/li&gt;
&lt;li&gt;The less and less likely we are to have a sum near 0 (or near the absolute
highest possible score of \(5 \times n\) rolls.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The same process, roughly, is going on with the magnitude of our vectors.
Instead of just summing our rolls, we&amp;rsquo;re squaring each roll, summing the
squares, and then taking the square root. These functions warp and
compress space a bit, but our intuition should generally still hold.&lt;/p&gt;
&lt;p&gt;We should intuitively expect that the more dice we roll,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The bigger our square-root sum of squares is, and&lt;/li&gt;
&lt;li&gt;The less and less likely we are to have a point near the origin
(or in the corners of our hypercube.)&lt;/li&gt;
&lt;/ol&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h1 id=&#34;tracing-lines-through-hyperspace&#34;&gt;Tracing Lines Through Hyperspace&lt;/h1&gt;
&lt;p&gt;Hopefully, you now have a solid grip on the spherical projections
we&amp;rsquo;ll be using from this point onwards. Remember, the distance
from a point to the origin in each plot represents the vector magnitude of
the &lt;em&gt;full vector&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Under this lens, what does linear interpolation (our &lt;code&gt;lerp&lt;/code&gt; function from earlier)
look like?&lt;/p&gt;
&lt;div id=&#34;spherical_lerp&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;lerp_vec&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot_with_vector(&#34;spherical_lerp&#34;, &#34;lerp_vec&#34;,
    (plot_id, vec_id) =&gt; {
        let redraw_chart = get_interpolated_chart(vec_space_1000, plot_id, lerp, vec_space_1000[0], vec_space_1000[1],
                                              vecs_to_spherical);
        let widget2 = get_vector_widget(vec_space_1000[0], vec_id, redraw_chart, 1);
        },
);
&lt;/script&gt;
&lt;p&gt;At low dimensions, lerp behaves exactly how we expect it to. But by the time we reach
around 20 dimensions, there&amp;rsquo;s a clear problem. Our linear path is well outside
the bounds of all the points in our vector space.&lt;/p&gt;
&lt;p&gt;As we increase the dimensionality of our space, the problem gets worse. At 1000 dimensions,
lerp spends almost the entirety of its path completely outside of the hyperspherical shell
that makes up the points in our vector space.&lt;/p&gt;
&lt;p&gt;In a machine learning context, this would mean that the interpolation is feeding in data
well outside the bounds of anything the model has been trained on.&lt;/p&gt;
&lt;h2 id=&#34;why-does-lerp-behave-like-this-in-higher-dimensional-spaces&#34;&gt;Why Does Lerp Behave Like This in Higher Dimensional Spaces?&lt;/h2&gt;
&lt;p&gt;To understand why &lt;code&gt;lerp&lt;/code&gt; diverges from our hyperspherical shell in higher
dimensions, we have to think about what it&amp;rsquo;s doing. For each element \(x_i\) in \(\vec{v}^1\)
and \(y_i\) in \(\vec{v}^2\), the output of &lt;code&gt;lerp&lt;/code&gt; can
never be larger than \(\max(x_i, y_i)\) and can never
be smaller than \(\min(x_i, y_i)\). Unless \(x_i\) and \(y_i\) both happen
to fall at exact opposite ends of their distributions, &lt;code&gt;lerp&lt;/code&gt; will necessarily
be operating in a smaller domain.&lt;/p&gt;
&lt;p&gt;Right at the midpoint, where &lt;code&gt;fraction=0.5&lt;/code&gt;, &lt;code&gt;lerp&lt;/code&gt; will give a vector that is
the average of \(vec{v}^1\) and \(\vec{v}^2\). The average is the point where
all values will be the most &amp;ldquo;smoothed out&amp;rdquo;. Because a particularly large element
is equally likely to appear in \(\vec{v}^1\) or \(\vec{v}^2\), averaging the two
vectors should give the point in the interpolation with minimum variance.
Because the distributions are centred about 0, minium variance corresponds to
minimum distance from the origin.&lt;/p&gt;
&lt;p&gt;If you want to try visualize this, change the &lt;code&gt;lerp&lt;/code&gt; visualization &lt;a href=&#34;http://localhost:1313/posts/hyperspace/#tracing-lines-through-hyperspace&#34;&gt;here&lt;/a&gt;
to have 3 dimensions. Imagine connecting any two points in the space with a
straight line. For every pair of points, the midpoint of a straight line
connecting them is closer to the origin than either point.&lt;/p&gt;
&lt;p&gt;Interestingly enough, the fact that lerp averages between the two vectors means that
the distribution of the vector becomes less and less uniform the closer to &lt;code&gt;fraction=0.5&lt;/code&gt;
we get. But that&amp;rsquo;s a topic for another post.&lt;/p&gt;
&lt;h1 id=&#34;slerp&#34;&gt;Slerp&lt;/h1&gt;
&lt;p&gt;Now that you&amp;rsquo;ve seen &lt;code&gt;lerp&lt;/code&gt; in a spherical projection, it&amp;rsquo;s only fair to
show &lt;code&gt;slerp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What do &lt;strong&gt;you&lt;/strong&gt; think will happen as the dimensionality increases?&lt;/p&gt;
&lt;p&gt;Was your intuition right?&lt;/p&gt;
&lt;div id=&#34;spherical_slerp&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;slerp_vec&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot_with_vector(&#34;spherical_slerp&#34;, &#34;slerp_vec&#34;,
    (plot_id, vec_id) =&gt; {
        let redraw_slerp = get_interpolated_chart(vec_space_1000, plot_id, slerp, vec_space_1000[0], vec_space_1000[1],
                                          vecs_to_spherical);
        let widget3 = get_vector_widget(vec_space_1000[0], vec_id, redraw_slerp, 1);
    }
);
&lt;/script&gt;
&lt;h1 id=&#34;what-is-slerp-actually-doing&#34;&gt;What Is Slerp Actually Doing?&lt;/h1&gt;
&lt;p&gt;Remember the definition of the slerp function &lt;a href=&#34;http://localhost:1313/posts/hyperspace/#the-obvious-answer-is-wrong&#34;&gt;from earlier?&lt;/a&gt;
Let&amp;rsquo;s break down where it came from, and what it&amp;rsquo;s actually doing.&lt;/p&gt;
&lt;p&gt;By looking at the projections above, you hopefully have a good intuition for
&lt;em&gt;what&lt;/em&gt; slerp is doing. The hints are in its name - spherical linear interpolation.
The function works by &lt;strong&gt;rotating&lt;/strong&gt; about the origin. Instead of translating from
point A to point B, slerp rotates between the two points, and scales the magnitude
of the vector while doing so.&lt;/p&gt;
&lt;p&gt;As our spherical coordinate projections &lt;a href=&#34;http://localhost:1313/posts/hyperspace/#why-bother-with-spherical-coordinates&#34;&gt;above showed,&lt;/a&gt;
higher dimensional spaces converge to a hyperspherical shell. To stay in this shell, we
want to orbit around the origin, keeping the vector magnitude (approximately) constant. This
is what slerp does, or tries to do.&lt;/p&gt;
&lt;p&gt;To actually get to the code, we have two parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Rotating in hyperspace.&lt;/li&gt;
&lt;li&gt;Scaling between the two vectors&amp;rsquo; magnitudes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Part 1) is provided to us by Shoemake &amp;amp; Davis, in the paper
&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/325334.325242&#34;&gt;Animating Rotation with Quaternion Curves&lt;/a&gt;.
In it, a rotation between two &lt;a href=&#34;https://www.youtube.com/watch?v=zjMuIxRvygQ&#34;&gt;quaternions&lt;/a&gt;,
\(q_1\) and \(q_2\), is given by the formula:&lt;/p&gt;
\[
    \text{Slerp}(q_1, q_2; u) = \frac{\sin( (1 - u)\omega)}{\sin \omega} q_1 + \frac{\sin u\omega}{\sin \omega} q_2
\]
&lt;p&gt;Where \(u\) is the &lt;code&gt;fraction&lt;/code&gt; parameter between 0 and 1, and \(q_1 \cdot q_2 = \cos \omega\).&lt;/p&gt;
&lt;p&gt;It turns out that this equation generalizes to n-dimensional vectors. Hence, we have part 1): a function to
rotate from one vector to another. I&amp;rsquo;m unclear how &amp;ldquo;optimal&amp;rdquo; this rotation is, since there are many ways to
rotate between two vectors in hyperspace. However, rotation - or &amp;ldquo;distance preserving linear maps&amp;rdquo; - are
very complicated and dimension-specific, so sticking with a general formula that works is a good plan.&lt;/p&gt;
&lt;p&gt;If we recall the definition of the dot product of two vectors:&lt;/p&gt;
\[
    a \cdot b = \vert \vert a \vert \vert  \space  \vert \vert b \vert \vert \cos \omega
\]
&lt;p&gt;Where \(\omega\) is the angle between the two vectors. We need \(\omega\) for our
slerp formula. So, we can rewrite the formula as:&lt;/p&gt;
\[
    \omega = \arccos( \frac{a}{\vert\vert a \vert \vert} \cdot \frac{b}{\vert \vert b \vert \vert} )
\]
&lt;p&gt;Another way of thinking about \(\frac{a}{\vert \vert a \vert \vert}\) is that is this is \(\hat{a}\)
(pronounced a-hat) - the unit (length 1) vector which represents only the direction components of a.&lt;/p&gt;
&lt;p&gt;This is indeed what the python slerp function does:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec), stop_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec)), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now that we have \(\omega\), we can plug it into Shoemake &amp;amp; Davis&amp;rsquo; Slerp, to get:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;start_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stop_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;new_direction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fraction)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_hat  &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_hat
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This &lt;strong&gt;isn&amp;rsquo;t&lt;/strong&gt; what the slerp code from &lt;a href=&#34;https://github.com/soumith/dcgan.torch/issues/14&#34;&gt;the DCGAN thread&lt;/a&gt;
does. Rather, this is the actual code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fraction)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_vec
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There&amp;rsquo;s a subtle difference - the vectors used in slerp - above titled \(q_1\) and \(q_2\) are not
normalized. And, rather than just calculating the angle, this line also does part 2), the vector
magntiude scaling.&lt;/p&gt;
&lt;p&gt;What this means is that &lt;code&gt;slerp&lt;/code&gt; is only actually using performing a pure rotation
when \(\vert \vert a \vert \vert \approx \vert \vert b \vert \vert\). In that case,
it&amp;rsquo;s effectively doing this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;slerp&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||a||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||b||, approx. ||a||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; start_mag &lt;span style=&#34;color:#75715e&#34;&gt;# a_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; stop_mag &lt;span style=&#34;color:#75715e&#34;&gt;# b_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_hat, stop_hat), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; fraction) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; start_mag &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; angle
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When the magnitudes of the two vectors are not particularly close,
such as in lower dimensions, this formula can give quite strange
results. This is exacerbated where the vectors are (almost) pi radians
apart from one another. (Since the vector spaces on this page are randomly
generated, if you refresh a few times, you&amp;rsquo;re bound to see some strange
slerp results in lower dimensions.)&lt;/p&gt;
&lt;p&gt;A slight improvement can be had by explicitly treating the interpolation between
the two vectors&amp;rsquo; magnitudes, and normalizing the vectors before performing the
slerp. This results in visually smoother paths,
and tends to overshoot the data bounds less when there are large changes in vector
magnitude.&lt;/p&gt;
&lt;p&gt;We treat the vector magnitude explicitly, and just linearly interpolate (&lt;code&gt;lerp&lt;/code&gt;) between
the magnitude of the first vector and the magnitude of the second vector. For the
purposes of this article, and at risk of being conceited, I&amp;rsquo;ll call this function &lt;code&gt;slerp2&lt;/code&gt;.
It is moderately more complicated than &lt;code&gt;slerp&lt;/code&gt;. The implementation here is formatted for
readability, not performance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;slerp2&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||a||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||b||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; start_mag &lt;span style=&#34;color:#75715e&#34;&gt;# a_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; stop_mag &lt;span style=&#34;color:#75715e&#34;&gt;# b_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_hat, stop_hat), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    magnitude &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_mag &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (start_mag &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; stop_mag) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; fraction &lt;span style=&#34;color:#75715e&#34;&gt;# lerp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; fraction) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; magnitude &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; angle
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;slerp2&#34;&gt;Slerp2&lt;/h1&gt;
&lt;div id=&#34;spherical_slerp2&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;slerp_vec2&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot_with_vector(&#34;spherical_slerp2&#34;, &#34;slerp_vec2&#34;, 
    (plot_id, vec_id) =&gt; {
        let redraw_slerp2 = get_interpolated_chart(vec_space_1000, plot_id, slerp2, vec_space_1000[0], vec_space_1000[1],
                                                  vecs_to_spherical);
        let widget3_2 = get_vector_widget(vec_space_1000[0], vec_id, redraw_slerp2, 1);
    }
);
&lt;/script&gt;
&lt;h1 id=&#34;using-it-in-practice&#34;&gt;Using it in practice&lt;/h1&gt;
&lt;p&gt;It&amp;rsquo;s all well and good talking abstractly of hyperspheres, but
you&amp;rsquo;re probably wondering: does &lt;code&gt;slerp&lt;/code&gt; actually perform better
in real-world applications?&lt;/p&gt;
&lt;p&gt;At the start of this post, I wrote about &lt;code&gt;StyleGAN&lt;/code&gt;. I picked it
because it is a more modern network building on the principals of
other GANs like &lt;a href=&#34;https://arxiv.org/abs/1511.06434v2&#34;&gt;DCGAN&lt;/a&gt;. DCGAN,
you might remember, is where the thread on &lt;code&gt;slerp&lt;/code&gt; originated that
kicked off this whole journey.&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t want to &lt;em&gt;just&lt;/em&gt; explore DCGAN, where there are &lt;a href=&#34;https://github.com/Newmu/dcgan_code/issues/12&#34;&gt;known dead zones
near the origin of the latent space&lt;/a&gt;.
Instead, I wanted to explore whether this is still the case with newer
networks.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;StyleGAN&lt;/code&gt; actually has &lt;strong&gt;two&lt;/strong&gt; latent spaces to explore:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Z-space, which is sampled from a normal distribution with 512 dimensions.&lt;/li&gt;
&lt;li&gt;W-space, which is internal to the network itself and is the result of
&lt;em&gt;learned&lt;/em&gt; transformations on the Z-space vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;rsquo;ll probably explore W-space in the future, but for now, Z-space
matches the kind of latent spaces we&amp;rsquo;ve been exploring in this article,
so that&amp;rsquo;s what we&amp;rsquo;ll explore.&lt;/p&gt;
&lt;h2 id=&#34;degenerate-case-1-almost-passing-through-the-origin&#34;&gt;Degenerate Case 1: (Almost) passing through the origin&lt;/h2&gt;
&lt;p&gt;I have a secret to confess: the two portraits I presented at the start of
this article were not exactly &lt;em&gt;randomly&lt;/em&gt; picked. The second portrait is
an (almost) exact opposite of the first - that is, the vector \(\vec{v}^2\)
used to generate the second image was calculated as:&lt;/p&gt;
\[
    \vec{v}^2 = - \vec{v}^1 + \epsilon
\]
&lt;p&gt;Where \(\epsilon\) was a very small offset necessary to prevent &lt;code&gt;slerp&lt;/code&gt; and &lt;code&gt;slerp2&lt;/code&gt; from blowing
up with a \(\frac{1}{\sin(0)}\) term. \(\vec{v}^1\) was a random vector
from the correct distribution.&lt;/p&gt;
&lt;p&gt;This means our &lt;code&gt;lerp&lt;/code&gt; from the first portrait to the second is a straight
line (nearly) through the origin.&lt;/p&gt;
&lt;p&gt;This is a degenerate case which should show whether vector magnitude actually
matters. Play around with the slider below to see the results for yourself.&lt;/p&gt;
&lt;div id=&#34;through_origin&#34;&gt;&lt;/div&gt;
&lt;script&gt;
let stylegan_space = randn(1000, 512);
let interp_points = [0.00, 0.14, 0.29, 0.43, 0.57, 0.71, 0.86, 1.00];
fetch(&#34;vecs.json&#34;)
    .then(response =&gt; response.json())
    .then(jvecs =&gt; {
    start_through_origin = jvecs.z;
    stop_through_origin = add(mult(jvecs.z, -1), 1e-4);
    spawn_plot(&#34;through_origin&#34;,
        (div_id) =&gt; {
            let redraw = get_multi_interp_chart(stylegan_space, div_id, {lerp: lerp, slerp: slerp, slerp2: slerp2}, start_through_origin, stop_through_origin, 
                                        &#34;./near_origin&#34;, interp_points,
                                        vecs_to_spherical);
        });
    });
&lt;/script&gt;
&lt;p&gt;You can see that the image generated by the &lt;code&gt;lerp&lt;/code&gt;-ed vector doesn&amp;rsquo;t meaningfully change
until passing the origin, where it immediately changes to the output image. This is interesting,
and might suggest that for StyleGAN2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vector magnitude is unimportant, in comparison to vector direction.&lt;/li&gt;
&lt;li&gt;The learned transformations between Z-space and W-space might discard
magnitude information, or else are only sensitive to magnitude within the
tight range for which all input data (in Z-space) was provided.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;degenerate-case-2-almost-passing-through-the-origin-with-elevation-changes&#34;&gt;Degenerate Case 2: (Almost) passing through the origin with elevation changes&lt;/h2&gt;
&lt;p&gt;This second degenerate case is similar to the first, excepting a slight
change in vector magnitude between \(\vec{v}^1\) and \(\vec{v}^2\). In this case,
I multiplied \(\vec{v}^1\) by 0.9999 and \(\vec{v}^2\) by 1.0001. This was to
see if vector magnitude had an impact on the images produced, and whether
&lt;code&gt;slerp&lt;/code&gt; or &lt;code&gt;slerp2&lt;/code&gt; handled it better.&lt;/p&gt;
&lt;div id=&#34;through_origin_with_scale&#34;&gt;&lt;/div&gt;
&lt;script&gt;
fetch(&#34;vecs.json&#34;)
    .then(response =&gt; response.json())
    .then(jvecs =&gt; {
    start_scale = mult(jvecs.z, 0.9999);
    stop_scale = add(mult(jvecs.z, -1.0001), 1e-4);
    spawn_plot(&#34;through_origin_with_scale&#34;,
        (div_id) =&gt; {
            let redraw_scale = get_multi_interp_chart(stylegan_space, div_id, {lerp: lerp, slerp: slerp, slerp2: slerp2}, 
                                                start_scale, stop_scale, &#34;./near_origin_scale&#34;, 
                                                interp_points, vecs_to_spherical);
        });
    });
&lt;/script&gt;
&lt;p&gt;This case exacerbates an odd quirk of &lt;code&gt;slerp&lt;/code&gt; - when vector magnitudes are relatively
different (and when angles are relatively aligned), the interpolation can produce
truly bizarre paths. This is a little unfair on regular &lt;code&gt;slerp&lt;/code&gt;, though, since this case
will statistically never be seen when interpolating between two random vectors.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;slerp2&lt;/code&gt; performs best here, presumably because it most evenly sweeps between angles
from start to finish. But all three interpolators are producing meaningful results.
This is really a testament to the robustness of StyleGAN.&lt;/p&gt;
&lt;h2 id=&#34;comparing-the-lerps-with-real-vectors&#34;&gt;Comparing the &amp;rsquo;lerps with real vectors&lt;/h2&gt;
&lt;p&gt;It&amp;rsquo;s only fair to compare interpolation between two actually random vectors,
and that&amp;rsquo;s exactly what&amp;rsquo;s going on here.&lt;/p&gt;
&lt;div id=&#34;random&#34;&gt;&lt;/div&gt;
&lt;script&gt;
fetch(&#34;vecs.json&#34;)
    .then(response =&gt; response.json())
    .then(jvecs =&gt; {
    start_scale = jvecs.random_start;
    stop_scale = jvecs.random_stop;
    spawn_plot(&#34;random&#34;, 
        (div_id) =&gt; {
            let redraw_scale = get_multi_interp_chart(stylegan_space, div_id, 
                                                        {lerp: lerp, slerp: slerp, slerp2: slerp2}, 
                                                        start_scale, stop_scale, &#34;./random&#34;, 
                                                        interp_points, vecs_to_spherical);
        }
    );
    }
);
&lt;/script&gt;
&lt;p&gt;You&amp;rsquo;ll note that even though &lt;code&gt;lerp&lt;/code&gt; shows its characteristically out-of-family
vector magnitude, the results produced by all 3 interpolators are functionally
identical.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;As &lt;a href=&#34;https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf&#34;&gt;Pedro Domingos famously put it&lt;/a&gt;,
&lt;em&gt;Intuition Fails in High Dimensions&lt;/em&gt;. Before setting out on this journey, I didn&amp;rsquo;t expect
higher dimensional vectors to form hyperspherical shells, nor did I expect spherical interpolation
to be a better way of interpolating between two such vectors.&lt;/p&gt;
&lt;p&gt;When all is said and done, though, the importance of how one navigates in hyperspace may
not matter, and certainly depends on the actual system being studied.&lt;/p&gt;
&lt;p&gt;Sometimes, the best solution really is the simplest one.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Why does my GAN do that?</title>
      <link>http://localhost:1313/posts/gans/</link>
      <pubDate>Mon, 22 Jul 2024 09:25:17 +1200</pubDate>
      
      <guid>http://localhost:1313/posts/gans/</guid>
      <description>What are GANs? Much ink has already been spilled on the class of machine learning networks called GANs, or Generative Adversarial Networks, so I will only summarize it here.
If you&amp;rsquo;re interested in learning more, this short course is a great resource.
Although replaced in contemporary applications by diffusion models for tasks like image generation, GANs provide a unique opportunity to study the interplay of two tightly-coupled systems, each seeking a different goal.</description>
      <content>&lt;h2 id=&#34;what-are-gans&#34;&gt;What are GANs?&lt;/h2&gt;
&lt;p&gt;Much ink has already been spilled on the class of machine learning networks called
GANs, or Generative Adversarial Networks, so I will only summarize it here.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re interested in learning more, &lt;a href=&#34;https://developers.google.com/machine-learning/gan/gan_structure&#34;&gt;this short course is a great resource.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Although replaced in contemporary applications by diffusion models for
tasks like image generation, GANs provide a unique opportunity
to study the interplay of two tightly-coupled systems, each seeking a
different goal.&lt;/p&gt;
&lt;p&gt;GANs consist of two distinct networks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a generator, which tries to generate new, convincingly realistic content, and&lt;/li&gt;
&lt;li&gt;a discriminator, which tries to tell real content from fake.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generally, during training, the generator is allowed to back-propagate gradients
all the way through both the discriminator (as it assesses the generated images)
and the generator itself. Conversely, the discriminator has no special knowledge
of the inner workings of the generator.
Hence, if a generator&amp;rsquo;s output fails to fool the discriminator, the
generator gets immediate feedback about what parts of the image tipped the discriminator off
to the fakery. But if a discriminator is repeatedly hoodwinked, it can only look inward to
understand how to improve.&lt;/p&gt;
&lt;p&gt;Although GANs can technically generate any type of content, this post will focus on the generation
of images.&lt;/p&gt;
&lt;h2 id=&#34;visualizing-dcgans&#34;&gt;Visualizing DCGANs&lt;/h2&gt;
&lt;p&gt;I particularly like using visualisation to get a deeper grip on a complex system
I am working with, and Deep Convolutional GANs (&lt;a href=&#34;https://arxiv.org/pdf/1511.06434&#34;&gt;as introduced in Radford, Metz &amp;amp; Chintala&lt;/a&gt;)
offered the perfect opportunity for some interesting visualisations.&lt;/p&gt;

  &lt;figure class=&#34;left&#34; &gt;
    &lt;img src=&#34;dcgan_gen_architecture.png&#34;   /&gt;
    
      &lt;figcaption class=&#34;center&#34; &gt;The DCGAN architecture (Radford, Metz &amp; Chintala), specifically the generator, with a 100-tall vector being processed through convolutional blocks that gradually decrease in feature depth and increase in resolution, until being projected to a 64 x 64 pixel RGB image.&lt;/figcaption&gt;
    
  &lt;/figure&gt;


&lt;p&gt;DCGANs use ordinary 2-dimensional convolutions in the discriminator to repeatedly downsample the image, building up
more and more internal features as the spatial resolution decreases.
In this way, they a variant of a typical convolutional image classifier.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The architecture presented in the DCGAN paper omits residual/skip-connections, à la &lt;a href=&#34;https://arxiv.org/pdf/1512.03385&#34;&gt;ResNet&lt;/a&gt;.
However, the two networks were introduced at similar times, and so the DCGAN&amp;rsquo;s authors probably didn&amp;rsquo;t shun them on purpose.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The generator does effectively the same thing, but in reverse, taking a large (in this case 100-long)
vector of random noise, and up-projecting it via transposed convolutions to gradually increase the
image resolution while decreasing the depth of the feature dimension.&lt;/p&gt;
&lt;p&gt;Because this network processes images, the very
first layer of the discriminator and the very last layer of the generator
should produce kernels that take in/out image data directly.&lt;/p&gt;
&lt;p&gt;For a (4x4 kernel) convolutional
layer that takes in an RGB image and produces a 128-feature output, this comes out to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;128 individual kernels (1 for each feature in the output layer),&lt;/li&gt;
&lt;li&gt;of depth 3 (i.e. each kernel has different weights for how much it activates
on a red, green, or blue pixel)&lt;/li&gt;
&lt;li&gt;of size 4 x 4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because each kernel has a depth of 3, we can visualize its weights using RGB images. In essence,
we get 128 x (4 high x 4 wide) images, where a bright red pixel indicates a part of the kernel
that activates strongly on red pixels, but not on green or blue, and a black pixel indicates no
activation for any input colour.&lt;/p&gt;
&lt;p&gt;We can use this process in reverse to visualize the generator&amp;rsquo;s &lt;strong&gt;output&lt;/strong&gt; kernels, where a 128-feature
space is projected up into an RGB image by transpose convolutions (effectively, but not quite, a convolution in reverse.)
The generator&amp;rsquo;s kernels are the different brushes with which the network paints the output image. Just like an artist might
need brushes of different sizes and shapes to effectively draw broad strokes and details, so the network might be expected
to need to specialize into different output kernels.&lt;/p&gt;
&lt;p&gt;At least, that&amp;rsquo;s my intuition for what would be expected to appear. In image classifiers (read: the discriminator),
the input kernels are often visualized in this way.&lt;/p&gt;
&lt;p&gt;For example, this image shows (centre) the kernels of a ResNet as visualized by &lt;a href=&#34;https://www.researchgate.net/publication/321192231&#34;&gt;Jiang, et. al&lt;/a&gt;:
&lt;img alt=&#34;Resnet in Jiang, et. al&#34; src=&#34;https://www.researchgate.net/publication/321192231/figure/fig4/AS:963217320841220@1606660313749/Visualization-of-first-layer-convolution-kernels-and-feature-maps-for-the-CS-ResCNN.gif&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;hypothesis-1&#34;&gt;Hypothesis 1&lt;/h2&gt;
&lt;p&gt;Before running the experiment, I expected that the discriminator would
develop clearly identifiable features in its kernels, such as
alternating black/white lines in various orientations (useful for edge-detection,) potentially filters
of one main colour, etc.&lt;/p&gt;
&lt;p&gt;I suspected the generator would be similar, but was less confident in this. After all, the kernel
visualizations I had seen, to date, were all of classifiers/discriminators, which serve a different
purpose to the generator I was going to train.&lt;/p&gt;
&lt;p&gt;What I saw, however, was much more surprising.&lt;/p&gt;
&lt;h2 id=&#34;exploring-my-dcgan&#34;&gt;Exploring my DCGAN&lt;/h2&gt;
&lt;p&gt;I started with a DCGAN with feature layers of depth [128, 256, 512], kernel size (4 x 4), and which took in an 64x64 RGB image.
The generator had an input vector of size 100, and was trained on normally distributed random noise.&lt;/p&gt;
&lt;p&gt;Training on the &lt;a href=&#34;https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html&#34;&gt;CelebA&lt;/a&gt; dataset, I used a batch-size of 8, using PyTorch
with an Adam optimizer using default settings for both the generator and the discriminator.&lt;/p&gt;
&lt;p&gt;The results from this first run are presented below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: I&amp;rsquo;ve used a non-linear
time-step in the video since the model should change less and less as it gets further
and further through its training.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;http://localhost:1313/posts/gans/gan_full.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;http://localhost:1313/posts/gans/gan_full.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;&lt;em&gt;Training a [128, 256, 512] feature DCGAN on CelebA for 3 epochs.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;These results were very surprising -
essentially the exact opposite of what I expected to see.
While I had suspected the generator kernels might be inscrutable, many of
them instead appeared to have an identifiable function.&lt;/p&gt;
&lt;p&gt;On the other hand, the discriminator kernels appeared to not change at all
from their initialisation. Although I suspected an issue with the code,
further investigation showed the discriminator&amp;rsquo;s kernels were, in fact, changing
throughout the run - just not enough to be discernible.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The values in the input kernels to the discriminator do change, slightly.
In the visualization, the layer becomes noticeably less saturated from start to finish, even though
the absolute values of the layer weights do not change substantially. Since I normalize
each frame by the max and min pixel values, this suggests to me that a few pixels are
&amp;lsquo;going hot&amp;rsquo;, but that
they are not doing so in a recognisable pattern.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hypothesis-2&#34;&gt;Hypothesis 2&lt;/h2&gt;
&lt;p&gt;My hypothesis, based on the above results, is as follows:&lt;/p&gt;
&lt;p&gt;Assumptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The capacity of a network to learn information during training should be correlated to
the size of the network.&lt;/li&gt;
&lt;li&gt;A layer retaining its initial values, or something very close to them, suggests that
the exact distribution of these layers is unimportant to the network.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Based on these (admittedly unproven) assumptions, I would make a few predictions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a layer is unimportant to the network, the network is probably over-sized for the task it is being
trained on&lt;/li&gt;
&lt;li&gt;Therefore, a smaller network (with its initial layer decreased in size) should be able to do equally well
on the task.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Doing equally well on the task&amp;rdquo;, in this context, is not strictly what the discriminator is evaluated on (i.e. its ability
to distinguish real from fake images), but rather is the quality of images produced after the GAN is fully trained.&lt;/li&gt;
&lt;li&gt;A well sized discriminator will show specialization in its input kernels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Boiling this down, I suspected that decreasing the number of input kernels of the discriminator (leaving the generator untouched)
would have little to no impact on the quality of images produced after training. I also suspected the combined network would
work equally well up to the point where the discriminator&amp;rsquo;s input kernels showed strong specialization (i.e. something similar to
the generator&amp;rsquo;s output kernels.)&lt;/p&gt;
&lt;h2 id=&#34;testing-hypothesis-2&#34;&gt;Testing Hypothesis 2&lt;/h2&gt;
&lt;p&gt;The obvious test was to decrease the number of input kernels for the discriminator
(i.e. the first-layer feature depth) from 128 to 64, and see what happens.&lt;/p&gt;
&lt;p&gt;Even though GANs are notoriously unstable during training, this change didn&amp;rsquo;t cause the network to diverge.
This suggests to me that the discriminator might have an
easier job to do than the generator, and so the smaller network was not immediately defeated
by its adversary.&lt;/p&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;http://localhost:1313/posts/gans/first_layer_64.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;http://localhost:1313/posts/gans/first_layer_64.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;There are some interesting takeaways from these results:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The output kernels from the generator look very similar to those from the previous
model. This suggests these kernels represent features useful to the generator,
regardless of the exact distribution of features in the hidden layers.&lt;/li&gt;
&lt;li&gt;The discriminator&amp;rsquo;s first layer still looks remarkably random. Despite being half as big,
the fully trained layer still looks like a desaturated version of the starting layer. At
least one recognisable feature seems to have appeared, though, in the 3rd column, 1st row.&lt;/li&gt;
&lt;li&gt;The image quality produced by the fully trained generator looks noticeably worse than for
the previous network. Although broad facial features are still present, the images qualitatively
look desaturated and hazy.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These findings suggest that although the input kernel&amp;rsquo;s exact weights may not be important, it is important
for the discriminator to have access to lots of them. Even if the feature representation inside the model
is ultimately fed by a series of random convolutions, having that feature depth seems to give the discriminator
more tools with which to sniff out fraudulent images. Consequently, a smaller number of input kernels lets the
generator get away with worse images.&lt;/p&gt;
&lt;h2 id=&#34;putting-the-hypothesis-properly-to-bed&#34;&gt;Putting the Hypothesis Properly to Bed&lt;/h2&gt;
&lt;p&gt;To check that these findings hold, I ran 3 more models with smaller and smaller input kernels. In particular,
the number of input features to the discriminator were decreased to 32, 16, and then 8. Mainly, I wanted to see
if the discriminator would eventually need to start specializing these kernel weights, even if it didn&amp;rsquo;t want to.&lt;/p&gt;
&lt;h3 id=&#34;32-input-kernels&#34;&gt;32 Input Kernels&lt;/h3&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;http://localhost:1313/posts/gans/first_layer_32.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;http://localhost:1313/posts/gans/first_layer_32.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;The 32 input-kernel network follows the same trend as the 64 input-kernel model: increasingly hazy, desaturated images.&lt;/p&gt;
&lt;p&gt;Two interesting notes, though:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Even as the image quality is degraded, the quality of the facial features looks pretty similar.&lt;/li&gt;
&lt;li&gt;More egregious structured artifacts are beginning to appear. In the lower left of this image, for example,
you can see a clear checker-boarding pattern in the background. Such patterns are commonly produced by
this network.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt=&#34;Blocky, repeating artifacts visible in the lower-left-corner&#34; src=&#34;http://localhost:1313/posts/gans/artefacts.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Together, these findings suggest to me that deeper layers of the discriminator
are still learning a good representation of facial features. However, the constrained
first layer has hindered the ability of the discriminator to notice and penalize noise and
overall &amp;ldquo;image-quality&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;I imagine each decrease in input kernels as the discriminator looking through an increasingly blurry
or perhaps tinted lens at the image, able to make out broad strokes but missing areas of high spatial frequency,
and seeing an increasingly desaturated version of the world.
The analogy isn&amp;rsquo;t quite right, since the spatial dimensions the network receives are unchanged, but it&amp;rsquo;s a start.&lt;/p&gt;
&lt;h3 id=&#34;the-edge-of-functionality---8-input-kernels&#34;&gt;The Edge of Functionality - 8 Input Kernels&lt;/h3&gt;
&lt;p&gt;During training, the 16-kernel GAN diverged, meaning the last model left to explore has 8 input kernels.&lt;/p&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;http://localhost:1313/posts/gans/first_layer_8.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;http://localhost:1313/posts/gans/first_layer_8.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;Finally, we see clear changes from the input kernels at the start to those at the end. However, this is
not enough to save the network, and the fully trained GAN produces images with little colour saturation,
degraded facial features, little separation between background and foreground, and most obviously, serious
checker-boarding artifacts across every part of the image.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s perhaps remarkable that such a constrained discriminator could cause the generator to build up anything
resembling a human face, but the final results are indisputably bad, and much worse than previous models.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Even though the input kernels to the discriminator in a DCGAN did not show much specialization during training,
reducing the number of input kernels available showed obvious reductions in image quality produced by the generator
after training. Further, the input kernels to the discriminator, no matter how few they were,
never showed the kind of specialization apparent in the final layers of the generator.&lt;/p&gt;
&lt;h3 id=&#34;other-wild-geese-to-chase&#34;&gt;Other Wild Geese to Chase&lt;/h3&gt;
&lt;p&gt;Even though the DCGAN&amp;rsquo;s Discriminator and Generator are largely symmetric, there are some key differences
that might explain the apparent lack of specialization in the discriminator&amp;rsquo;s first layer.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Activation functions: the generator uses Tanh between the transpose convolution and the final generated image,
while the discriminator a) uses LeakyReLU and b) places the activation function after the convolution. I haven&amp;rsquo;t
visualized the effect of these activation functions (since doing so would require an input to be run through
the network, and the result would depend on said input.) It&amp;rsquo;s quite possible the answer to this mystery lies
here.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The discriminator is not actually trained in the same way as typical classifiers. Although the architecture is
similar, the output of this discriminator is a single value (real or fake.)
It&amp;rsquo;s possible random noise is perfectly sufficient for
this task, whereas specialization only becomes necessary for classifiers that need to distinguish between
multiple different classes of image.&lt;/p&gt;
&lt;p&gt;Testing this would be as simple* as changing datasets (e.g. to &lt;a href=&#34;https://github.com/zalandoresearch/fashion-mnist&#34;&gt;fashion-MNIST&lt;/a&gt;
or &lt;a href=&#34;https://www.cs.toronto.edu/~kriz/cifar.html&#34;&gt;CIFAR-10&lt;/a&gt;), and changing the discriminator to
choose from 11 categories (the 10 from CIFAR-10, plus 1 extra denoting &amp;ldquo;fake&amp;rdquo;).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;*No guarantees it will be this simple&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The flow of gradients through the network for a GAN is asymmetric: the generator gets access
to the entire state of the discriminator for backprop, while the discriminator only gets its
own network&amp;rsquo;s response to stimulus to learn from. Why this mismatch would lead to such a
difference in layer specialization is unknown, to me at least. Perhaps patterned specialization
in the discriminator&amp;rsquo;s layer closest to the generator&amp;rsquo;s own layers would provide an easy
attack vector for the generator to learn and defeat the discriminator?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Is the first layer actually random?&lt;/em&gt; The lack of human-identifiable structure in the kernels
doesn&amp;rsquo;t strictly mean the discriminator isn&amp;rsquo;t specializing them. Freezing this layer and comparing
performance to the original network could tell whether the discriminator is, in fact, getting
value from this layer after all.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/drafts/hyperspace/testing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/drafts/hyperspace/testing/</guid>
      <description>&lt;!DOCTYPE html&gt; + - vec_len - vec_len + </description>
      <content>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script src=&#34;plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;div id=&#34;myDiv&#34;&gt;&lt;/div&gt;
&lt;button onclick=&#34;vector_position = Math.min(VEC_LEN, vector_position + 1); redraw_background();&#34;&gt; + &lt;/button&gt;
  &lt;span id=&#34;vector_display&#34;&gt;&lt;/span&gt;
&lt;button onclick=&#34;vector_position = Math.max(0, vector_position - 1); redraw_background();&#34;&gt; - &lt;/button&gt;
&lt;button onclick=&#34;vec_pos = Math.max(0, vec_pos - 1); calc_vecs(); redraw_background();&#34;&gt; vec_len - &lt;/button&gt;
  &lt;span id=&#34;vec_len&#34;&gt;&lt;/span&gt;
&lt;button onclick=&#34;vec_pos = Math.min(vec_pos + 1, VEC_LENGTHS.length - 1); calc_vecs(); redraw_background();&#34;&gt; vec_len + &lt;/button&gt;

  &lt;div id=&#34;hyperspace&#34; style=&#34;flexbox&#34;&gt;
    &lt;div id=&#34;circular&#34;&gt;&lt;/div&gt;
    &lt;div id=&#34;spherical&#34;&gt;&lt;/div&gt;
  &lt;/div&gt;

&lt;div class=&#34;slidecontainer&#34;&gt;
  &lt;input type=&#34;range&#34; min=&#34;0.&#34; max=&#34;1.&#34; value=&#34;0.5&#34; class=&#34;slider&#34; id=&#34;myRange&#34;
    oninput=&#34;frac = this.value; draw_point();&#34;&gt;
&lt;/div&gt;

&lt;script&gt;

const NUM_VECS = 10_000;

const VEC_LENGTHS = [1, 2, 3, 4, 5, 6, 10, 20, 50, 100, 1000];
let vec_pos = 2;
let VEC_LEN = VEC_LENGTHS[vec_pos];


// Hopefully all this configuration stuff can be
// pulled in from CSS from the site...
const point_color = &#39;grey&#39;;
const DEFAULT_MARKER_SIZE = 2.0;

// User-selectable elements
let vector_position = 0;

function gaussianRandom(mean=0, stdev=1) {
  const u = 1 - Math.random();
  const v = Math.random();
  const z = Math.sqrt( -2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);
  return z * stdev + mean;
}

function uniformRandom(min=-1, max=1) {
  return Math.random() * (max - min) + min;
}

function vec_to_spherical_xyz(vec, elem0=0, elem1=1, elem2=2) {
  // Consider only calculating this once, when generating the
  // vectors.
  const two_norm = Math.sqrt(vec.reduce((acc, x) =&gt; (acc + x**2), 0));
  if (vec.length == 0) {
    return [0, 0, 0];
  }
  if (vec.length == 1) {
    return [two_norm, 0, 0];
  }
  if (vec.length == 2 | elem2 == null) {
    let angle_1 = Math.atan2(vec[elem1], vec[elem0]);
    return [two_norm * Math.cos(angle_1), two_norm * Math.sin(angle_1), 0];
  }

  let angle_1 = Math.atan2(vec[elem1], vec[elem0]);
  let angle_2 = Math.atan2(vec[elem2], Math.sqrt(vec[elem0]**2 + vec[elem1]**2));

  return [
    two_norm * Math.cos(angle_1) * Math.cos(angle_2), 
    two_norm * Math.sin(angle_1) * Math.cos(angle_2), 
    two_norm * Math.sin(angle_2)
  ];
}

function vec_norm(vec) {
  let acc = 0;
  for (var i = 0; i &lt; vec.length; i++) {
    acc += vec[i]**2;
  }
  return Math.sqrt(acc);
}

function vec_to_spherical_maybe_faster(vec, elem0=0, elem1=1, elem2=2) {
  if (vec.length == 1) {
    return [vec[elem0], 0, 0];
  }
  const norm = vec_norm(vec);

  if (vec.length == 2 | elem2 == null) {
    // This feels like cheating, but really 
    // we don&#39;t need to do anything up until 
    // 4 dimensions
    return [vec[elem0], vec[elem1], 0];
  }

  const dir_norm = vec_norm([vec[elem0], vec[elem1], vec[elem2]]);
  const mag = norm / dir_norm;
  return [vec[elem0] * mag, vec[elem1] * mag, vec[elem2] * mag];
}

function vecs_to_spherical(vecs, elem0=0, elem1=1, elem2=2) {
  let x = [];
  let y = [];
  let z = [];

  vecs.map((vec) =&gt; {
    let [vec_x, vec_y, vec_z] = vec_to_spherical_xyz(vec, elem0, elem1, elem2);
    x.push(vec_x);
    y.push(vec_y);
    z.push(vec_z);
  });

  return [x, y, z];
}

function newVec(initializer) {
  return Array.from({length: VEC_LEN}, (x, i) =&gt; initializer());
}
  
let vecs = [];

function calc_vecs() {
  VEC_LEN = VEC_LENGTHS[vec_pos];
  vecs = [];
  for (let i = 0; i &lt; NUM_VECS; i++) {
    vecs.push(newVec(gaussianRandom));
  }
}

function slice_arrays(index, array) {
  let x = [];
  let y = [];
  let z = [];
  
  for (var i = 0; i &lt; array.length; i++) {
    x.push(array[i][index]);
    y.push(array[i][index + 1]);
    z.push(array[i][index + 2]);
  }
  return [x, y, z];
}


let layout = {
  width: &#34;30%&#34;,
  paper_bgcolor: &#39;rgba(0,0,0,0)&#39;,
  plot_bgcolor: &#39;rgba(0,0,0,0)&#39;,
  hovermode: false,
  
  xaxis: {
    zeroline: false,
    tickmode: &#34;array&#34;,
    tickvals: [-3, 0, 3], 
  },
  yaxis: {
    zeroline: false,
    tickmode: &#34;array&#34;,
    tickvals: [-3, 0, 3], 
  },
  scene: {
    aspectmode: &#39;data&#39;,
    xaxis: {
      zeroline: false,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    },
    yaxis: {
      zeroline: false,
      scaleanchor: &#34;x&#34;,
      scaleratio: 1,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    },
    zaxis: {
      zeroline: false,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    }
  }
};

calc_vecs();

let [x, y, z] = slice_arrays(vector_position, vecs);
/* let [hero_x, hero_y, hero_z] = slice_arrays(vector_position, hero_vec); */

const data = [
  {
    type: &#39;scatter3d&#39;,
    mode: &#39;markers&#39;,
    x: x,
    y: y,
    z: z,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      }
    }
  },
  // {
  //   type: &#39;scatter3d&#39;,
  //   mode: &#39;markers&#39;,
  //   x: hero_x,
  //   y: hero_y,
  //   z: hero_z,
  //   marker: {
  //     size: 2,
  //     color: &#39;red&#39;,
  //   }
  //}
]
data[0].marker.color[0] = &#39;red&#39;;
data[0].marker.color[1] = &#39;red&#39;;
data[0].marker.size[0] = 6;
data[0].marker.size[1] = 6;

const config = {
  displayModeBar: false,
  dragMode: false,
  scrollZoom: true,
};

let plot = document.getElementById(&#34;myDiv&#34;);
let spherical = document.getElementById(&#34;spherical&#34;);
let circular = document.getElementById(&#34;circular&#34;);
let vec_display = document.getElementById(&#34;vector_display&#34;);

function redraw_background() {
  let [x, y, z] = slice_arrays(vector_position, vecs);
  data[0].x = x;
  data[0].y = y;
  data[0].z = z;
  data[0].marker.color[0] = &#39;red&#39;;
  data[0].marker.color[1] = &#39;red&#39;;
  data[0].marker.size[0] = 6;
  data[0].marker.size[1] = 6;

  Plotly.react(plot, data, layout, config);

  let [s_x, s_y, s_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, vector_position + 2);
  spherical_data[0].x = s_x;
  spherical_data[0].y = s_y;
  spherical_data[0].z = s_z;
  spherical_data[0].marker.color[0] = &#39;red&#39;;
  spherical_data[0].marker.color[1] = &#39;red&#39;;
  spherical_data[0].marker.size[0] = 6;
  spherical_data[0].marker.size[1] = 6;

  layout.scene.xaxis.tickmode = &#34;array&#34;;
  layout.scene.yaxis.tickmode = &#34;array&#34;;
  layout.scene.zaxis.tickmode = &#34;array&#34;;
  let sigma = 1.0;
  let bound = Math.ceil(Math.sqrt(vecs[0].length) * sigma);
  layout.scene.xaxis.tickvals = [-bound, bound];
  layout.scene.yaxis.tickvals = [-bound, bound];
  layout.scene.zaxis.tickvals = [-bound, bound];
  layout.xaxis.tickvals = [-bound, bound];
  layout.yaxis.tickvals = [-bound, bound];


  Plotly.react(spherical, spherical_data, layout, config);


  let [c_x, c_y, c_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, null);
  circular_data[0].x = c_x;
  circular_data[0].y = c_y;
  circular_data[0].marker.color[0] = &#39;red&#39;;
  circular_data[0].marker.color[1] = &#39;red&#39;;
  circular_data[0].marker.size[0] = 6;
  circular_data[0].marker.size[1] = 6;
  circular_data[0].test = &#34;true&#34;;

  Plotly.react(circular, circular_data, layout, config);

  // show interpolation
  let lerp_path = draw_interp(vecs, lerp);
  let [p_x, p_y, p_z] = slice_arrays(vector_position, lerp_path);
  let new_data = {
    type: &#39;scatter3d&#39;,
    mode: &#39;lines&#39;,
    x: p_x,
    y: p_y,
    z: p_z,
  }

  Plotly.addTraces(plot, new_data);
  Plotly.deleteTraces(plot, 1);

  let [ns_x, ns_y, ns_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, vector_position + 2);
  let new_sphere = {
    type: &#39;scatter3d&#39;,
    mode: &#39;lines&#39;,
    x: ns_x,
    y: ns_y,
    z: ns_z,
  }

  Plotly.deleteTraces(spherical, 1);
  Plotly.addTraces(spherical, new_sphere);

  let [nc_x, nc_y, nc_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, null);
  let new_circ = {
    type: &#39;scattergl&#39;,
    mode: &#39;lines&#39;,
    x: nc_x,
    y: nc_y,
  }

  Plotly.deleteTraces(circular, 1);
  Plotly.addTraces(circular, new_circ);

  showVecText();
  draw_point();
}

function showVecText() {
  let vec_string = &#34;[&#34;;
  if (vector_position &gt; 0) {
    vec_string += &#34;..., &#34;; 
  }

  // TODO bounds check on vector_position
  const NUM_DISPLAYED = 3;
  for (var pos = vector_position; pos &lt; Math.min(VEC_LEN, vector_position + NUM_DISPLAYED); pos++) {
    vec_string += `${vecs[0][pos].toFixed(2)}, `;
  }

  if (vector_position + NUM_DISPLAYED &lt; VEC_LEN) {
    vec_string += &#34;...&#34;;
  }

  vec_string += &#34;]&#34;;
  
  vec_display.textContent = vec_string;

  let vec_len = document.getElementById(&#34;vec_len&#34;);
  vec_len.textContent = VEC_LEN;
}

Plotly.newPlot(plot, data, layout, config);

// 3-sphere
let [s_x, s_y, s_z] = vecs_to_spherical(vecs);


const spherical_data = [
  {
    type: &#39;scatter3d&#39;,
    mode: &#39;markers&#39;,
    x: s_x,
    y: s_y,
    z: s_z,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      } 
    }
  },
]
spherical_data[0].marker.color[0] = &#39;red&#39;;
spherical_data[0].marker.color[1] = &#39;red&#39;;
spherical_data[0].marker.size[0] = 6;
spherical_data[0].marker.size[1] = 6;

Plotly.newPlot(spherical, spherical_data, layout, config);

// 2-sphere
let [c_x, c_y, c_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, null);

const circular_data = [
  {
    type: &#39;scattergl&#39;,
    mode: &#39;markers&#39;,
    x: c_x,
    y: c_y,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      } 
    }
  },
]
circular_data[0].marker.color[0] = &#39;red&#39;;
circular_data[0].marker.color[1] = &#39;red&#39;;
circular_data[0].marker.size[0] = 6;
circular_data[0].marker.size[1] = 6;

Plotly.newPlot(circular, circular_data, layout, config);
// Plotly.restyle(plot, &#39;marker.size&#39;, [[&#39;red&#39;]]);
showVecText();

// lerp

function lerp(fraction, start, stop) {
  let out = [];
  for (var i = 0; i &lt; start.length; i++) {
    out[i] = start[i] + fraction * (stop[i] - start[i]);
  }
  return out;
}

function _v(func, array) {
  // Apply a function along a vector.
  return array.map((x) =&gt; func(x));
}

function clamp(val, min, max) {
  // Mirror&#39;s numpy&#39;s &#39;clip&#39; function
  return Math.max(min, Math.min(val, max));
}

function mult(array, num) {
  // elemwise multiplication
  return array.map((x) =&gt; x * num);
}

function dot(arr1, arr2) {
  // Implicitly assumes arr1 and arr2 
  // have the same length.
  acc = 0;
  for (var i = 0; i &lt; arr1.length; i++) {
    acc += arr1[i] * arr2[i]; 
  }
  return acc;
}

function slerp(fraction, start, stop) {
  const norm_start = mult(start, 1 / vec_norm(start));
  const norm_stop = mult(stop, 1 / vec_norm(stop));

  const omega = Math.acos(clamp(dot(norm_start, norm_stop), -1, 1));
  const so = Math.sin(omega);

  let out = new Array(start.length);

  if (so == 0) {
    for (let i = 0; i &lt; start.length; i++) {
      out[i] = (1.0 - fraction) * start[i] + fraction * stop[i];
    }
  }
  else {
    let s_omega_minus = Math.sin((1.0 - fraction) * omega) / so;
    let s_omega_plus = Math.sin(fraction * omega) / so;
    for (let i = 0; i &lt; start.length; i++) {
      out[i] = s_omega_minus * start[i] + s_omega_plus * stop[i];
    }
  }
  return out;
}

// Returns an array of vectors, i.e. NOT transformed into x, y, z
function draw_interp(vecs, interpolator, num_steps=100) {
  let tweens = Array.from({ length: num_steps}, (v, i) =&gt; i / (num_steps - 1));
  
  return tweens.map((fraction) =&gt; interpolator(fraction, vecs[0], vecs[1]));
     
}

// show interpolation
let lerp_path = draw_interp(vecs, lerp);
let [p_x, p_y, p_z] = slice_arrays(vector_position, lerp_path);
let new_data = {
  type: &#39;scatter3d&#39;,
  mode: &#39;lines&#39;,
  x: p_x,
  y: p_y,
  z: p_z,
}

Plotly.addTraces(plot, new_data);

let [ns_x, ns_y, ns_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, vector_position + 2);
let new_sphere = {
  type: &#39;scatter3d&#39;,
  mode: &#39;lines&#39;,
  x: ns_x,
  y: ns_y,
  z: ns_z,
}

Plotly.addTraces(spherical, new_sphere);

let [nc_x, nc_y, nc_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, null);
let new_circ = {
  type: &#39;scattergl&#39;,
  mode: &#39;lines&#39;,
  x: nc_x,
  y: nc_y,
}

Plotly.addTraces(circular, new_circ);

let frac = 0.5;

function draw_point(del_old=true) {
  let midpoint = slerp(frac, vecs[0], vecs[1]);
  midpoint_circ = vecs_to_spherical([midpoint], vector_position, vector_position + 1, null);
  midpoint_spher = vecs_to_spherical([midpoint], vector_position, vector_position + 1, vector_position + 2);
  if (del_old) {
    Plotly.deleteTraces(spherical, 1);
    Plotly.deleteTraces(circular, 1);
    Plotly.deleteTraces(plot, 1);
  }
  let spher_point = {
    type: &#39;scatter3d&#39;,
    mode: &#39;marker&#39;,
    x: midpoint_spher[0],
    y: midpoint_spher[1],
    z: midpoint_spher[2],
  }
  let circ_point = {
    type: &#39;scattergl&#39;,
    mode: &#39;marker&#39;,
    x: midpoint_circ[0],
    y: midpoint_circ[1],
  } 
  let point = {
    type: &#39;scatter3d&#39;,
    mode: &#39;marker&#39;,
    x: midpoint[0],
    y: midpoint[1],
    z: midpoint[2],
  }

  Plotly.addTraces(spherical, spher_point);
  Plotly.addTraces(circular, circ_point);
  Plotly.addTraces(plot, point);
}

draw_point(false);


&lt;/script&gt;
&lt;/body&gt;
</content>
    </item>
    
    <item>
      <title></title>
      <link>http://localhost:1313/drafts/hyperspace/testing2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/drafts/hyperspace/testing2/</guid>
      <description>&lt;!DOCTYPE html&gt; </description>
      <content>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script type=&#34;text/javascript&#34; id=&#34;MathJax-script&#34; async
  src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;
&lt;/script&gt;
&lt;script src=&#34;plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
&lt;div id=&#39;vector&#39;&gt;&lt;/div&gt;

&lt;script&gt;
const VEC_ELEMS_DISPLAYED = 8;
const AVAILABLE_DIMENSIONS = [1, 2, 3, 4, 5, 6, 10, 20, 50, 100, 1000];


function latexize_vector(vector, element_id, slice_offset, dimensions, num_selected) {
  if (dimensions &gt; vector.length) throw(&#34;Dimensions &gt; vector length&#34;);
  let latex_str = `
    \\[
    \\mathbf{
    \\begin{align}
\\vec{v_{${dimensions}}} = \\begin{bmatrix}`;

  const start = Math.max(0, Math.min(slice_offset, dimensions - VEC_ELEMS_DISPLAYED));
  const desired_stop = Math.min(dimensions, slice_offset + VEC_ELEMS_DISPLAYED);
    
  // Adding dots increases the size of the vector, so we need
  // this check to stop the vector increasing and decreasing
  // in length as we scroll through.
  const stop = (start &gt; 0 &amp;&amp; desired_stop &lt; dimensions) ? desired_stop - 1 : desired_stop;

  if (start &gt; 0) latex_str += `\\vdots \\\\`;
  for (let i = start; i &lt; stop; i++) {
    if ((i - slice_offset) &gt;= 0 &amp;&amp; (i - slice_offset) &lt; num_selected) {
      latex_str += `\\mathbf{${vector[i].toFixed(2)}} \\\\`
    } else {
      latex_str += `${vector[i].toFixed(2)} \\\\`
    }
  }
  if (stop &lt; dimensions) latex_str += `\\vdots \\\\`;

  latex_str += `\\end{bmatrix}
              \\end{align}
            }
            \\]`;
  document.getElementById(element_id).innerHTML = latex_str;
}

function get_vector_widget(vector, id, start_dims=0, start_offset=0, num_selected=2) {
  let current_dims = start_dims;
  let current_offset = start_offset;

  const container = document.getElementById(id);
  const dim_plus = container.appendChild(document.createElement(&#34;button&#34;));
  const dim_minus = container.appendChild(document.createElement(&#34;button&#34;));
  const slice_plus = container.appendChild(document.createElement(&#34;button&#34;));
  const slice_minus = container.appendChild(document.createElement(&#34;button&#34;));
  
  const vec_div = container.appendChild(document.createElement(&#34;div&#34;));
  vec_div.id = id + &#34;_vec_div&#34;;

  async function redraw_vec() {
    latexize_vector(vector, vec_div.id, current_offset, AVAILABLE_DIMENSIONS[current_dims], num_selected);
    await MathJax.typesetPromise();
  }

  redraw_vec();


  // create +dimensions button
  dim_plus.textContent = &#34;dim+&#34;;
  dim_plus.onclick = () =&gt; {
    if (AVAILABLE_DIMENSIONS[current_dims + 1] &lt;= vector.length) {
      current_dims = current_dims + 1
      current_offset = Math.min(current_offset, AVAILABLE_DIMENSIONS[current_dims] - num_selected);
      redraw_vec();
    };
  };
  // create -dimensions button
  dim_minus.textContent = &#34;dim-&#34;;
  dim_minus.onclick = () =&gt; {
    current_dims = Math.max(0, current_dims - 1);
    current_offset = Math.min(current_offset, AVAILABLE_DIMENSIONS[current_dims] - num_selected);
    redraw_vec();
  }; 
  // create +slice button
  slice_plus.textContent = &#34;slice+&#34;;
  slice_plus.onclick = () =&gt; {
    current_offset = Math.min(AVAILABLE_DIMENSIONS[current_dims] - num_selected, current_offset + 1); 
    redraw_vec();
  };

  // create -slice button
  slice_minus.textContent = &#34;slice-&#34;;
  slice_minus.onclick = () =&gt; {
    current_offset = Math.max(0, current_offset - 1); 
    redraw_vec();
  };


}
  // hook buttons up to relevant plot callbacks

get_vector_widget(Array.from({length: 1000}, (v, i) =&gt; i), &#39;vector&#39;, 0, 0, 1);

&lt;/script&gt;
</content>
    </item>
    
    <item>
      <title>About me</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/about/</guid>
      <description>Hi, I&amp;rsquo;m Will!
I&amp;rsquo;m an engineer living in Auckland. I have a Master&amp;rsquo;s in Mechanical and Aerospace engineering, but I write about programming and machine learning, mostly.
Things I&amp;rsquo;ve done (so far):
Helped develop a rocket engine and send a satellite to the moon. Lead the analysis of several propellant systems for the reusable Neutron rocket. Lead the development and early testing of Neutron&amp;rsquo;s RCS system. Developed internal tools for modelling, data analysis, and configuration management at Rocket Lab.</description>
      <content>&lt;p&gt;Hi, I&amp;rsquo;m Will!&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m an engineer living in Auckland. I have a Master&amp;rsquo;s in Mechanical and Aerospace engineering,
but I write about programming and machine learning, mostly.&lt;/p&gt;
&lt;p&gt;Things I&amp;rsquo;ve done (so far):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Helped develop a &lt;a href=&#34;https://www.youtube.com/live/LtvMiivrxxA?si=-F8PH2Z62zVpUlsi&amp;t=1930&#34;&gt;rocket engine and send a satellite to the moon.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lead the analysis of several propellant systems for the &lt;a href=&#34;https://www.rocketlabusa.com/launch/neutron/&#34;&gt;reusable Neutron rocket.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lead the development and early testing of Neutron&amp;rsquo;s &lt;a href=&#34;https://en.wikipedia.org/wiki/Reaction_control_system&#34;&gt;RCS system.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Developed internal tools for modelling, data analysis, and configuration management at &lt;a href=&#34;https://www.rocketlabusa.com/&#34;&gt;Rocket Lab.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learnt Rust (and accidentally learnt JavaScript and some web-dev along the way) by developing &lt;strong&gt;&lt;a href=&#34;https://www.playhexchess.com&#34;&gt;playhexchess.com&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.linkedin.com/in/william-snell-818159171&#34;&gt;linkedin&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/williamsnell&#34;&gt;github&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
</content>
    </item>
    
  </channel>
</rss>
