<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>willsnell</title>
    <link>https://willsnell.com/</link>
    <description>Recent content on willsnell</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 04 Dec 2024 10:26:20 +1300</lastBuildDate><atom:link href="https://willsnell.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Trigrams</title>
      <link>https://willsnell.com/posts/trigrams/</link>
      <pubDate>Wed, 04 Dec 2024 10:26:20 +1300</pubDate>
      
      <guid>https://willsnell.com/posts/trigrams/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;This post is converted from a Jupyter Notebook. To view the original interactive version, check out the
&lt;a href=&#34;https://colab.research.google.com/drive/161EE2W98h_mpphESWv_mPtbv__MZP8jV?usp=sharing&#34;&gt;Colab notebook.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;monthly-algorithmic-challenge-november-2024-trigrams&#34;&gt;Monthly Algorithmic Challenge (November 2024): Trigrams&lt;/h1&gt;
&lt;p&gt;Last week, I worked through the monthly Mechanistic Interpretability challenge from &lt;a href=&#34;https://arena3-chapter1-transformer-interp.streamlit.app/Monthly_Algorithmic_Problems&#34;&gt;Callum McDougall&amp;rsquo;s ARENA course&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(A huge shoutout to Callum and the entire ARENA team for all the work they do!)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The challenge was to interpret how a simple neural net - in this case, a 1 layer 1 head transformer (with MLP) - solves a problem.
The problem at hand was to predict the next token in a sequence of random tokens. As the model was trained with cross-entropy
loss, training on a completely random dataset would lead the model to always uniformly predict all tokens in the vocabulary.&lt;/p&gt;</description>
      <content>&lt;blockquote&gt;
&lt;p&gt;This post is converted from a Jupyter Notebook. To view the original interactive version, check out the
&lt;a href=&#34;https://colab.research.google.com/drive/161EE2W98h_mpphESWv_mPtbv__MZP8jV?usp=sharing&#34;&gt;Colab notebook.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;monthly-algorithmic-challenge-november-2024-trigrams&#34;&gt;Monthly Algorithmic Challenge (November 2024): Trigrams&lt;/h1&gt;
&lt;p&gt;Last week, I worked through the monthly Mechanistic Interpretability challenge from &lt;a href=&#34;https://arena3-chapter1-transformer-interp.streamlit.app/Monthly_Algorithmic_Problems&#34;&gt;Callum McDougall&amp;rsquo;s ARENA course&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(A huge shoutout to Callum and the entire ARENA team for all the work they do!)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The challenge was to interpret how a simple neural net - in this case, a 1 layer 1 head transformer (with MLP) - solves a problem.
The problem at hand was to predict the next token in a sequence of random tokens. As the model was trained with cross-entropy
loss, training on a completely random dataset would lead the model to always uniformly predict all tokens in the vocabulary.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;However&lt;/em&gt;, inserted randomly throughout the dataset were &lt;strong&gt;trigrams&lt;/strong&gt;, sequences of 3 tokens which always followed the pattern&lt;/p&gt;
&lt;p&gt;&lt;code&gt;trigram[0], trigram[1]&lt;/code&gt; =&amp;gt; &lt;code&gt;trigram[2].&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;For example, for a trigram &lt;code&gt;(1, 2, 3)&lt;/code&gt; and the sequence &lt;code&gt;5 74 38 12 52 1 2&lt;/code&gt;, we know for certain the next token is &lt;code&gt;3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Consequently, we expect the model to develop ways of detecting the presence of trigrams, determining &lt;em&gt;which&lt;/em&gt; trigram is present, retrieving the correct completion, and writing to the output to confidently predict the correct completion token. The mechanisms the model learns to do this are explored below.&lt;/p&gt;
&lt;p&gt;My work starts from &lt;a href=&#34;https://willsnell.com/posts/trigrams/#misc-tools&#34;&gt;&amp;ldquo;Misc Tools&amp;rdquo;&lt;/a&gt; onwards.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re comfortable with Jupyter Notebooks/Google Colab, I&amp;rsquo;d recommend reading through the
interactive version of this page, linked as a Google Colab notebook, &lt;a href=&#34;https://colab.research.google.com/drive/161EE2W98h_mpphESWv_mPtbv__MZP8jV?usp=sharing&#34;&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;beginning-of-attempt&#34;&gt;Beginning of Attempt&lt;/h1&gt;
&lt;h1 id=&#34;misc-tools&#34;&gt;Misc Tools&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_trigram_positions&lt;/span&gt;(dataset: BigramDataset) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; Tuple[
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;n_trigram_occurences&amp;#34;&lt;/span&gt;], Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;n_trigram_occurences&amp;#34;&lt;/span&gt;]]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Return the batch and sequence positions of trigrams
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    for the tokens in a dataset.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Do a 2-wide sliding window&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    pairs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unfold(dimension&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, size&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, step&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    patterns &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]] &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; trigram &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Match all pairs against all patterns.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# &amp;#39;matches&amp;#39; gives the position where a particular trigram matches.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    matches &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (pairs&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; patterns&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;reshape(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, len(patterns), &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;all(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#75715e&#34;&gt;# [batch, seq - 1, num_patterns]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# trigram_pos gives the starting position of *any* valid trigram.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    batch_idx, seq_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(matches&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;any(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; batch_idx, seq_idx
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;attention-patterns&#34;&gt;Attention Patterns&lt;/h1&gt;
&lt;p&gt;The first thing to probe is the attention head. To figure out what algorithm/s it might be implementing, we want to plot a number of different batches against the attention patterns.&lt;/p&gt;
&lt;p&gt;In particular, we add two markers to the plot:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;A ✓ to indicate the model made a correct prediction of the next token,
based on this sequence position.&lt;/li&gt;
&lt;li&gt;A highlighted horizontal bar, indicating the presence of the first two elements (trigram[0] and trigram[1]) of a trigram.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;batch_idx, seq_idx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; get_trigram_positions(dataset)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;visualize_attn&lt;/span&gt;(batch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    trigrams &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; seq_idx[batch_idx &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; batch]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    attn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.attn.hook_pattern&amp;#39;&lt;/span&gt;][batch, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#75715e&#34;&gt;# select batch, head = 0 -&amp;gt; [q_seq, k_seq]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    bound &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; max(attn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;min()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs(), attn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;max()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;abs())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;batch&lt;span style=&#34;color:#e6db74&#34;&gt;=}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(attn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), vmin&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, vmax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;bound, cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Blues&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Key&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Query&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Visualize if the model makes a correct prediction&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    correct_predictions &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;where(logits[batch, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks[batch, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;:])[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; len(correct_predictions), correct_predictions&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;g&amp;#34;&lt;/span&gt;, linestyle&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;, marker&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;$✓$&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Highlight places where trigrams are present (in the query direction).&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(attn, device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mask[trigrams] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mask[trigrams &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(mask&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;, cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# interact(visualize_attn, batch=(0, logits.shape[0] - 1, 1))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;visualize_attn(batch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_6_0.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;From the plot, we can see a few interesting things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Firstly, by default the head attends to the current sequence position. We can probably think of this as a &amp;rsquo;no-op&#39;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Secondly, most of the time when a trigram is present, the query key for &lt;code&gt;trigram[1]&lt;/code&gt; will attend strongly (&amp;gt;0.9) to &lt;code&gt;trigram[0]&lt;/code&gt;. Less frequently, the head will split attention between &lt;code&gt;trigram[1]&lt;/code&gt; and &lt;code&gt;trigram[0]&lt;/code&gt; roughly evenly, and ignore everything else.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Thirdly, for some trigrams, the model makes a correct prediction of &lt;code&gt;trigram[2]&lt;/code&gt; but only attends to &lt;code&gt;trigram[1]&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finally, the model occasionally makes correct predictions when no trigrams are present, which is just the result of a lucky guess.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Point one makes sense: the model doesn&amp;rsquo;t need to know anything about the previous token if it is just going to make a guess (in the case of no trigram).
Point two also makes some sense: the residual stream for &lt;code&gt;trigram[1]&lt;/code&gt; always contains information about &lt;code&gt;trigram[1]&lt;/code&gt;. For the unembeddings or the MLP later on to make a correct guess, however, the residual stream also needs some information about &lt;code&gt;trigram[0]&lt;/code&gt;, and the only way it can get this is by attending to the previous token.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s perhaps counter-intuitive is that sometimes the model makes correct predictions in the presence of a trigram without attending to &lt;code&gt;trigram[0]&lt;/code&gt; at all!&lt;/p&gt;
&lt;p&gt;To get a better understanding of what&amp;rsquo;s going on, let&amp;rsquo;s break apart the attention mechanism into position-based and token-based - that is, projecting the &lt;code&gt;W_pos&lt;/code&gt; and &lt;code&gt;W_E&lt;/code&gt; matrices into the attention space.&lt;/p&gt;
&lt;p&gt;Below, we plot these two components for the tokens in each batch, all pre-softmax.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;mask_trigrams&lt;/span&gt;(attn, batch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Show a highlighted area over the query-sequence
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    positions where `trigram[0], trigram[1]` are
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    present. &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    trigrams &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; seq_idx[batch_idx &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; batch]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mask &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(attn[batch], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mask[trigrams] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    mask[trigrams &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(mask&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), alpha&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.05&lt;/span&gt;, cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;gray&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;plot_tok_pos&lt;/span&gt;(batch):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Plot the attention head contributions from token embeddings
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  and positional embeddings, separately.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Positional embedding only&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  q_pos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pos_embed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_Q[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_Q[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  k_pos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;pos_embed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_K[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_K[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  attn_pos &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(q_pos, k_pos, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... qseq dhead, ... kseq dhead -&amp;gt; ... qseq kseq&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#75715e&#34;&gt;#.masked_fill_(t.triu(t.ones(q_pos.shape[-2], q_pos.shape[-2]).bool(), diagonal=1), -t.inf)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  fig, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Positional Embeddings&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(attn_pos[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;inferno&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(f)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  mask_trigrams(attn_pos, batch)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Query&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Key&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;# Token only, no positional embeddings&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  q_tok &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hook_embed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_Q[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_Q[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  k_tok &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hook_embed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_K[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_K[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  attn_tok &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(q_tok, k_tok, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... qseq dhead, ... kseq dhead -&amp;gt; ... qseq kseq&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;masked_fill_(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;triu(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ones(q_tok&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], q_tok&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;bool(), diagonal&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;inf)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  fig, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Token Embeddings&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(attn_tok[batch]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;inferno&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(f)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xticks(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]), dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks[batch]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), rotation&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_yticks(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]), dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks[batch]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Query&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Key&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# interact(plot_tok_pos, batch=(0, logits.shape[0] - 1, 1))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plot_tok_pos(batch&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_8_0.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_8_1.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;initial-hypothesis&#34;&gt;Initial Hypothesis&lt;/h1&gt;
&lt;h2 id=&#34;token-embeddings&#34;&gt;Token Embeddings&lt;/h2&gt;
&lt;p&gt;The query vector is looking for a token that precedes it in a trigram.&lt;/p&gt;
&lt;p&gt;E.g. for token 47, the query vector is looking for 2, 4, or 41 (because (2, 47, 28), (4, 47, 23), and (41, 47, 3) are all valid trigrams.)&lt;/p&gt;
&lt;p&gt;The key vector indicates which token it represents. For token 41, the key vector says &amp;ldquo;I am 41&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;positional-embeddings&#34;&gt;Positional Embeddings&lt;/h2&gt;
&lt;p&gt;The positional embeddings are monotonic and essentially linear based on sequence position, with higher scores for later tokens. This means that the highest attention score is, by default, always the current token.&lt;/p&gt;
&lt;p&gt;The positional embeddings for the last position of the sequence appears to be nonsense, because there is no correct prediction to learn.&lt;/p&gt;
&lt;h2 id=&#34;combined-embeddings&#34;&gt;Combined Embeddings&lt;/h2&gt;
&lt;p&gt;Combining the two embeddings, the algorithm for detecting trigrams appears to be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. Use token embeddings to determine if a preceding token matches the current token. That is, increase attention when (key == trigram[0]) and (query == trigram[1]).

2. Use positional embeddings to mask out the attention scores for all keys except the immediately previous one.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;em&gt;could&lt;/em&gt; explain how the model works for almost all trigrams.&lt;/p&gt;
&lt;p&gt;The one notable exception to this are for trigrams with repeats, e.g. (72, 72, 48). In this case, the model appears to attend only to the most recent occurence of the token. Given what we suspect about how this model&amp;rsquo;s attention mechanism works, we shouldn&amp;rsquo;t really expect it to do anything else.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The monotonic nature of the learned positional embeddings mean the most recent token always gets precedence&lt;/li&gt;
&lt;li&gt;The token embeddings for two identical keys must, by definition, be identical&lt;/li&gt;
&lt;li&gt;Because softmax is translation invariant, the model can&amp;rsquo;t just make the token-based attention score very high in the case of duplicated sequences, because only the difference between the two positions&amp;rsquo; attention scores matters.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;How, then, does the model predict these duplicate trigrams (and it does predict them correctly!)&lt;/p&gt;
&lt;p&gt;Maybe the MLP directly implements predictions for repeated tokens? However, there&amp;rsquo;s no mechanism for the MLP to get information about the previous token without an attention head playing ball and telling it the current token is a repeat. Since the positional embedding scheme in the single head present doesn&amp;rsquo;t do that, there&amp;rsquo;s really only one avenue left for the model to predict completions of duplicate-starting trigrams: fake it!&lt;/p&gt;
&lt;p&gt;Since &lt;code&gt;trigram[0], trigram[1]&lt;/code&gt; always imply the same &lt;code&gt;trigram[2]&lt;/code&gt;, the model can always guess the correct completion, regardless of whether the current token is a duplicate.&lt;/p&gt;
&lt;p&gt;Is this what we see?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;fig, axes &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;, figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Predictions for &amp;#39;X, 72 -&amp;gt; &amp;#39;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;72&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;72&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;72, 72&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;72&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1, 72&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;72&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;74, 72&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;72&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1, 74, 72&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Token&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Probability&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# a series of random tokens (of the same sequence length)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# that end in 54&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Predictions for &amp;#39;X, 54 -&amp;gt; &amp;#39;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;54&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;54&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;54, 54&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;54&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1, 54&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;74&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;54&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;74, 54&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Token&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Probability&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# two random tokens that are not a trigram&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Random Tokens&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;32, 52&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;32&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;1, 32, 52&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;31&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;52&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), label&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;31, 52&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;legend()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Token&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Probability&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# two random tokens that **are** a trigram&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Random Trigram&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;26&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;49&lt;/span&gt;]]))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Token&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;axes[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Probability&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_10_0.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Above, we have four plots showing (from top left, clockwise):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For any sequence (that isn&amp;rsquo;t a non-repeating trigram) ending in 72, the model always makes the same prediction. That is, it (weakly) predicts the correct continuation of the (72, 72, 48) trigram.&lt;/li&gt;
&lt;li&gt;For another repeating trigram (54, 54, 67), we have the same behaviour: all sequences ending in 54 weakly predict 67 as the follow up.&lt;/li&gt;
&lt;li&gt;Picking an arbitrary non-repeating trigram (in this case, (26, 49, 22)), we see that the model very strongly predicts the correct continuation (22). This is quite different to the two preceding plots, where the prediction was closer to uniform.&lt;/li&gt;
&lt;li&gt;If we look at a number of non-trigram sequences, we can see that while predictions are fairly uniform, both sequence position and the preceding token appear to slightly tweak the exact distribution output. This is markedly different to the repeating trigrams (figures 1 and 2), which vary their predictions only based on sequence position and &lt;em&gt;not&lt;/em&gt; on the preceding token.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;does-token-attention-encode-trigram-starts&#34;&gt;Does Token Attention Encode Trigram Starts?&lt;/h1&gt;
&lt;p&gt;If the model is really using key-query vectors to encode &lt;code&gt;trigram[0], trigram[1]&lt;/code&gt; pairs, we should be able to see that directly. Looking at the first 50 sequence positions:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tokens &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cfg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;n_ctx &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unsqueeze(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;m, c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_with_cache(tokens)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Token only, no positional embeddings&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;q_tok &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (c[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hook_embed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_Q[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_Q[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;k_tok &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (c[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;hook_embed&amp;#39;&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_K[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_K[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;attn_tok &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(q_tok, k_tok, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... qseq dhead, ... kseq dhead -&amp;gt; ... qseq kseq&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;fig, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;8&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grid()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(attn_tok[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;softmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), cmap&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;Greens&amp;#39;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(f)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Trigram[0]&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Trigram[1]&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_xticks(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), tokens[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy(), rotation&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;90&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_yticks(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;), tokens[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_13_0.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Indeed, we can read off the values of our trigram-starting pairs by:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. Pick a value from the y-axis. This is the query token, and
represents `trigram[1]`.
2. Read from left to right, until we encounter a large value.
3. From this highlighted square, read off the x-axis value. This is the key value that the query was looking for - i.e. `trigram[0]`.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can compare the hotspots on this chart to the set of possible trigrams, sorted by second element (&lt;code&gt;trigram[1]&lt;/code&gt;). This gives quite good agreement, once we filter out very low values.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s interesting is the significant variability in how intensely the model attends to different trigram pairs. It&amp;rsquo;s possible this is a limitation of the space the model has to work with, or something else entirely.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;table &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Table(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;First Element&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_column(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Second Element&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_column(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Third Element&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; trigram &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; sorted(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams, key&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: x[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    table&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;add_row(str(trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]), str(trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]), str(trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;console &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; Console()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;console&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;print(table)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;details&gt;
	&lt;summary&gt;&lt;b&gt;Click to view table&lt;/b&gt;&lt;/summary&gt;
&lt;pre style=&#34;white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,&#39;DejaVu Sans Mono&#39;,consolas,&#39;Courier New&#39;,monospace&#34;&gt;┏━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃&lt;span style=&#34;font-weight: bold&#34;&gt; First Element &lt;/span&gt;┃&lt;span style=&#34;font-weight: bold&#34;&gt; Second Element &lt;/span&gt;┃&lt;span style=&#34;font-weight: bold&#34;&gt; Third Element &lt;/span&gt;┃
┡━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ 17            │ 0              │ 43            │
│ 57            │ 0              │ 34            │
│ 9             │ 0              │ 37            │
│ 12            │ 0              │ 20            │
│ 13            │ 1              │ 22            │
│ 6             │ 1              │ 54            │
│ 17            │ 1              │ 12            │
│ 64            │ 1              │ 8             │
│ 10            │ 2              │ 67            │
│ 56            │ 2              │ 22            │
│ 3             │ 2              │ 62            │
│ 63            │ 2              │ 17            │
│ 58            │ 3              │ 70            │
│ 15            │ 4              │ 50            │
│ 57            │ 4              │ 73            │
│ 54            │ 4              │ 4             │
│ 71            │ 4              │ 7             │
│ 13            │ 4              │ 8             │
│ 11            │ 5              │ 53            │
│ 2             │ 5              │ 17            │
│ 16            │ 5              │ 60            │
│ 38            │ 5              │ 35            │
│ 67            │ 6              │ 72            │
│ 10            │ 7              │ 56            │
│ 37            │ 7              │ 51            │
│ 52            │ 8              │ 30            │
│ 63            │ 8              │ 8             │
│ 5             │ 8              │ 0             │
│ 22            │ 8              │ 38            │
│ 12            │ 9              │ 26            │
│ 11            │ 9              │ 30            │
│ 2             │ 9              │ 59            │
│ 45            │ 10             │ 47            │
│ 4             │ 10             │ 3             │
│ 24            │ 10             │ 22            │
│ 51            │ 10             │ 65            │
│ 28            │ 10             │ 6             │
│ 37            │ 11             │ 66            │
│ 64            │ 12             │ 34            │
│ 12            │ 12             │ 4             │
│ 39            │ 12             │ 73            │
│ 6             │ 13             │ 39            │
│ 71            │ 13             │ 62            │
│ 42            │ 13             │ 69            │
│ 59            │ 13             │ 73            │
│ 47            │ 13             │ 18            │
│ 26            │ 13             │ 46            │
│ 14            │ 13             │ 9             │
│ 59            │ 14             │ 68            │
│ 9             │ 14             │ 65            │
│ 16            │ 14             │ 5             │
│ 60            │ 14             │ 16            │
│ 24            │ 14             │ 62            │
│ 22            │ 15             │ 20            │
│ 6             │ 15             │ 47            │
│ 12            │ 15             │ 54            │
│ 24            │ 15             │ 66            │
│ 71            │ 15             │ 38            │
│ 18            │ 15             │ 0             │
│ 50            │ 16             │ 16            │
│ 3             │ 16             │ 71            │
│ 6             │ 17             │ 40            │
│ 0             │ 17             │ 26            │
│ 13            │ 17             │ 16            │
│ 70            │ 17             │ 52            │
│ 57            │ 18             │ 2             │
│ 52            │ 18             │ 48            │
│ 72            │ 19             │ 18            │
│ 55            │ 19             │ 0             │
│ 60            │ 19             │ 15            │
│ 9             │ 20             │ 2             │
│ 14            │ 20             │ 1             │
│ 60            │ 20             │ 30            │
│ 2             │ 20             │ 57            │
│ 13            │ 21             │ 46            │
│ 67            │ 21             │ 30            │
│ 69            │ 22             │ 4             │
│ 9             │ 22             │ 2             │
│ 21            │ 22             │ 20            │
│ 68            │ 22             │ 9             │
│ 2             │ 23             │ 55            │
│ 67            │ 23             │ 10            │
│ 16            │ 23             │ 9             │
│ 55            │ 23             │ 51            │
│ 22            │ 23             │ 16            │
│ 11            │ 23             │ 37            │
│ 47            │ 24             │ 0             │
│ 10            │ 24             │ 42            │
│ 18            │ 25             │ 10            │
│ 5             │ 25             │ 55            │
│ 51            │ 25             │ 46            │
│ 56            │ 25             │ 11            │
│ 60            │ 25             │ 72            │
│ 16            │ 25             │ 61            │
│ 46            │ 26             │ 42            │
│ 42            │ 26             │ 51            │
│ 55            │ 26             │ 16            │
│ 37            │ 26             │ 62            │
│ 7             │ 26             │ 60            │
│ 55            │ 27             │ 72            │
│ 44            │ 27             │ 7             │
│ 21            │ 27             │ 23            │
│ 4             │ 27             │ 14            │
│ 32            │ 28             │ 18            │
│ 62            │ 28             │ 14            │
│ 15            │ 28             │ 40            │
│ 57            │ 28             │ 7             │
│ 16            │ 28             │ 16            │
│ 41            │ 29             │ 41            │
│ 10            │ 29             │ 34            │
│ 60            │ 29             │ 67            │
│ 69            │ 30             │ 14            │
│ 35            │ 30             │ 17            │
│ 2             │ 30             │ 55            │
│ 26            │ 31             │ 18            │
│ 73            │ 32             │ 10            │
│ 29            │ 33             │ 53            │
│ 67            │ 33             │ 40            │
│ 33            │ 34             │ 46            │
│ 27            │ 34             │ 27            │
│ 63            │ 34             │ 43            │
│ 13            │ 35             │ 72            │
│ 27            │ 35             │ 8             │
│ 52            │ 35             │ 70            │
│ 2             │ 35             │ 62            │
│ 35            │ 36             │ 28            │
│ 40            │ 36             │ 47            │
│ 39            │ 36             │ 7             │
│ 13            │ 36             │ 50            │
│ 22            │ 37             │ 37            │
│ 69            │ 37             │ 61            │
│ 40            │ 37             │ 47            │
│ 48            │ 37             │ 8             │
│ 65            │ 37             │ 27            │
│ 17            │ 37             │ 5             │
│ 43            │ 38             │ 67            │
│ 33            │ 38             │ 25            │
│ 14            │ 38             │ 30            │
│ 57            │ 39             │ 18            │
│ 58            │ 39             │ 73            │
│ 72            │ 39             │ 6             │
│ 46            │ 39             │ 30            │
│ 55            │ 40             │ 20            │
│ 19            │ 40             │ 68            │
│ 39            │ 40             │ 62            │
│ 59            │ 40             │ 67            │
│ 48            │ 40             │ 52            │
│ 42            │ 40             │ 63            │
│ 1             │ 40             │ 72            │
│ 15            │ 41             │ 52            │
│ 49            │ 41             │ 38            │
│ 7             │ 42             │ 17            │
│ 50            │ 42             │ 63            │
│ 33            │ 42             │ 58            │
│ 31            │ 42             │ 24            │
│ 0             │ 42             │ 36            │
│ 16            │ 43             │ 68            │
│ 39            │ 43             │ 19            │
│ 69            │ 43             │ 50            │
│ 10            │ 43             │ 36            │
│ 15            │ 43             │ 37            │
│ 17            │ 44             │ 15            │
│ 68            │ 44             │ 45            │
│ 18            │ 44             │ 6             │
│ 13            │ 44             │ 13            │
│ 0             │ 44             │ 53            │
│ 53            │ 44             │ 38            │
│ 73            │ 44             │ 43            │
│ 69            │ 44             │ 12            │
│ 12            │ 45             │ 61            │
│ 63            │ 45             │ 19            │
│ 68            │ 45             │ 30            │
│ 51            │ 45             │ 67            │
│ 23            │ 46             │ 4             │
│ 36            │ 46             │ 34            │
│ 2             │ 46             │ 35            │
│ 2             │ 47             │ 28            │
│ 41            │ 47             │ 3             │
│ 4             │ 47             │ 23            │
│ 55            │ 48             │ 26            │
│ 28            │ 48             │ 29            │
│ 56            │ 49             │ 0             │
│ 54            │ 49             │ 65            │
│ 28            │ 49             │ 17            │
│ 26            │ 49             │ 22            │
│ 8             │ 49             │ 40            │
│ 58            │ 50             │ 45            │
│ 65            │ 50             │ 67            │
│ 54            │ 50             │ 32            │
│ 16            │ 50             │ 72            │
│ 9             │ 50             │ 74            │
│ 46            │ 51             │ 54            │
│ 11            │ 51             │ 66            │
│ 57            │ 51             │ 47            │
│ 47            │ 51             │ 37            │
│ 19            │ 52             │ 41            │
│ 34            │ 53             │ 47            │
│ 13            │ 53             │ 35            │
│ 6             │ 53             │ 52            │
│ 22            │ 53             │ 30            │
│ 21            │ 53             │ 39            │
│ 20            │ 54             │ 10            │
│ 4             │ 54             │ 12            │
│ 32            │ 54             │ 56            │
│ 54            │ 54             │ 67            │
│ 55            │ 54             │ 20            │
│ 4             │ 55             │ 72            │
│ 64            │ 55             │ 2             │
│ 36            │ 56             │ 32            │
│ 24            │ 56             │ 51            │
│ 31            │ 56             │ 69            │
│ 51            │ 56             │ 42            │
│ 38            │ 56             │ 47            │
│ 44            │ 56             │ 37            │
│ 43            │ 56             │ 67            │
│ 14            │ 56             │ 69            │
│ 47            │ 57             │ 54            │
│ 44            │ 57             │ 24            │
│ 31            │ 57             │ 17            │
│ 49            │ 58             │ 28            │
│ 61            │ 58             │ 56            │
│ 21            │ 58             │ 42            │
│ 3             │ 58             │ 32            │
│ 28            │ 60             │ 43            │
│ 49            │ 60             │ 7             │
│ 23            │ 60             │ 44            │
│ 12            │ 60             │ 48            │
│ 16            │ 60             │ 46            │
│ 72            │ 61             │ 11            │
│ 28            │ 61             │ 6             │
│ 37            │ 62             │ 61            │
│ 58            │ 62             │ 43            │
│ 7             │ 62             │ 73            │
│ 11            │ 63             │ 36            │
│ 61            │ 63             │ 32            │
│ 71            │ 63             │ 3             │
│ 28            │ 64             │ 11            │
│ 4             │ 64             │ 20            │
│ 23            │ 64             │ 64            │
│ 18            │ 64             │ 19            │
│ 72            │ 65             │ 21            │
│ 31            │ 65             │ 30            │
│ 23            │ 65             │ 19            │
│ 40            │ 66             │ 43            │
│ 74            │ 66             │ 33            │
│ 31            │ 66             │ 7             │
│ 26            │ 66             │ 47            │
│ 27            │ 66             │ 74            │
│ 37            │ 66             │ 41            │
│ 44            │ 67             │ 66            │
│ 5             │ 67             │ 59            │
│ 63            │ 67             │ 25            │
│ 1             │ 68             │ 72            │
│ 25            │ 68             │ 7             │
│ 70            │ 68             │ 11            │
│ 51            │ 69             │ 48            │
│ 36            │ 70             │ 33            │
│ 58            │ 70             │ 35            │
│ 32            │ 70             │ 40            │
│ 61            │ 70             │ 74            │
│ 21            │ 70             │ 46            │
│ 9             │ 71             │ 20            │
│ 52            │ 71             │ 45            │
│ 20            │ 71             │ 35            │
│ 1             │ 71             │ 26            │
│ 65            │ 71             │ 45            │
│ 32            │ 72             │ 3             │
│ 52            │ 72             │ 62            │
│ 72            │ 72             │ 48            │
│ 54            │ 72             │ 49            │
│ 56            │ 73             │ 3             │
│ 5             │ 73             │ 25            │
│ 71            │ 73             │ 5             │
│ 16            │ 74             │ 46            │
│ 35            │ 74             │ 55            │
│ 3             │ 74             │ 28            │
│ 44            │ 74             │ 42            │
└───────────────┴────────────────┴───────────────┘
&lt;/pre&gt;
&lt;/details&gt;
&lt;hr&gt;
&lt;h1 id=&#34;testing-our-working-model&#34;&gt;Testing our working model&lt;/h1&gt;
&lt;p&gt;So far, we have a strong working theory for how the model might work.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use the attention mechanism to encode &lt;code&gt;(trigram[0], trigram[1])&lt;/code&gt; pairs. So long as &lt;code&gt;trigram[0]&lt;/code&gt; and &lt;code&gt;trigram[1]&lt;/code&gt; are different numbers, the model has two modes of operation. If a trigram is detected, the attention mechanism will move some information about &lt;code&gt;trigram[0]&lt;/code&gt; (via the OV-circuit) into the residual stream. If a trigram is not detected, it will move information about &lt;code&gt;trigram[1]&lt;/code&gt; into the residual stream (i.e. self-attend).&lt;/li&gt;
&lt;li&gt;Based on the contents of the residual stream, predict the continuation. Theoretically this could be done purely with the unembeddings, although there will probably be practical constraints that prevent this and rely on the MLP.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can build this simplified model in code and see how well it predicts different trigrams (versus the actual model). Since we&amp;rsquo;ll always predict trigrams, we&amp;rsquo;ll fake the attention head by defining our own mid-model residual stream:&lt;/p&gt;
&lt;p&gt;\[
x_\text{mid} = W_{OV}\:x_\text{trigram[0]} + x_\text{trigram[1]}
\]&lt;/p&gt;
&lt;p&gt;Where \(x_\text{trigram}\) is the combination of positional and token embeddings for the two tokens. (There are biases to consider, too, but I&amp;rsquo;ve hidden them for simplicity in the above equation.)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;simple_model&lt;/span&gt;(trigram_0, trigram_1, print_results&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    toks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[trigram_0, trigram_1]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    embeddings &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pos_embed(toks) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;embed(toks)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ov_transformed &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (embeddings[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_V[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_V[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_O[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;b_O[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    resid_mid_fake &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ov_transformed &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; embeddings[:, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unembed(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;blocks[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mlp(resid_mid_fake) &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; resid_mid_fake)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model_prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(toks)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; print_results:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Trigram: (&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;trigram_0&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;trigram_1&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, ...)&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Simplified Model Prediction: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;prediction&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Actual Model Prediction: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;model_prediction&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;-&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;30&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; prediction, model_prediction
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;simple_model(&lt;span style=&#34;color:#ae81ff&#34;&gt;55&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;simple_model(&lt;span style=&#34;color:#ae81ff&#34;&gt;34&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;53&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;------------------------------
Trigram: (55, 40, ...)
Simplified Model Prediction: 20
Actual Model Prediction: 20
------------------------------


------------------------------
Trigram: (34, 53, ...)
Simplified Model Prediction: 36
Actual Model Prediction: 47
------------------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that our simplified model gets some predictions correct, but gets others wrong relative to the model - even with the full power of the mlp.&lt;/p&gt;
&lt;p&gt;We can assess our simple model&amp;rsquo;s accuracy against all the trigrams in the dataset. For every trigram the simple model fails to predict, we&amp;rsquo;ll also print it&amp;rsquo;s attention pattern (i.e. attention paid to (previous_token, current_token)).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;simpl_correct &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model_correct &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; trigram &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    simpl_predict, model_predict &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; simple_model(trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], &lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; simpl_predict &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        simpl_correct &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        _, c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_with_cache(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Trigram: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;trigram&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        attn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; c[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.attn.hook_pattern&amp;#39;&lt;/span&gt;][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Attention pattern: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;attn[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;.3f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;, &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;attn[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#e6db74&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;.3f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; model_predict &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        model_correct &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;\n\n&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;Simplified Model accuracy = &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;simpl_correct &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Model accuracy: &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;model_correct &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Click to view output&lt;/b&gt;&lt;/summary&gt;
&lt;pre&gt;&lt;code&gt;Trigram: (34, 53, 47)
Attention pattern: 0.000, 1.000
Trigram: (9, 14, 65)
Attention pattern: 0.000, 1.000
Trigram: (12, 45, 61)
Attention pattern: 0.000, 1.000
Trigram: (7, 42, 17)
Attention pattern: 0.756, 0.244
Trigram: (10, 29, 34)
Attention pattern: 0.000, 1.000
Trigram: (21, 58, 42)
Attention pattern: 0.000, 1.000
Trigram: (54, 49, 65)
Attention pattern: 0.000, 1.000
Trigram: (59, 13, 73)
Attention pattern: 0.687, 0.313
Trigram: (36, 56, 32)
Attention pattern: 0.000, 1.000
Trigram: (63, 45, 19)
Attention pattern: 0.000, 1.000
Trigram: (61, 63, 32)
Attention pattern: 0.000, 1.000
Trigram: (57, 0, 34)
Attention pattern: 0.000, 1.000
Trigram: (54, 50, 32)
Attention pattern: 0.000, 1.000
Trigram: (47, 13, 18)
Attention pattern: 0.680, 0.320
Trigram: (51, 69, 48)
Attention pattern: 0.000, 1.000
Trigram: (24, 56, 51)
Attention pattern: 0.000, 1.000
Trigram: (33, 38, 25)
Attention pattern: 0.000, 1.000
Trigram: (48, 40, 52)
Attention pattern: 0.000, 1.000
Trigram: (65, 37, 27)
Attention pattern: 0.000, 1.000
Trigram: (23, 46, 4)
Attention pattern: 0.002, 0.998
Trigram: (18, 25, 10)
Attention pattern: 0.000, 1.000
Trigram: (50, 42, 63)
Attention pattern: 0.000, 1.000
Trigram: (71, 73, 5)
Attention pattern: 0.000, 1.000
Trigram: (11, 51, 66)
Attention pattern: 0.000, 1.000
Trigram: (71, 63, 3)
Attention pattern: 0.000, 1.000
Trigram: (73, 32, 10)
Attention pattern: 0.000, 1.000
Trigram: (57, 18, 2)
Attention pattern: 0.002, 0.998
Trigram: (21, 22, 20)
Attention pattern: 0.000, 1.000
Trigram: (0, 17, 26)
Attention pattern: 0.000, 1.000
Trigram: (70, 17, 52)
Attention pattern: 0.000, 1.000
Trigram: (56, 25, 11)
Attention pattern: 0.000, 1.000
Trigram: (16, 5, 60)
Attention pattern: 0.000, 1.000
Trigram: (2, 35, 62)
Attention pattern: 0.000, 1.000
Trigram: (26, 66, 47)
Attention pattern: 0.000, 1.000
Trigram: (72, 72, 48)
Attention pattern: 0.000, 1.000
Trigram: (12, 60, 48)
Attention pattern: 0.000, 1.000
Trigram: (57, 51, 47)
Attention pattern: 0.000, 1.000
Trigram: (26, 31, 18)
Attention pattern: 0.000, 1.000
Trigram: (54, 54, 67)
Attention pattern: 0.000, 1.000
Trigram: (1, 71, 26)
Attention pattern: 0.000, 1.000
Trigram: (31, 65, 30)
Attention pattern: 0.000, 1.000
Trigram: (73, 44, 43)
Attention pattern: 0.000, 1.000
Trigram: (21, 27, 23)
Attention pattern: 0.000, 1.000
Trigram: (64, 12, 34)
Attention pattern: 0.000, 1.000
Trigram: (28, 48, 29)
Attention pattern: 0.000, 1.000
Trigram: (24, 15, 66)
Attention pattern: 0.000, 1.000
Trigram: (69, 43, 50)
Attention pattern: 0.000, 1.000
Trigram: (19, 52, 41)
Attention pattern: 0.000, 1.000
Trigram: (60, 19, 15)
Attention pattern: 0.000, 1.000
Trigram: (54, 72, 49)
Attention pattern: 0.000, 1.000
Trigram: (68, 22, 9)
Attention pattern: 0.000, 1.000
Trigram: (64, 1, 8)
Attention pattern: 0.000, 1.000
Trigram: (7, 26, 60)
Attention pattern: 0.000, 1.000
Trigram: (51, 10, 65)
Attention pattern: 0.000, 1.000
Trigram: (21, 70, 46)
Attention pattern: 0.000, 1.000
Trigram: (64, 55, 2)
Attention pattern: 0.000, 1.000
Trigram: (21, 53, 39)
Attention pattern: 0.000, 1.000
Trigram: (39, 12, 73)
Attention pattern: 0.000, 1.000
&lt;/code&gt;&lt;/pre&gt;
&lt;/details&gt;
&lt;pre&gt;&lt;code&gt;Simplified Model accuracy = 0.7906137184115524
Model accuracy: 0.9602888086642599
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Evidently, our simplified attention pattern captures most - but not all - of the nuances of what the model has learned. The ~17% of failed predictions fall into two camps:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Attention is only paid to the current token. (This is the vast majority).&lt;/li&gt;
&lt;li&gt;Some attention is paid to both the current and the previous token (this is quite rare.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, we need to slightly extend our understanding of what attention does in the model:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Attention detects &lt;em&gt;most&lt;/em&gt; trigram pairs, and &lt;em&gt;typically&lt;/em&gt; pays attention to the preceding token if it detects a trigram. Most of the time this is ~100% attention, but occasionally the split of (previous:current) is around 70:30.&lt;/li&gt;
&lt;li&gt;Otherwise, the attention mechanism focuses on just the current token.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Some trigrams are still succesfully predicted, even when the attention mechanism focuses 100% on the current token. For this to work, the model must encode a &lt;code&gt;trigram[1] -&amp;gt; trigram[2]&lt;/code&gt; map and always predict the same completion, regardless of if &lt;code&gt;trigram[0]&lt;/code&gt; is present - that is, the same mechanism as used for repeated trigrams.&lt;/p&gt;
&lt;p&gt;To verify this, lets take a trigram that doesn&amp;rsquo;t excite the attention pattern out of its default state: (39, 12, 73):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Prediction (39, 12) -&amp;gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;39&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Prediction (15, 12) -&amp;gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;15&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Prediction (64, 12) -&amp;gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Prediction (12, 12) -&amp;gt; &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;model(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[&lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;12&lt;/span&gt;]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device))[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Prediction (39, 12) -&amp;gt; 34
Prediction (15, 12) -&amp;gt; 34
Prediction (64, 12) -&amp;gt; 34
Prediction (12, 12) -&amp;gt; 34
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Interestingly, in this case, the model fails to predict several trigrams (12, 12, 4), and (39, 12, 73) because it always predicts the completion for (64, 12, 34).&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s possible this is an artefact of a phase-change in learned behaviour - the model might initially predict completions based only on the most recent token,
and only later in training learns to exploit attention to do a two-part prediction. If this is the case, perhaps some trigrams have not yet transitioned from the single-token prediction regime to the two-token regime.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s also interesting that the model always predicts the completion for (64, 12, 34) - a sequence it could detect with attention - and not for (12, 12, 4), a sequence it could not detect because of the duplicate 12&amp;rsquo;s.&lt;/p&gt;
&lt;p&gt;Other uses of this attention-free mechanism make some sense: (19, 52, 41) is never going to clash with another trigram, because 52 only appears as &lt;code&gt;trigram[1]&lt;/code&gt; in this single example. Still, the prediction is less confident than it could otherwise be.&lt;/p&gt;
&lt;h1 id=&#34;predicting-tokens&#34;&gt;Predicting Tokens&lt;/h1&gt;
&lt;p&gt;We have a fairly good grip on how the model detects trigrams. How, then, does it predict the continuation?&lt;/p&gt;
&lt;p&gt;In a lot of cases, we might expect the model to be able to just pass the output of the attention head to the unembedding matrix, and predict the continuation from there. It seems likely, too, that the MLP will contribute to this process, but the exact split of MLP to direct logit attribution seems unclear.&lt;/p&gt;
&lt;h2 id=&#34;direct-logit-attribution&#34;&gt;Direct Logit Attribution&lt;/h2&gt;
&lt;p&gt;We can try directly projecting \(x_\text{mid}\) into the output space, like so:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;attn_attribution&lt;/span&gt;(trigram_0, trigram_1):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Directly unembed the residual stream
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    after the attention head, i.e. skipping the
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    MLP.&amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    _, c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_with_cache(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[trigram_0, trigram_1]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                names_filter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blocks.0.hook_resid_mid&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unembed(c[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.hook_resid_mid&amp;#39;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;correct &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; trigram &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    attn_attr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; attn_attribution(trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; attn_attr[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        correct &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accuracy = &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;correct &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Accuracy = 0.18050541516245489
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This isn&amp;rsquo;t a great baseline, though. It&amp;rsquo;s not like the MLP doesn&amp;rsquo;t exist. We could try account for it by mean-ablating it, instead of zero-ablating it. We ignore the last sequence position, since that&amp;rsquo;s pretty noisy, and take the mean over our (fairly large) dataset.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mean_mlp &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.hook_mlp_out&amp;#39;&lt;/span&gt;][:, :&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;attn_mean_ablated&lt;/span&gt;(trigram_0, trigram_1):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    _, c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_with_cache(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[trigram_0, trigram_1]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                names_filter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blocks.0.hook_resid_mid&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unembed(c[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.hook_resid_mid&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; mean_mlp)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;correct &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; trigram &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    attn_attr &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; attn_mean_ablated(trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; attn_attr[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item() &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        correct &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accuracy = &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;correct &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Accuracy = 0.2490974729241877
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;linearized-jacobians&#34;&gt;Linearized Jacobians&lt;/h2&gt;
&lt;p&gt;So is ~24.5% a fair accuracy score for how well the attention mechanism predicts tokens? Arguably, no.&lt;/p&gt;
&lt;p&gt;To see why, let&amp;rsquo;s rewrite the MLP contribution:&lt;/p&gt;
&lt;p&gt;\[
\text{MLP}(x_\text{mid}) = A\:x_\text{mid} + b + \mathcal{N}(x_\text{mid})
\]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Where the MLP has been decomposed into a linear contribution \(A x + b\) and a nonlinear contribution \(\mathcal{N}\).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The motivation behind this split is that we understand well how linear systems work, and can see that a fixed linear transformation doesn&amp;rsquo;t add extra &amp;ldquo;logic&amp;rdquo; to the model - instead, it moves information around, and always works the same way, regardless of what information it is moving.&lt;/p&gt;
&lt;p&gt;Conceptually, especially without layer-norm, the linear contribution could be absorbed into surrounding matrices and biases such as \(W_U\) and \(b_U\). So, if we could calculate \(A\) and \(b\), we could get a better understanding of the attention head&amp;rsquo;s predictive power without MLP intervention.&lt;/p&gt;
&lt;p&gt;To do this, we can start by looking at the jacobian between the MLP&amp;rsquo;s inputs and its outputs. For each token, the jacobian maps how much a given upstream vector contributes to a downstream vector.&lt;/p&gt;
&lt;p&gt;That is, for an upstream vector x (such as \(x_\text{mid}\)) and a downstream vector y (such as \(x_\text{post}\)), the jacobian \(J\) is defined as:&lt;/p&gt;
&lt;p&gt;\[
J = \left(\begin{matrix}
\frac{\partial y_1}{\partial x_1} &amp;amp; &amp;hellip; &amp;amp; \frac{\partial y_1}{\partial x_n} \\
\frac{\partial y_2}{\partial x_1} &amp;amp; &amp;hellip; &amp;amp; \frac{\partial y_2}{\partial x_n} \\
\vdots &amp;amp; \vdots &amp;amp; \vdots \\
\frac{\partial y_n}{\partial x_1} &amp;amp; &amp;hellip; &amp;amp; \frac{\partial y_n}{\partial x_n} \\
\end{matrix}\right)
\]&lt;/p&gt;
&lt;p&gt;For a nonlinear function like an MLP, \(J\) needs to be recalculated for each input. Then, for each input, we have&lt;/p&gt;
&lt;p&gt;\[ y = J\:x + b \]&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Where \(b\) is a constant bias (independent of J) that we need to calculate.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;While \(J\) is a function of x (\(J = J(x)\)) for non-linear functions like our MLP,
we hope that we can find some situations where \(J\) doesn&amp;rsquo;t vary much, and can use that as the basis of our linearization.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;set_grad_enabled(&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;attach_jacobian_hooks&lt;/span&gt;(upstream: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_upstream&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          downstream: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_downstream&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          network: t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          stop_idx_downstream: int,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          start_idx_downstream&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Calculate the jacobian matrix between an upstream vector and
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       a downstream vector. You must run a forward pass through the model
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       before the gradients tensor will be populated.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       upstream - The upstream vector.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       downstream - The downstream vector. Does not need to have the same
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;                    shape as `upstream`.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       network - The model that contains both `upstream` and `downstream`.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       stop_idx_downstream (required) and
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       start_idx_downstream(optional)-
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            The jacobian will be calculated for the downstream vector elements
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            as downstream[ start_idx_downstream : stop_idx_downstream ]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       Returns: (get_jacobian(), get_upstream_vec(), remove_hooks())
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    n_outputs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stop_idx_downstream &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start_idx_downstream
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    capture &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; {}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;setup_upstream_hook&lt;/span&gt;(module, inp, out):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        capture[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;upstream_vec&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; out
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(out,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                            &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch ... d_hidden -&amp;gt; (batch d_out) ... d_hidden&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                            d_out&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_outputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Setup a do-nothing vector to let us extract the gradients&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# of this intermediate layer.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; out&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        capture[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;upstream_grad&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros(output_shape, requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;out&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;device)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; out &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; capture[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;upstream_grad&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;setup_downstream_hook&lt;/span&gt;(module, inp, out):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Extract the jacobian dimension we snuck&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# into the batch dimension.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rearrange(out,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(batch d_out) ... d_hidden -&amp;gt; batch ... d_out d_hidden&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               d_out&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_outputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        network&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zero_grad()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        out[&lt;span style=&#34;color:#f92672&#34;&gt;...&lt;/span&gt;, start_idx_downstream : stop_idx_downstream]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(n_outputs, device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;out&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;device)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;repeat(&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;out&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[:&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    remove_upstr_hook &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; upstream&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;register_forward_hook(setup_upstream_hook)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    remove_downstr_hook &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; downstream&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;register_forward_hook(setup_downstream_hook)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;remove_hooks&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        remove_upstr_hook&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;remove()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        remove_downstr_hook&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;remove()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_jacobian&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; capture&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;upstream_grad&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;RuntimeError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Gradients must be initialized by &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;running a forward pass through &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;the model before they can be  &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;accessed.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        rearranged &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rearrange(capture[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;upstream_grad&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(batch d_out) ... d_in -&amp;gt; batch ... d_out d_in&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                d_out&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;n_outputs)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; rearranged
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;get_upstream_vec&lt;/span&gt;():
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; capture&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;upstream_vec&amp;#34;&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;raise&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;RuntimeError&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Vectors must be initialized by &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;running a forward pass through &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;the model before they can be  &amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                               &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;accessed.&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; capture[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;upstream_vec&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; get_jacobian, get_upstream_vec, remove_hooks
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;calc_jacobian&lt;/span&gt;(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    upstream_vec: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_up&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    downstream_vec: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_down&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model: t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;nn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Module,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tokens: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch seq 1&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    ) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch seq d_down d_up&amp;#34;&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      Return the jacobian,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;        J = d(downstream_vec)/d(upstream_vec)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      The jacobian will be calculated across the batches and sequences
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      in `tokens`.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      upstream_vec: Vector in `model` upstream (i.e. before) `downstream_vec` in
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;                    `model`&amp;#39;s forward pass.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      downstream_vec: Vector in `model`
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;      model: The torch neural net containing `upstream_vec` and `downstream_vec`,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;             and accepting `tokens` for its forward pass.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;  &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  jacs &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad_(&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(tokens&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      get_jacobian, get_upstream_vec, remove_hooks &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; attach_jacobian_hooks(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          upstream_vec, downstream_vec, model, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cfg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d_model
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      &lt;span style=&#34;color:#75715e&#34;&gt;# Run a forward pass through the model&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      model(tokens[i: i &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      jacs &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; [get_jacobian()]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;      remove_hooks()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;requires_grad_(&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cat(jacs)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Here, we&amp;rsquo;ll run the full set of tokens through the model, and generate a jacobian between \(x_\text{mid}\) and \(x_\text{post}\) for each (batch, seq) combination.&lt;/p&gt;
&lt;p&gt;Because we&amp;rsquo;re interested in the default behaviour of the MLP, we need to subtract off the identity from any jacobians we get, because of the residual connection, i.e.&lt;/p&gt;
&lt;p&gt;\[ x_\text{post} = \text{MLP}(x_\text{mid}) + x_\text{mid} \]&lt;/p&gt;
&lt;p&gt;So, we define our jacobians as&lt;/p&gt;
&lt;p&gt;\[ J_\text{MLP} = J_\text{mid -&amp;gt; post} - \mathbb{I}\]&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll then plot these jacobians to observe how the MLP modifies its input. The following plot is a series of squares, of shape (d_model, d_model). These are tiled in the x-direction by batch, and in the y-direction by sequence position.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve also clipped the range displayed to lie between -1 and 1, because some jacobians are extremely out-of-family.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;jacobian &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; calc_jacobian(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;blocks[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hook_resid_mid, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;blocks[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;hook_resid_post, model, dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;toks) &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;eye(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cfg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;d_model, device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;fig, ax &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;subplots(figsize&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;20&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;16&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;num_seq &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;25&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;num_batch &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; ax&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;rearrange(jacobian[:num_batch, :num_seq], &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;batch seq d_res1 d_res2 -&amp;gt; (seq d_res1) (batch d_res2)&amp;#34;&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu(), vmin&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, vmax&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(f)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Jacobian vs (batch, sequence)&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Batch&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Seq&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xticks(ticks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(num_batch)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;jacobian&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;], labels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(num_batch))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;yticks(ticks&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(num_seq)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;jacobian&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], labels&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(num_seq))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_31_0.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;observations-about-the-jacobian&#34;&gt;Observations about the Jacobian&lt;/h2&gt;
&lt;p&gt;Looking at the plot, there are some interesting observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The MLP definitely appears to have a default behavior. Different tiles (with a few clear exceptions) look remarkably similar to one another&lt;/li&gt;
&lt;li&gt;There are a few cases where the MLP behaves extremely differently. This turns out to be (generally) in cases where a trigram is present. These jacobians are orders of magnitude larger than the typical jacobians.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looking more closely at a single &amp;ldquo;default&amp;rdquo; jacobian (in this case, batch=0, seq=0), we can actually make out some features:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(jacobian[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Jacobian (batch=0, seq=0)&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(f)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_33_0.png&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The MLP slightly erases a number of leading-diagonal terms. Given this, we should probably expect direct logit attribution of upstream vectors to perform worse than on a model trained without this MLP.&lt;/li&gt;
&lt;li&gt;The MLP isn&amp;rsquo;t just erasing data, it&amp;rsquo;s &lt;em&gt;moving&lt;/em&gt; data. There are some clear hotspots ((12, 2) in the jacobian, for example) that repeat amongst different sequence positions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It&amp;rsquo;s also important to remember that once we fix a jacobian (i.e. we &lt;em&gt;linearize the MLP&lt;/em&gt;), the jacobian can no longer add extra information to the residual stream, and instead only moves it around.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s an appropriate jacobian to fix? We could try the mean:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;jac_mean &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; jacobian&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mean(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Mean Jacobian&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(jac_mean&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(f)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.colorbar.Colorbar at 0x7f4e57dac3d0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_35_1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;However, this is not an especially principled choice - when the MLP does activate, the jacobian is changed dramatically. Taking the mean includes the influence of these very large activations, even if we don&amp;rsquo;t really want to.&lt;/p&gt;
&lt;p&gt;Instead, we can try the median:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;jac_median &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; jacobian&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;median(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;median(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;figure()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Median Jacobian&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imshow(jac_median&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;colorbar(f)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.colorbar.Colorbar at 0x7f4e4a0054b0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_37_1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;This looks a lot more like our &lt;code&gt;jacobian[0, 0]&lt;/code&gt; (and other unactivated MLP jacobians)!&lt;/p&gt;
&lt;p&gt;So, now that we have \(J\), we just need to calculate our bias, \(b\), since the MLP ignores constants. To do so, we rearrange the definition of the jacobian:&lt;/p&gt;
&lt;p&gt;\[
\begin{align}
y &amp;amp;= J x + b \\
b &amp;amp;= y - J x \\
&amp;amp; = x_\text{post} - J x_\text{mid} \\
\end{align}
\]&lt;/p&gt;
&lt;p&gt;Using similar justification to before, we pick the median bias:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;projected &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(jacobian, cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.hook_resid_mid&amp;#39;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;... seq d_model_out d_model_in, ... seq d_model_in -&amp;gt; ... seq d_model_out&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;bias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.hook_mlp_out&amp;#39;&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; projected)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;median(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;median(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;testing-the-linearization&#34;&gt;Testing the Linearization&lt;/h1&gt;
&lt;p&gt;So, now that we&amp;rsquo;ve frozen the MLP in linearized form, do we get better predictions from the attention mechanism?&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;attention_predict&lt;/span&gt;(trigram):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    _, c &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;run_with_cache(t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]]], device&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;device),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                                names_filter&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;blocks.0.hook_resid_mid&amp;#34;&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    resid_after_attn &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; c[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.hook_resid_mid&amp;#39;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    resid_post_approx &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; bias &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; resid_after_attn &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; einops&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;einsum(jac_median, resid_after_attn,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                          &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_model_out d_model_in, ... seq d_model_in -&amp;gt; ... seq d_model_out&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;unembed(resid_post_approx)[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(dim&lt;span style=&#34;color:#f92672&#34;&gt;=-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;item()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;correct &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; trigram &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    prediction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; attention_predict(trigram)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; prediction &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; trigram[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        correct &lt;span style=&#34;color:#f92672&#34;&gt;+=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Accuracy = &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;correct &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; len(dataset&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trigrams)&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Accuracy = 0.3104693140794224
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yes!!&lt;/p&gt;
&lt;p&gt;By better accounting for the passive behaviour of the MLP, we go from ~25% accuracy to ~31% accuracy using only the attention mechanism&amp;rsquo;s logic (since jac_median and bias are just frozen, linear transformations.)&lt;/p&gt;
&lt;p&gt;In relative terms, we discovered ~25% more performance from the attention mechanism. It&amp;rsquo;s still a long way from explaining the entirety of the model&amp;rsquo;s performance, but it&amp;rsquo;s a step.&lt;/p&gt;
&lt;h1 id=&#34;how-the-model-predicts-the-rest-of-the-tokens&#34;&gt;How the model predicts the rest of the tokens&lt;/h1&gt;
&lt;p&gt;Given what we know about the rest of the model, we can hypothesize the following about the MLP:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It reads from the stream written to by the OV circuit, as well as the current token stream.&lt;/li&gt;
&lt;li&gt;It uses the results from these two streams to retrieve the correct completion. From this, it writes into the unembedding direction corresponding to this conclusion to boost the logits, and potentially even supresses other likely completions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;An attempt to analyse the MLP using a sparse transcoder was made. In this case, a transcoder seemed like it could work well because we have clearly defined, discrete inputs (e.g. 16 in position 0, 43 in position 1) which lead to discrete outputs
(e.g. predict 68).&lt;/p&gt;
&lt;p&gt;However, although a number of different attempts were made (varying transcoder widths, warm-up vs cold-start for learning rate and l1 penalty, varieties of learning rates, batch sizes, resampling frequencies etc.), no transcoders emerged that provided cleanly interpretable features.&lt;/p&gt;
&lt;p&gt;It seems likely that good results could come from pursuing this further, but the results obtained in attempts thus far are uninteresting.&lt;/p&gt;
&lt;h2 id=&#34;one-last-trick&#34;&gt;One last trick&lt;/h2&gt;
&lt;p&gt;One trick we have left is to look at what subspaces the MLP reads in. The MLP has dimension 20, the model (residual stream) has dimension 32, and the attention head has dimension 16. This means that the MLP could fully read from the output space of the attention head, but cannot read the full token stream.&lt;/p&gt;
&lt;p&gt;We can observe how it weights these two competing priorities based on the distance between subspaces. This isn&amp;rsquo;t guaranteed to be meaningful for reasons I &lt;a href=&#34;https://www.willsnell.com/posts/math_composition/&#34;&gt;wrote about here&lt;/a&gt;, but might still give us some idea.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; dataclasses &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; dataclass
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;@dataclass&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;SubspaceMetrics&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  theta: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_hidden&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  cos_theta: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_hidden&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  principal_vecs_out: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_model d_hidden&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  principal_vecs_in: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_model d_hidden&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  U: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_head d_head&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  Vh: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_head d_head&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;qr_svd&lt;/span&gt;(out_mat: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_hidden d_model&amp;#34;&lt;/span&gt;],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           in_mat: Float[Tensor, &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;d_model d_hidden&amp;#34;&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;           ) &lt;span style=&#34;color:#f92672&#34;&gt;-&amp;gt;&lt;/span&gt; SubspaceMetrics:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&amp;#34;&amp;#34;Purpose:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           Calculate statistics between the two subspaces
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           spanned by the matrices `out_mat` and `in_mat`,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           These matrices should write to/read from a
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           common space of dimension `d_model`.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           Calculate the principal vectors of the subspaces
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           spanned by out_mat and in_mat.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           Also return the angle between each set of principal
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           vectors (aka the principal angles, theta).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           theta[0] &amp;lt;= ... &amp;lt;= theta[-1]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       Returns:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           (theta, cos(theta), principal_vectors_out_mat,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;            principal_vectors_in_mat, U, Vh)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       Follows the procedure in
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       https://helper.ipam.ucla.edu/publications/glws1/glws1_15465.pdf
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;       Assumptions:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           Assumes the first n columns in a
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           m x n (m &amp;gt;= n) matrix are linearly
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           independent.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           E.g. in W_O.T, shape [768, 64],
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           the first 64 columns should be
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;           linearly independent.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Q is the set of orthonormal basis vectors&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# for the subspace spanned by each matrix.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    q_out, r_out &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;qr(out_mat&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    q_in, r_in &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;qr(in_mat)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Compute the deviation between the&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# two subspaces using SVD.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    U, S, Vh &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;svd(q_out&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; q_in)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Principal vectors let us know what directions were&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# chosen to calculate theta. That is, each are a set&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# of basis vectors that span the spaces of the&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# respective matrices (in or out) and are most closely&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# aligned to each other.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    principal_vectors_out_mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; q_out &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; U
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    principal_vectors_in_mat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; q_in &lt;span style=&#34;color:#f92672&#34;&gt;@&lt;/span&gt; Vh&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;transpose(&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(S)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; SubspaceMetrics(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        t&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(S),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          S,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          principal_vectors_out_mat,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          principal_vectors_in_mat,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          U,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          Vh
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    )
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;res &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; qr_svd(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_O[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;blocks[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;mlp&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;W_in)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(res&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos_theta&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;detach()&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cpu())
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Angle Between Attention Head (writing) and MLP (reading)&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;OV Dimension&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Cos(theta) between subspaces&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;f&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;cos(theta) = &lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;{&lt;/span&gt;res&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos_theta&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tolist()&lt;span style=&#34;color:#e6db74&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_45_0.png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cos(theta) = [1.0000001192092896, 1.0, 0.9999998807907104, 0.9999998807907104, 0.9893388152122498, 0.9778618216514587, 0.9700286984443665, 0.9570831656455994, 0.8961935639381409, 0.8844886422157288, 0.7993403673171997, 0.745817244052887, 0.7342832088470459, 0.5622190237045288, 0.35370132327079773, 0.18341064453125]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, the MLP pays very close attention to the first 4 dimensions output by the OV circuit, and then pays increasingly less attention. There&amp;rsquo;s a sharp dropoff around the 9th dimension, which implies the MLP&amp;rsquo;s focus is (very crudely) around 50% on the OV circuit and 50% on the current stream, assuming the residual stream has similar variance in all directions.&lt;/p&gt;
&lt;p&gt;To verify this assumption, we can look at the residual stream directly:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;var_resid_mid &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; cache[&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;blocks.0.hook_resid_mid&amp;#39;&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;var(dim&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;plot(var_resid_mid)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;title(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Residual Stream Variance&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;xlabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Residual Stream Dimension&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;ylabel(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Variance&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;plt&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;show()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img alt=&#34;png&#34; src=&#34;https://willsnell.com/posts/trigrams/output_47_0.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;So, while the residual stream is not equal in magnitude for all directions, everything is within an order of magnitude. For this very crude subspace measurement, it&amp;rsquo;s probably close enough to uniform that we can use subspace angles to quantify how much focus the MLP is placing in different subspaces.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Entropy and Information Theory</title>
      <link>https://willsnell.com/posts/entropy/</link>
      <pubDate>Mon, 18 Nov 2024 13:45:34 +1300</pubDate>
      
      <guid>https://willsnell.com/posts/entropy/</guid>
      <description>Learning about Information Theory can be fun! Join me as we explore what entropy and information mean, intuitively.</description>
      <content>&lt;script src=&#34;./mi_charts.js&#34; type=&#34;module&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;./knn.js&#34; type=&#34;module&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;./observer.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://cdn.plot.ly/plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;link rel=&#34;preconnect&#34; href=&#34;https://fonts.googleapis.com&#34;&gt;
&lt;link rel=&#34;preconnect&#34; href=&#34;https://fonts.gstatic.com&#34; crossorigin&gt;
&lt;link href=&#34;https://fonts.googleapis.com/css2?family=Silkscreen:wght@400;700&amp;display=swap&#34; rel=&#34;stylesheet&#34;&gt;
&lt;link href=&#34;./charts.css&#34; rel=&#34;stylesheet&#34;&gt;
&lt;p&gt;&lt;em&gt;Photo by &lt;a href=&#34;https://unsplash.com/@adrianikoos?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash&#34;&gt;Adria Berrocal Forcada&lt;/a&gt; &lt;em&gt;on&lt;/em&gt; &lt;a href=&#34;https://unsplash.com/photos/an-old-phone-is-hanging-on-a-wall-o7PxpvonuRQ?utm_content=creditCopyText&amp;utm_medium=referral&amp;utm_source=unsplash&#34;&gt;unsplash&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Information theory - and in particular, entropy - can be quite an intimidating topic.
It doesn&amp;rsquo;t have to be. If you can develop some key intuitions for the topic, a lot of the concepts
become a lot simpler than they might initially seem.&lt;/p&gt;
&lt;p&gt;There are three main sections to this article. If you already have a solid grasp on any of them, feel
free to skip ahead! Each section should hopefully be a bit of fun, though, so don&amp;rsquo;t feel obliged to.&lt;/p&gt;
&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://willsnell.com/posts/entropy/#what-is-entropy&#34;&gt;What is Entropy?&lt;/a&gt; - If you&amp;rsquo;re new to information theory&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://willsnell.com/posts/entropy/#entropy-for-continuous-numbers&#34;&gt;Entropy for Continuous Numbers&lt;/a&gt; - If terms like &amp;ldquo;differential entropy&amp;rdquo;
aren&amp;rsquo;t familiar.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://willsnell.com/posts/entropy/#mutual-information&#34;&gt;Mutual Information and Conditional Mutual Information&lt;/a&gt; - If you&amp;rsquo;re interested in some
more advanced concepts, with a focus on signal processing.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;what-is-entropy&#34;&gt;What is Entropy?&lt;/h1&gt;
&lt;p&gt;Let&amp;rsquo;s dive right in&amp;hellip; by playing the lottery!&lt;/p&gt;
&lt;p&gt;Each round, you get to pick one number on the ticket below:&lt;/p&gt;
&lt;div style=&#34;width: 100%; margin: auto; margin-bottom: -200px;&#34;&gt;
    &lt;object id=&#34;ticket&#34; type=&#34;image/svg+xml&#34; data=&#34;lottery_ticket.svg&#34; height=&#34;500px&#34;&gt;&lt;/object&gt;
    &lt;div id=&#34;ticket numbers&#34; style=&#34;position: relative; top: -340px; left: 86px; 
        width: 202px; height: 182px; display: flex; flex-wrap: wrap;&#34;&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Once you&amp;rsquo;ve picked the number, you can get the results of
the lottery on the machine below.&lt;/p&gt;
&lt;p&gt;There are two possible outcomes,
and so I only need to send you a single &lt;em&gt;bit&lt;/em&gt; of information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1, if your ticket is a winner,&lt;/li&gt;
&lt;li&gt;0, otherwise&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It&amp;rsquo;s tiiiiiimmmmmme to play the lottery! Each press of the button below
will pick a &lt;strong&gt;new random number&lt;/strong&gt;, and give you the results.&lt;/p&gt;
&lt;p&gt;&lt;object id=&#34;machine&#34; type=&#34;image/svg+xml&#34; data=&#34;lottery_machine.svg&#34; style=&#34;margin-bottom: -80px&#34;&gt;&lt;/object&gt;&lt;/p&gt;
&lt;script src=&#34;./lottery.js&#34;&gt;&lt;/script&gt;
&lt;p&gt;Did you win?&lt;/p&gt;
&lt;p&gt;Chances are, you didn&amp;rsquo;t. You can keep playing until you do, but be warned,
it might take a while.&lt;/p&gt;
&lt;p&gt;It might seem like each time you played, I would send you the same amount of information. Either you won or you lost,
and both times you learned a single bit of information.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;But that&amp;rsquo;s not the whole story.&lt;/em&gt; To see why, let&amp;rsquo;s modify the game slightly. This time,
I want you to tell me &lt;strong&gt;the winning number&lt;/strong&gt; for each round.
Is this possible? Most of the time - no. If your ticket lost, you can eliminate
1 of the 20 numbers, but there&amp;rsquo;s still 19 to pick from!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;However&lt;/strong&gt;, if you &lt;strong&gt;won&lt;/strong&gt;, you immediately know which number was picked. More
than that, you also know all the 19 numbers that weren&amp;rsquo;t picked!&lt;/p&gt;
&lt;p&gt;The key intuition for understanding entropy is exactly this: the &lt;strong&gt;more likely&lt;/strong&gt; a piece of information
is, the &lt;strong&gt;less information&lt;/strong&gt; it carries. Formally, we define &lt;strong&gt;Information Content&lt;/strong&gt;, sometimes called &lt;em&gt;surprisal&lt;/em&gt;, as \(\frac{1}{P}\),
where \(P\) is the probability of the event happening. Actually, we need to take the &lt;em&gt;log&lt;/em&gt; of this term
to get the exact definition of Information Content:&lt;/p&gt;
\[
\begin{align}
            I(x) &amp;= \log_2{\frac{1}{P(x)}} \\
                 &amp;= -\log_2{P(x)}
\end{align}
\]&lt;p&gt;&lt;em&gt;Where \(P(x)\) is the probability of event \(x\) occuring, and \(I(x)\) is measured in bits (sometimes
called Shannons in this context).&lt;/em&gt;&lt;/p&gt;
&lt;h4 id=&#34;why-do-we-need-to-take-the-log&#34;&gt;Why do we need to take the log?&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s think about the lottery. If we had a winning ticket (with probability
\(P = \frac{1}{20}),\) we only need to be sent a single bit to know that we won.
When we get that message, we immediately know twenty things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the 1 winning number&lt;/li&gt;
&lt;li&gt;the 19 numbers that did not win&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If I wanted to just send you the winning number directly, and we were using binary,
we&amp;rsquo;d need somewhere between 4 bits (\(2^4 = 16\))
and 5 bits (\(2^5 = 32\)) for me to specify which number has won.&lt;/p&gt;
&lt;p&gt;So why do we take the log? Because it takes the &lt;strong&gt;number&lt;/strong&gt; of things we&amp;rsquo;ve learned, and
converts it into the &lt;em&gt;bits of information&lt;/em&gt; we&amp;rsquo;d need to represent that many things.&lt;/p&gt;
&lt;p&gt;In our example, the information content of a winning ticket is:&lt;/p&gt;
\[
\begin{align}
        I(\text{win}) &amp;= \log_2{\frac{1}{1/20}} \\
                      &amp;\approx 4.322\;\text{bits}
\end{align}
\]&lt;p&gt;So in the winning case, I send you a 1-bit message, and with it you&amp;rsquo;ve learned about 4.32 bits
of &lt;em&gt;information&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;a-free-lunch&#34;&gt;A Free Lunch?&lt;/h3&gt;
&lt;p&gt;This might seem too good to be true - greater than perfect compression of more than 4 bits of information
into a single bit message! Of course, this isn&amp;rsquo;t the case.&lt;/p&gt;
&lt;p&gt;The winning lottery ticket carries so much information &lt;strong&gt;because&lt;/strong&gt; it is
so unlikely. Similarly, a losing lottery ticket tells us very little &lt;strong&gt;because&lt;/strong&gt; it&amp;rsquo;s such a common occurrence.
If you can internalize this notion - rare messages carry more information - you can understand entropy
intuitively.&lt;/p&gt;
&lt;h2 id=&#34;defining-entropy&#34;&gt;Defining Entropy&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ve talked about &lt;em&gt;information content&lt;/em&gt; so far, but I promised to explain entropy. Fortunately,
the jump from information content to entropy is almost trivial. We can define entropy as&lt;/p&gt;
\[
        H(X) := \mathbb{E}[I(X)]
\]&lt;p&gt;\(\mathbb{E}\) is the expected value - the mean - and \(I(X)\) is what we defined before,
the information
content. So the entropy \(H(X)\) is simply the average amount of information contained in all the
possible messages we could receive.&lt;/p&gt;
&lt;p&gt;How do we calculate the average? After all, some messages are much more likely than others. Easy!
We just multiply the &lt;em&gt;information&lt;/em&gt; of each message by the &lt;em&gt;likelihood&lt;/em&gt; of receiving that message.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s calculate the entropy of the single-bit messages I send you, communicating
the results of the lottery:&lt;/p&gt;
\[
        H(\text{Lottery}) = P(\text{win}) I(\text{win}) + P(\text{lose}) I(\text{lose}) \\
\]\[
                    I(x)  = \log_2{\frac{1}{P(x)}} = -\log_2{P(x)} \\
\]\[
H(\text{Lottery}) = -P(\text{win}) \log_2{P(\text{win})} \\
                    - P(\text{lose}) \log_2{P(\text{lose})}
\]&lt;p&gt;We know that \(P(\text{win}) = \frac{1}{20}\) and \(P(\text{lose}) = \frac{19}{20}\), so
the entropy of the set of messages we could receive is:&lt;/p&gt;
\[
\begin{align}
            H(\text{Lottery}) &amp;= -\frac{1}{20} \log_2\left(\frac{1}{20}\right) 
            -\frac{19}{20}\log_2\left(\frac{19}{20}\right) \\
                              &amp;\approx 0.216... +\;0.070... \\
                              &amp;\approx 0.286...
\end{align}
\]&lt;p&gt;There are a few key takeaways here:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We&amp;rsquo;re receiving, on average, a lot less than 1 bit of information per message.
Our communication scheme is wasting most of its capacity.&lt;/li&gt;
&lt;li&gt;Roughly 75% of the entropy comes from the rare &lt;em&gt;win&lt;/em&gt; message. The information
carried by each &lt;em&gt;lose&lt;/em&gt; message is much, much lower.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Finally, let&amp;rsquo;s introduce the standard formula for entropy. By now, it shouldn&amp;rsquo;t be
too intimidating. Remember, all it says is that entropy is the average information
content carried by all the messages we could send/receive:&lt;/p&gt;
\[
            H(X) := - \sum_{x\in X} p(x) \log_2 {p(x)}
\]&lt;p&gt;&lt;em&gt;Where \(x \in X\) just means all the messages \(x\) in the collection of messages that
could be transmitted, \(X\). In the lottery example, \(X = [0, 1]\).&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;another-entropy-example&#34;&gt;Another Entropy Example&lt;/h3&gt;
&lt;p&gt;To really solidify the concept, lets look at a different binary channel. We can
receive the message 0 or 1, like in the lottery. However, let&amp;rsquo;s say that both
messages are equally likely: \(P(0) = P(1) = \frac{1}{2}\).&lt;/p&gt;
&lt;p&gt;Then,&lt;/p&gt;
\[
\begin{align}
            H(X) &amp;= -\left(\frac{1}{2}\log_2\left(\frac{1}{2}\right) + \frac{1}{2}\log_2\left(\frac{1}{2}\right)\right) \\
                 &amp;= -\log_2\left(\frac{1}{2}\right) \\
                 &amp;= \log_2 (2) \\
                 &amp;= 1
\end{align}
\]&lt;p&gt;In other words, our 1-bit channel has an entropy of 1 bit &lt;em&gt;if&lt;/em&gt; the two messages 0 and 1 are
equally likely. If one message is more likely than another, our entropy would decrease, meaning
we would be transferring less useful information per bit, on average.&lt;/p&gt;
&lt;p&gt;Without proving this, we can show its consequences. Let&amp;rsquo;s imagine our 1-bit channel now
only ever sends the message &lt;em&gt;1&lt;/em&gt;. If you will always (as in &lt;em&gt;always&lt;/em&gt; always) receive the same message, you can&amp;rsquo;t
glean anything useful from it. The entropy of this situation would be 0.&lt;/p&gt;
&lt;h2 id=&#34;consequences&#34;&gt;Consequences&lt;/h2&gt;
&lt;p&gt;What&amp;rsquo;s interesting about entropy is that it says nothing about the &lt;em&gt;contents&lt;/em&gt; of the message. In the lottery
example, we could make the winning message a &lt;em&gt;0&lt;/em&gt; and the losing message a &lt;em&gt;1&lt;/em&gt;, and nothing would change.
At no point does the actual message being sent factor into the calculation. Instead, all that matters
when calculating information content and entropy is &lt;em&gt;probability&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This consequence also means that we are free to waste gratuitous amounts of capacity, if we want to,
based on how we &lt;em&gt;encode&lt;/em&gt; our messages. For example, we could send the strings &amp;ldquo;WIN&amp;rdquo; and &amp;ldquo;LOSE&amp;rdquo;,
using 3 bytes (24 bits) and 4 bytes (32 bits) respectively. Our channel would still only have
\(\approx 0.286\) bits of entropy, though.&lt;/p&gt;
&lt;h4 id=&#34;compression&#34;&gt;Compression&lt;/h4&gt;
&lt;p&gt;For our exact case (communicating the results of a lottery), our 1-bit channel is actually optimal.
We need to send something each time the lottery is drawn - otherwise, how would the receiver know
that they&amp;rsquo;d received the results? - and the smallest amount of information we can send is a single bit.&lt;/p&gt;
&lt;p&gt;This encoding scheme is quite suboptimal for our other problem, though: if we want to know
what number was drawn, we&amp;rsquo;d have to receive up to 19 losing bits (or 1 winning bit) before we
were certain we knew the winning number. If we wanted to optimize our scheme for transmission of the winning
number, we could use a 5 bit scheme &lt;em&gt;(or perhaps a variable-length 4 bit / 5 bit scheme)&lt;/em&gt; to
just transmit the number directly. But if our receiver is just going to compare the winning number
against the number on the ticket to see if we&amp;rsquo;ve won, we&amp;rsquo;ve wasted 3 or 4 bits.&lt;/p&gt;
&lt;p&gt;This is an example of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pigeonhole_principle&#34;&gt;Pigeonhole principle&lt;/a&gt;:
any time we losslessly compress messages on a channel, some kinds of messages get longer, and others get
shorter.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(It&amp;rsquo;s called the Pigeonhole principle because if you have &lt;strong&gt;n&lt;/strong&gt; pigeonholes, you can&amp;rsquo;t put &lt;strong&gt;n+1&lt;/strong&gt; messages
in them without putting at least two messages in the same hole. [Pigeonholes are a kind of
mailbox, although I like the idea of literal pigeons better.] In our case, if we only have 2 messages
and 20 possible winning numbers, 19 of our numbers end up in one kind of message, and only one ends up in the other.)&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;practical-applications&#34;&gt;Practical Applications&lt;/h1&gt;
&lt;p&gt;Information Theory is widely used for analyzing all kind of communication. In his seminal paper -
&lt;a href=&#34;https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf&#34;&gt;A Mathematical Theory of Communication&lt;/a&gt; -
Claude Shannon applied the ideas to telecommunication (at the time, the telegraph and the teletype were dominant), artificial
languages &lt;em&gt;(sequences of characters such as ABBDABCD)&lt;/em&gt;,
as well as to communication in human languages like English.&lt;/p&gt;
&lt;p&gt;Like in our lottery example, real messages written in human language
have &lt;em&gt;much less entropy&lt;/em&gt; than could theoretically be transmitted with the same set of symbols (for example, the English alphabet.)
We can think of this as &lt;em&gt;redundancy&lt;/em&gt; - what fraction of the letters in a message we could delete
before the message lost its original meaning.&lt;/p&gt;
&lt;p&gt;As Shannon wrote,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The redundancy of a language is related to the existence of crossword puzzles. If the redundancy is
zero any sequence of letters is a reasonable text in the language and any two-dimensional array of letters
forms a crossword puzzle. If the redundancy is too high the language imposes too many constraints for large
crossword puzzles to be possible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For this article, however, we will focus on &lt;em&gt;signal processing&lt;/em&gt;. My claim is that entropy can be explained
visually, and that this visualization provides good intuitive insights. My hope is that
bringing the underlying geometry to the forefront will make it clearer what is going on than
bombarding you with maths would.&lt;/p&gt;
&lt;p&gt;To motivate what would otherwise
be a very abstract journey, we will examine the function \(Y\). Our goal is to try and determine
whether \(Y\) is related to \(X_1\) and \(X_2\), using only
samples from \(X_1\), \(X_2\), and \(Y\). We define these signals as such:&lt;/p&gt;
\[
\begin{align}
            X_1 &amp;\sim \mathcal{U}(0, 20) \\
            X_2 &amp;\sim \mathcal{U}(-5, 5) \\
            Y &amp;= \sin(X_1) \sin(X_2)\;X_1\;X_2\\
\end{align}
\]&lt;p&gt;Where \(\mathcal{U}(a, b)\) denotes a uniform distribution between a and b.&lt;/p&gt;
&lt;p&gt;\(Y\) is a deterministic function of \(X_1\) and \(X_2\), and so we should be able to figure
out, from samples of the three distributions, that they are all correlated.&lt;/p&gt;
&lt;p&gt;If we treat our three distributions as timeseries signals, we can sample from them and
plot their values over time:&lt;/p&gt;
&lt;div id=&#34;timeseries-plot&#34;&gt;&lt;/div&gt;
&lt;p&gt;This just looks like a collection of colourful noise. Instead, we can plot each trio of samples as a point in space,
i.e. \((x_1, x_2, y)_t\) for each timestep \(t\):&lt;/p&gt;
&lt;div id=&#34;teaser-plot&#34;&gt;&lt;/div&gt;
&lt;p&gt;This function was chosen because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It&amp;rsquo;s completely deterministic if you know \(X_1\) and \(X_2\).&lt;/li&gt;
&lt;li&gt;It&amp;rsquo;s decidedly non-linear. There are periodic functions, terms
multiplied together, but not a linear term in sight. It&amp;rsquo;s a mess!&lt;/li&gt;
&lt;li&gt;The underlying distributions are not normally distributed.
A lot of successful techniques assume underlying normal distributions,
but we want a technique that doesn&amp;rsquo;t &lt;em&gt;require&lt;/em&gt; those assumptions hold
to be accurate.&lt;/li&gt;
&lt;li&gt;It looks a bit like a sideways christmas-tree on the \(x_1-y\) plane, and a bit like a bow-tie on
the \(x_2-y\) plane.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;rsquo;m not completely joking with the last point -
our human brains can &lt;em&gt;easily&lt;/em&gt; tell that \(Y\), \(X_1\), and \(X_2\) are related. There&amp;rsquo;s
so much structure in the plot! So many patterns appear before us as we explore the
space.&lt;/p&gt;
&lt;p&gt;Despite this, many common techniques completely fail to detect these patterns.
If we were to use linear analysis techniques - for example, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pearson_correlation_coefficient&#34;&gt;Pearson correlation coefficient&lt;/a&gt; -
we would get results telling us that \(Y\) is uncorrelated to \(X_1\) and \(X_2\), because
the slopes of \(Y\) against \(X_1\), \(X_2\), or both are on average flat.&lt;/p&gt;
&lt;p&gt;Similary, &lt;a href=&#34;https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient&#34;&gt;Spearman&amp;rsquo;s rank correlation coefficient&lt;/a&gt;
won&amp;rsquo;t help us because \(Y\) is not monotonic.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s also important that our method distinguishes between the actual generating source (e.g. \(X_1\)) and
an identically distributed but independent source. For example, we could define an independent distribution
with exactly the same &lt;em&gt;distribution&lt;/em&gt; as \(X_1\):&lt;/p&gt;
\[
Q \sim \mathcal{U}(0, 20)
\]&lt;p&gt;If we were to plot \(Q\) instead of \(X_1\), we get a plot with much less structure. The
christmas tree is missing!
Whatever method we end up with, it should be able to distinguish between these
two cases.&lt;/p&gt;
&lt;div id=&#34;teaser-plot-2&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import {get_timeseries_chart, get_3d_chart} from &#34;./mi_charts.js&#34;;
let x = Array(10_000).fill(0).map((_) =&gt; Math.random() * 20);
let y = Array(10_000).fill(0).map((_) =&gt; (Math.random() - 0.5) * 10);
let z = x.map((xi, i) =&gt; 0.25 * Math.sin(xi) * Math.sin(y[i]) * xi * y[i] + Math.random());
spawn_plot(&#34;timeseries-plot&#34;, (id) =&gt; get_timeseries_chart(id, 
                                        [x.slice(0, 500), y.slice(0, 500), z.slice(0, 500)], 
                                        [&#39;x₁&#39;, &#39;x₂&#39;, &#39;y&#39;]));
spawn_plot(&#34;teaser-plot&#34;, (id) =&gt; get_3d_chart(id, x.map((xi, i) =&gt; [xi, y[i], z[i]])));
spawn_plot(&#34;teaser-plot-2&#34;, (id) =&gt; get_3d_chart(id, y.map((yi, i) =&gt; [x[(i+1)%x.length], yi, z[i]]), 
                                        [&#39;q&#39;, &#39;x₂&#39;, &#39;y&#39;]));
&lt;/script&gt;
&lt;p&gt;With our challenge posed, let&amp;rsquo;s start building the tools we need to tackle it!&lt;/p&gt;
&lt;h1 id=&#34;entropy-for-continuous-numbers&#34;&gt;Entropy for Continuous Numbers&lt;/h1&gt;
&lt;p&gt;Entropy as defined earlier is quite restrictive:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We need to know all the possible messages that could be transmitted.&lt;/li&gt;
&lt;li&gt;We need to know the probabilities of receiving each possible message.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this section, we will extend these concepts into signals made up of continuous
numbers.&lt;/p&gt;
&lt;h2 id=&#34;a-refresher-on-continuous-probability-distributions&#34;&gt;A Refresher on Continuous Probability Distributions&lt;/h2&gt;
&lt;p&gt;While some probability distributions are discrete - the outcomes of
rolling dice, our lottery example from before, etc. - a lot of situations call for
continuous probability distributions.&lt;/p&gt;
&lt;p&gt;As an example, let&amp;rsquo;s look at the normal distribution.
This is arguably the most useful distribution in statistics, and we&amp;rsquo;d
very much like to characterise its entropy.&lt;/p&gt;
&lt;div id=&#34;normal distribution chart&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import {normal_chart} from &#34;./charts.js&#34;;
spawn_plot(&#34;normal distribution chart&#34;, (id) =&gt; normal_chart(id));
&lt;/script&gt;
&lt;p&gt;The plot above is the &lt;em&gt;probability density function&lt;/em&gt;, which we label \(p(x)\).
Points are more likely to be sampled from regions of high \(p(x)\) than from low
\(p(x)\). If we sampled 100 points from this distribution, we&amp;rsquo;d get a
distribution that looks like this:&lt;/p&gt;
&lt;div id=&#34;normal samples chart&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import {normal_sample_chart} from &#34;./charts.js&#34;;
spawn_plot(&#34;normal samples chart&#34;, (id) =&gt; normal_sample_chart(id));
&lt;/script&gt;
&lt;p&gt;We use the lowercase \(p(x)\) to denote probability &lt;em&gt;density&lt;/em&gt;, which is
different to the probability for discrete events, \(P(X)\). With a probability
density (and continuous numbers), the likelihood of sampling
at any exact value of \(x\) is zero. Instead, we integrate
across some range to get the likelihood of a sample falling in that &lt;em&gt;range&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For example, with our normal distribution, the likelihood of a point being greater than the mean (\(\mu\))
is 50%. Formally (for a normal distribution),&lt;/p&gt;
\[
    \int_\mu^\infty p(x) dx = 0.5
\]&lt;p&gt;Finally, the integral under the curve of \(p(x)\) from \(-\infty\) to \(\infty\) must equal
exactly 1. That is, when we sample from the distribution, we have to get a point &lt;em&gt;somewhere&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;making-things-discrete&#34;&gt;Making Things Discrete&lt;/h2&gt;
&lt;p&gt;We want a definition of entropy that works for continuous distributions. What we currently
have is a definition for discrete events:&lt;/p&gt;
\[
    H(X) = -\sum_{x \in X} P(x) \log_2{P(x)} \\
\]&lt;p&gt;From our definitions above, we know that we can use the integral of probability density \(p(x)\)
to calculate the likelihood of a point falling in some range (a, b). That is,&lt;/p&gt;
\[
    P(a \leq x \leq b) = \int_a^b p(x) dx       
\]&lt;p&gt;
&lt;em&gt;Here we use the capital \(P\) on the left side because it is an actual probability.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So, we can approximate a discrete distribution by dividing our continuous interval into
a number of &lt;em&gt;bins&lt;/em&gt;, and calculating the probabilities of each bin. As we increase the number
of bins, we should get a better and better approximation of the &lt;em&gt;continous&lt;/em&gt; entropy, whatever
that is. If we divide our domain into \(N\) bins, and the
width of each bin is \(\Delta x\), then we are going to calculate all the information content between
all \((x_i, x_i + \Delta x)\) for i from 0 to \(N\).&lt;/p&gt;
&lt;p&gt;Writing this statement in maths, we are saying:&lt;/p&gt;
\[
\begin{align}
    H(X) &amp;= -\sum_{x \in X} P(x) \log_2 P(x) \\
         &amp;= -\sum_{i = 0}^{N} \left(\int_{x_i}^{x_i+\Delta x} p(x) dx\right)\:\log_2 \left(\int_{x_i}^{x_i + \Delta x} p(x) dx\right) \\
\end{align}
\]&lt;p&gt;Finally, instead of actually computing the exact integral, we can approximate it with a
&lt;a href=&#34;https://en.wikipedia.org/wiki/Riemann_sum&#34;&gt;Riemann sum&lt;/a&gt;. A Reimann sum is quite simple:
we draw a rectangle from 0 up to a point on the function, \(f(x)\).
The area of this rectangle is \(f(x) \cdot \Delta x\), where
\(\Delta x\) is the width of the rectangle.&lt;/p&gt;
&lt;p&gt;As we make these rectangles narrower &lt;em&gt;(under some
conditions)&lt;/em&gt;, our approximation to the integral should get better and better. In other words,
as our rectangle gets narrower (i.e. \(\lim_{\Delta x \rightarrow 0}\)), the area of each rectangle
approaches the integral:&lt;/p&gt;
\[
        \lim_{\Delta x \rightarrow 0}\int_{x}^{x + \Delta x} f(x)\:dx = \Delta x \cdot f(x)
\]&lt;p&gt;With all our tools assembled, we can now practically compute the entropy of our normal distribution.
Substituting in the Reimann approximation to the integral, we have:&lt;/p&gt;
\[
\begin{align}
    H(X) &amp;= - \lim_{\Delta x \rightarrow 0} \left( \sum_{i = 0}^{N} p(x_i) \Delta x\:\
    \log_2 p(x_i) \Delta x \right) \\
\end{align}
\]&lt;p&gt;Play around with the chart below, where we carry out this exact procedure..
You should see that as we increase the number of bins, the area under the curve, \(\int_{-\infty}^{\infty} p(x) dx\),
rapidly converges to its true value of \(\approx 1\). This is just our earlier statement, that all of our
points must fall between \((-\infty, \infty)\).&lt;/p&gt;
&lt;p&gt;You might also notice that the entropy \(H(X)\) keeps increasing as the bins get narrower. Worryingly,
this value never converges - it just keeps increasing. If we take the limit of \(\Delta x \rightarrow 0\),
we&amp;rsquo;ll have &lt;strong&gt;infinite&lt;/strong&gt; entropy.&lt;/p&gt;
&lt;div id=&#34;integral&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import {integral_chart} from &#34;./charts.js&#34;;
spawn_plot(&#34;integral&#34;, (id) =&gt; integral_chart(id));
&lt;/script&gt;
&lt;h3 id=&#34;what-went-wrong&#34;&gt;What Went Wrong?&lt;/h3&gt;
&lt;p&gt;This result isn&amp;rsquo;t an issue with any of our assumptions. Instead, we can tease what&amp;rsquo;s going on directly out of the maths.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s go back to our continous entropy formula:&lt;/p&gt;
\[
\begin{align}
    H(X) &amp;= \lim_{\Delta x \rightarrow 0} \left( -\sum_{i = 0}^{N} p(x_i) \Delta x\:\
    \log_2 \left( p(x_i) \Delta x \right) \right) \\
\end{align}
\]&lt;p&gt;Looking at the last term, and remembering that \(\log(a \cdot b) = \log(a) + \log(b)\), we can
write it as:&lt;/p&gt;
\[
\begin{align}
    \log_2 p(x_i) \Delta x = \log_2 p(x_i) + \log_2 \Delta x \\
\end{align}
\]&lt;p&gt;Substituting this into the entropy formula,&lt;/p&gt;
\[
\begin{align}
    H(X) &amp;= -\lim_{\Delta x \rightarrow 0} \left( \sum_{i = 0}^{N} p(x_i) \Delta x\:\
    \left( \log_2 p(x_i) + \log_2 \Delta_x \right) \right) \\
         &amp;= -\lim_{\Delta x \rightarrow 0} \left(\
            \sum_{i=0}^N p(x_i) \Delta x \log_2 p(x_i) + \sum_{i=0}^N p(x_i) \Delta x \log_2 \Delta x \right) 
\end{align}
\]&lt;p&gt;In the last line, we split the sum into two sums.
Because \(\log_2 \Delta x\) is a constant, we can bring it out to the front of the second sum, giving us:&lt;/p&gt;
\[
\begin{align}
    H(X) &amp;= -\lim_{\Delta x \rightarrow 0} \left(\
            \sum_{i=0}^N p(x_i) \Delta x \log_2 p(x_i) + \log_2 \Delta x \sum_{i=0}^N p(x_i) \Delta x \right) 
\end{align}
\]\[
\begin{align}
        p(x) \Delta x &amp;\approx \int_x^{x + \Delta x} p(x) dx \\
    \lim_{\Delta x \rightarrow 0} \sum_{i=0}^N  p(x_i) \Delta x &amp;= 1 \\
\end{align}
\]&lt;p&gt;Substituting this term into the entropy formula, we simplify the second term and rearrange the first:&lt;/p&gt;
\[
\begin{align}
   H(X) &amp;= -\lim_{\Delta x \rightarrow 0} \left(\
            \sum_{i=0}^N p(x_i) \log_2 p(x_i) \Delta x + \log_2 \Delta x \cdot 1 \right) 
\end{align}
\]&lt;p&gt;Finally, we can convert our Riemann sum &lt;em&gt;back&lt;/em&gt; to an integral, to give us the formula:&lt;/p&gt;
&lt;blockquote&gt;
\[
    H(X) = \left(-\int_{-\infty}^{\infty} p(x) \log_2 p(x)\:dx\right)\
    - \lim_{\Delta x \rightarrow 0} \log_2 \Delta x \
    \]&lt;/blockquote&gt;
&lt;p&gt;The first term looks pretty sensible - this is the formula for \(H(X)\) that we started
with at the top of this section, but with \(\sum\) swapped for \(\int\), and \(P\) swapped
for \(p\).&lt;/p&gt;
&lt;p&gt;However, the \(\log_2 \Delta x\) term is &lt;strong&gt;bad news&lt;/strong&gt; - it blows up to infinity
as \(\Delta x\) approaches 0. In other words, the more slices we use to divide our continous distribution, the
higher the entropy. This should perhaps not be surprising since, as we said earlier, the probability of getting
any particular number from a continuous distribution is infinitely unlikely, and hence carries infinite information.
As our bins approach 0 width, this is exactly the situation we get.&lt;/p&gt;
&lt;h3 id=&#34;a-flawed-solution-differential-entropy&#34;&gt;A Flawed Solution: Differential Entropy&lt;/h3&gt;
&lt;p&gt;What if we just closed our eyes and ignored the \(\log_2 \Delta x\) term? Since it&amp;rsquo;s the part that blows up to infinity, we can
salvage the rest of the equation and define the &lt;em&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Differential_entropy&#34;&gt;Differential Entropy&lt;/a&gt;&lt;/em&gt;,
\(h(X)\), as:&lt;/p&gt;
\[
\begin{align}
        h(X) &amp;= H(X) + \lim_{\Delta x \rightarrow 0} \log_2 \Delta x \\
             &amp;= -\int_{-\infty}^{\infty} p(x) \log_2 p(x)\:dx \\
\end{align}
\]&lt;p&gt;The measure we&amp;rsquo;re left with, \(h(X)\), is a lot less useful than the discrete \(H(X)\) we know
and love:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;\(H(X) = 0\) implied no information was transmitted, because we always sent the same message with
100% certainty. \(h(X) = 0\), however, does not have any special meaning. This is because:&lt;/li&gt;
&lt;li&gt;Differential entropy can be negative. Negative!&lt;/li&gt;
&lt;li&gt;\(h(X)\) is sensitive to scale (and therefore units). If we measured 100 people&amp;rsquo;s heights,
\[\text{height}_\text{cm} = [167\text{cm}, 185\text{cm}, ...]\] Then we converted the measurements to metres:
\[\text{height}_\text{m} = [1.67\text{m}, 1.85\text{m}, ...]\]
The differential entropy of \(\text{height}_\text{cm}\) would be &lt;em&gt;larger&lt;/em&gt; than the differential entropy of \(\text{height}_\text{m}\).&lt;/li&gt;
&lt;/ol&gt;
\[
        h(X + c) = h(X)
\]&lt;p&gt;So, with our normal distribution, we can shift the mean wherever we like and keep the same differential
entropy.&lt;/p&gt;
&lt;p&gt;This seemingly arbitrary collection of properties has a simple explanation: differential entropy is
basically a measure of (log of) &lt;strong&gt;volume&lt;/strong&gt;. Without being rigorous, we can suggest that:&lt;/p&gt;
\[
    V \approx 2^{h(X)}        
\]&lt;p&gt;Where \(V\) is the volume of a hypercube that fits most of the probability mass of our distribution. For a more
rigorous explanation, see &lt;a href=&#34;https://stats.stackexchange.com/a/616892&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This intuitive explanation clarifies all of the above properties. 1. and 2. occur because
volumes can be smaller than 1 (\(2^{-3} = 0.125\), for example.) 3. occurs because when we change units,
the box containing our numbers grows or shrinks in terms of absolute number magnitude
(even if the actual underlying data is the same.)&lt;/p&gt;
&lt;h3 id=&#34;a-better-solution-divergence&#34;&gt;A Better Solution: Divergence&lt;/h3&gt;
&lt;p&gt;Differential Entropy, then, isn&amp;rsquo;t the whole answer. To motivate the actual solution, we&amp;rsquo;ll start by
looking at the entropy formula we tried to discretize earlier:&lt;/p&gt;
\[
\begin{align}
    H(X) &amp;= \lim_{\Delta x \rightarrow 0} \left( -\sum_{i = 0}^{N} p(x_i) \Delta x\:\
    \log_2 \left( p(x_i) \Delta x \right) \right)\\
\end{align}
\]&lt;p&gt;The trouble really stems from the last term:&lt;/p&gt;
\[
    \log_2 p(x_i) \Delta x
\]&lt;p&gt;We want to introduce some term that knocks out this \(\Delta x\). To do so,
we need to introduce a second distribution - say, as second normal distribution
that may (or may not) have the same mean and variance as our original distribution \(p(x)\).
We&amp;rsquo;ll label the &lt;em&gt;probability density function&lt;/em&gt;
of this distribution \(q(x)\).&lt;/p&gt;
&lt;p&gt;Instead of measuring the information content of each slice, we could try measuring the &lt;em&gt;difference&lt;/em&gt;
in information content between \(p(x)\) and \(q(x)\). That is, instead of&lt;/p&gt;
\[\log_2 p(x_i) \Delta x\]&lt;p&gt;We measure&lt;/p&gt;
\[
\begin{align}
\log_2 p(x_i) \Delta x - \log_2 q(x_i) \Delta x &amp;= \log_2 \frac{p(x_i) \Delta x}{q(x_i) \Delta x} \\
                                                &amp;= \log_2 \frac{p(x_i)}{q(x_i)} \\
\end{align}
\]&lt;p&gt;Because we want our quantity to still be an expectation value \(\mathbb{E}\), we
need to weight how likely each slice is, somehow. We can choose \(p(x)\) to do
this weighting. In other words, we&amp;rsquo;re now calculating&lt;/p&gt;
\[
D_{KL}(p || q) = \lim_{\Delta x \rightarrow 0} \sum_{i = 0}^{N} p(x_i) \Delta x\:\
\log_2 \frac{p(x_i)}{q(x_i)} \\
\]&lt;p&gt;If we really want to use \(q(x)\) to do the weighting (and sometimes we do), we could just
swap which distribution we call \(p\) and which we call \(q\).&lt;/p&gt;
&lt;p&gt;This nicely cancels out the \(\Delta x\) term. But does it work?&lt;/p&gt;
&lt;div id=&#34;divergence&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import {integral_chart} from &#34;./charts.js&#34;;
spawn_plot(&#34;divergence&#34;, (id) =&gt; integral_chart(id, true));
&lt;/script&gt;
&lt;p&gt;Yes! Just as \(P(X) = \int_{-\infty}^{\infty} p(x) dx\) rapidly converges to 1, \(D_{KL}\)
also converges to a constant value, even as \(H(X)\) continues to increase.&lt;/p&gt;
&lt;h3 id=&#34;so-what-is-the-kl-divergence&#34;&gt;So what &lt;em&gt;is&lt;/em&gt; the KL-Divergence?&lt;/h3&gt;
&lt;p&gt;The KL-Divergence is a core tool in Information Theory, for discrete, continuous, and mixed
distributions. With it, we&amp;rsquo;ll build the tools we need to make sense of signals.&lt;/p&gt;
&lt;p&gt;To understand the KL-Divergence better, I&amp;rsquo;d highly recommend reading through &lt;a href=&#34;https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence&#34;&gt;Six (and a half) intuitions for KL divergence.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For now, suffice it to say that the KL-divergence is a measure of the &lt;em&gt;difference in information&lt;/em&gt;
between two distributions. If we observe a particular event, the information we gain from that
observation varies depending on the message was generated according to the statistics of one probability
distribution, &lt;em&gt;p&lt;/em&gt;, or a different one, &lt;em&gt;q&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In our lottery example from earlier, observing a 1 carries a lot of information. But if instead
we had agreed that I would send you a 0 every time the winning number was odd, and a 1 every time it was even, the
information content of that &amp;ldquo;1&amp;rdquo; message would be lower. KL-divergence quantifies this difference,
averaged (using \(p\)) across the whole distribution.&lt;/p&gt;
&lt;h3 id=&#34;why-is-kl-divergence-an-improvement&#34;&gt;Why is KL-Divergence an Improvement?&lt;/h3&gt;
&lt;p&gt;Even though the derivation of KL-Divergence seems more mathematically sound than that of
differential entropy, is it better in practical ways? To see, let&amp;rsquo;s examine some of its
properties:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;\(D_{KL}(p || q) = 0\) implies \(p = q\).&lt;/li&gt;
&lt;li&gt;\(D_{KL} \geq 0\).&lt;/li&gt;
&lt;li&gt;\(D_{KL}\) is insensitive to unit changes, rescaling etc. Because we have two probability distributions
\(p\) and \(q\), if we change the units of one, we have to change units of the other. These effects cancel out,
and we get back the same divergence as we started with. In fact, we can warp our coordinates using an arbitrary
function \(y(x)\) which need not be linear, provided that \(y(x)\) is unique for each unique \(x\) (i.e. it
is &lt;a href=&#34;https://en.wikipedia.org/wiki/Bijection&#34;&gt;bijective).&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;KL-Divergence has one major consideration, though: anywhere \(p(x) &gt; 0\), \(q(x)\) &lt;strong&gt;must&lt;/strong&gt; be greater than
0, too. Otherwise, the \(p(x) \log\frac{p(x)}{q(x)}\) term blows up to \(\infty\), and with it the divergence.&lt;/p&gt;
&lt;p&gt;With this tool, we now have a firm footing for using information theory in continuous domains. We can
build on it to obtain the &lt;em&gt;mutual information&lt;/em&gt;, the tool we will use to finally solve our problem.&lt;/p&gt;
&lt;h1 id=&#34;mutual-information&#34;&gt;Mutual Information&lt;/h1&gt;
&lt;p&gt;When it comes to determining if two signals are correlated, mutual information is the tool we&amp;rsquo;ve been looking for.
Yet, it is also subtly different from what we might&amp;rsquo;ve expected. Mutual information tells us how much information we learn about a signal \(Y\) if we were
to observe samples of a different signal, \(X\).&lt;/p&gt;
&lt;p&gt;Formally, the mutual information between two distributions \(X\) and \(Y\), \(I(X;Y)\), is defined as&lt;/p&gt;
\[
            I(X;Y) = D_{KL} (P_{(X,Y)} || P_X \otimes P_Y)
\]&lt;p&gt;\(P_{(X,Y)}\) is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Joint_probability_distribution&#34;&gt;joint distribution&lt;/a&gt; of X and Y,
\(P_X\) and \(P_Y\) are the &lt;a href=&#34;https://en.wikipedia.org/wiki/Marginal_distribution&#34;&gt;marginal distributions&lt;/a&gt; or X and Y
respectively, and \(\otimes\) is the element-wise product between them.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s a lot of words!  I promise it&amp;rsquo;ll make more sense when you see
it in action. For now, there are some important properties to note:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;\(I(X;Y) = 0\) &lt;em&gt;if and only if&lt;/em&gt; \(X\) is independent of \(Y\).&lt;/li&gt;
&lt;li&gt;\(I(X;Y) \geq 0\).&lt;/li&gt;
&lt;li&gt;\(I(X;Y) = I(Y;X)\) - that is, mutual information is &lt;em&gt;symmetric&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;\(I(X;X) = H(X)\). For continuous signals, the amount of information gained (or uncertainty removed) about \(X\)
by observing \(X\) is \(\infty\). This applies too for \(I(X;f(X)\) where \(f()\) is invertible (i.e. bijective.)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;the-histogram-method&#34;&gt;The Histogram Method&lt;/h2&gt;
&lt;p&gt;There are a number of ways to estimate mutual information. The most straightforward approach would be to divide the space
into lots of bins, and count how many samples fall into each bin. We could then assume the probability is constant
across each bin, giving an estimate for \(p(x)\):&lt;/p&gt;
\[
    \hat{p}(\text{bin}) = \frac{n_\text{bin}}{n_\text{total}}
\]&lt;p&gt;We could apply the same technique, with the same bins, to sample from \(q\) and estimate \(q(x)\) as \(\hat{q}(\text{bin})\).&lt;/p&gt;
&lt;p&gt;We immediately run into problems, though. Anywhere one or more samples from \(p\) fall into a bin, that
bin &lt;strong&gt;must&lt;/strong&gt; also capture at least one sample from \(q\). Otherwise, the estimated probability of \(q = 0\),
and we blow up the KL-divergence to infinity (recall, mutual information is a special application of the KL-divergence.)&lt;/p&gt;
&lt;p&gt;In practice, this means we need lots of samples &lt;strong&gt;and&lt;/strong&gt; large bin sizes, neither of which are ideal.&lt;/p&gt;
&lt;h1 id=&#34;k-nearest-neighbors&#34;&gt;K-Nearest Neighbors&lt;/h1&gt;
&lt;p&gt;Instead, we&amp;rsquo;ll use K-Nearest-Neighbors (KNN). This technique can be used for a number of problems, although we&amp;rsquo;ll
use it to estimate the mutual information directly (as per &lt;a href=&#34;https://arxiv.org/pdf/cond-mat/0305641&#34;&gt;Kraskov, Stögbauer, and Grassberger&lt;/a&gt;).&lt;/p&gt;
\[
\begin{align}
X = \mathcal{U}(0, 5) \\
Y = \sin(X) + \mathcal{U}(0, 1) \\
\end{align}
\]&lt;p&gt;So, our two signals are correlated, but not perfectly.&lt;/p&gt;
&lt;div id=&#34;plot&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import {get_2d_mi_chart} from &#34;./mi_charts.js&#34;;
let x = Array(500).fill(0).map((_) =&gt; Math.random() * 5);
let y = x.map((xi) =&gt; Math.sin(xi) + Math.random() * 1);
spawn_plot(&#34;plot&#34;, (id) =&gt; get_2d_mi_chart(id, x.map((xi, i) =&gt; [xi, y[i]]), 5));
&lt;/script&gt;
&lt;p&gt;What&amp;rsquo;s going on is:&lt;/p&gt;
&lt;p&gt;For each point \((x_i, y_i)\):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Calculate the distance, \(d_k\) to the Kth nearest neighbor (e.g. if k=5,
\(d_5\) is the distance to the third nearest neighbor to \(x_i\)). We calculate distance using
the &lt;a href=&#34;https://en.wikipedia.org/wiki/Uniform_norm&#34;&gt;Infinity Norm&lt;/a&gt;, i.e. \(d = \max(d_x, d_y)\). Hence,
we know there are exactly \(k\) points within a hypercube of side-length \(d\).&lt;/li&gt;
&lt;li&gt;Ignoring the x-direction, calculate \(n_y\), the number of points that are within a distance \(d_k\) of \(y_i\).&lt;/li&gt;
&lt;li&gt;Ignoring the y-direction, calculate \(n_x\), the number of points that are within a distance \(d_k\) of \(x_i\).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then, the mutual information can be estimated as&lt;/p&gt;
\[
        I(X;Y) \approx \psi(k) + \psi(N) - \frac{1}{N} \sum_{i=0}^N \psi(n_x + 1) + \psi(n_y + 1)
\]&lt;p&gt;\(\psi(x)\) is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Digamma_function&#34;&gt;Digamma function&lt;/a&gt;, which is close to \(\log(x)\) for
large x. N is the number of points, k is the k from K-nearest-neighbors, and \(n_x\) and \(n_y\) are the values
described above.&lt;/p&gt;
&lt;p&gt;The reason we can just take an average over all our points without needing to weight by \(p(x)\) is because
KNN naturally samples more in areas of high probability, and less in areas of low probability. Because each bin
is dynamically constructed around points actually sampled from our distributions, the probability weighting happens
for free.&lt;/p&gt;
&lt;p&gt;Again, this formula is not the most illuminating. We need to pick it apart to really understand what&amp;rsquo;s going on.
Recall that \(I(X;Y) = 0\) &lt;em&gt;if and only if&lt;/em&gt; the two signals are uncorrelated. For our formula to equal zero,
either \(n_x\) or \(n_y\) (or both) would have to be, on average, very close to \(N\), the total number of points.
We can actually extend this further. For large \(n\), we have very approximately:&lt;/p&gt;
\[
    \psi(n) \approx 2 \cdot \psi(\sqrt{n})
\]&lt;p&gt;In other words, if we have \(N\) points, \(n_x\) and \(n_y\) each only need to be slightly larger than
\(\sqrt{N}\) for the mutual information to be 0. We&amp;rsquo;ll see a visual representation of this later.&lt;/p&gt;
&lt;p&gt;On the other hand, if \(n_x\) and \(n_y\) are small most of the time, the mutual information would be very high.&lt;/p&gt;
&lt;p&gt;We can maximise mutual information if the only points captured in our \(n_x\) and \(n_y\) bounds were already
captured inside our k-nearest neighbors. In some sense, the &amp;ldquo;sharper&amp;rdquo; the line in our plot is, the fewer
points will be captured by \(n_x\) and \(n_y\). As we add noise, the line gets fuzzier, and \(n_x\) and \(n_y\)
increase.&lt;/p&gt;
&lt;p&gt;Also note that \(n_x\) and \(n_y\) are treated identically by the function. This again highlights the
symmetric nature of mutual information: \(I(X;Y) = I(Y;X)\).&lt;/p&gt;
&lt;p&gt;Finally, the \(\psi(N)\) term means that in cases of very high mutual information, the exact
number we get will depend on the number of samples we analyse. If \(X\) is continuous and \(Y = X\), for example,
the true mutual information should be infinite. Instead, we will see it gradually increase as the number of
samples increases, much like the differential entropy from earlier. Typically, \(Y\) is not exactly equal to
\(X\), for example if some extra noise were added, which means that mutual information typically plateaus
at some (high) value, even for very correlated signals.&lt;/p&gt;
&lt;h3 id=&#34;illustrative-examples-of-mutual-information&#34;&gt;Illustrative Examples of Mutual Information&lt;/h3&gt;
&lt;p&gt;So, we can maximize mutual information by capturing as few points in our \(n_x\) and \(n_y\) bounds
as possible. One way to do that very effectively is to have \(Y\) be a linear function of \(X\). E.g.&lt;/p&gt;
\[
\begin{align}
    X = \mathcal{U}(0, 5) \\
    Y = X;
\end{align}
\]&lt;p&gt;Indeed, this gives us a very high mutual information score.&lt;/p&gt;
&lt;div id=&#34;very-linear-plot&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;linear-text&#34;&gt;&lt;/code&gt;
&lt;script type=&#34;module&#34;&gt;
import {get_2d_mi_chart} from &#34;./mi_charts.js&#34;;
let x = Array(500).fill(0).map((_) =&gt; Math.random() * 5);
let y = x.map((xi) =&gt; xi);
spawn_plot(&#34;very-linear-plot&#34;, (id) =&gt; get_2d_mi_chart(id, x.map((xi, i) =&gt; [xi, y[i]]), 5));
//
const worker = new Worker(&#34;./worker.js&#34;, { type: &#34;module&#34;} );
worker.onmessage = (e) =&gt; {
    document.getElementById(&#34;linear-text&#34;).textContent = `Estimated Mutual Information = ${e.data}`;
};
worker.postMessage([&#34;MI&#34;, x.map((x, i) =&gt; [x, y[i]]), 5]);
&lt;/script&gt;
&lt;p&gt;But mutual information does not &lt;strong&gt;require&lt;/strong&gt; linearity. For example, the
following very non-linear function which would flummox any linear analysis
(but is obviously quite correlated to the naked eye) also gives us a high
mutual information score:&lt;/p&gt;
\[
\begin{align}
X &amp;= \mathcal{U}(0, 5) \\
Y &amp;= \left\{ \begin{array}{ll}
           x &amp; 0 \leq x &lt; 1 \\
           -x &amp; 1 \leq x &lt; 2 \\
           x &amp; 2 \leq x &lt; 3 \\
           ... &amp; \\
\end{array}
\right.
\end{align}
\]&lt;div id=&#34;very-nonlinear-plot&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;very-nonlinear-text&#34;&gt;&lt;/code&gt;
&lt;script type=&#34;module&#34;&gt;
import {get_2d_mi_chart} from &#34;./mi_charts.js&#34;;
let x = Array(500).fill(0).map((_) =&gt; Math.random() * 5);
let y = x.map((xi) =&gt; xi * ( 1 + Math.floor(xi % 2) * -2));
spawn_plot(&#34;very-nonlinear-plot&#34;, (id) =&gt; get_2d_mi_chart(id, x.map((xi, i) =&gt; [xi, y[i]]), 5));
//
const worker = new Worker(&#34;./worker.js&#34;, { type: &#34;module&#34;} );
worker.onmessage = (e) =&gt; {
    document.getElementById(&#34;very-nonlinear-text&#34;).textContent = `Estimated Mutual Information = ${e.data}`;
};
worker.postMessage([&#34;MI&#34;, x.map((x, i) =&gt; [x, y[i]]), 5]);
&lt;/script&gt;
&lt;p&gt;Mutual information is subtle, though. Just because \(y\) might be a
function of \(x\) doesn&amp;rsquo;t mean mutual information is maximised. Take the
following distributions,&lt;/p&gt;
\[
\begin{align}
X &amp;= \mathcal{U}(0, 20) \\
Y &amp;= \sin(X) \\
\end{align}
\]&lt;div id=&#34;sine-plot&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;sine-text&#34;&gt;&lt;/code&gt;
&lt;script type=&#34;module&#34;&gt;
import {get_2d_mi_chart} from &#34;./mi_charts.js&#34;;
let x = Array(2000).fill(0).map((_) =&gt; Math.random() * 20);
let y = x.map((xi) =&gt; Math.sin(xi));
spawn_plot(&#34;sine-plot&#34;, (id) =&gt; get_2d_mi_chart(id, x.map((xi, i) =&gt; [xi, y[i]]), 5));
//
const worker = new Worker(&#34;./worker.js&#34;, { type: &#34;module&#34;} );
worker.onmessage = (e) =&gt; {
    document.getElementById(&#34;sine-text&#34;).textContent = `Estimated Mutual Information = ${e.data}`;
};
worker.postMessage([&#34;MI&#34;, x.map((x, i) =&gt; [x, y[i]]), 5]);
&lt;/script&gt;
&lt;p&gt;Notice how the samples for \(n_y\) come from multiple different cycles of
the sine wave. Also, remember that mutual information is &lt;strong&gt;symmetric&lt;/strong&gt;. So,
even though knowing \(x\) tells us exactly what \(y\) will be, knowing
the value of \(y\) doesn&amp;rsquo;t let us pinpoint an exact \(x.\) Instead, we know
\(x \mod 2\pi \), but there are still an infinite number of \(x\)&amp;rsquo;s for every
\(y.\)&lt;/p&gt;
&lt;p&gt;Another way to think about this is that, probabilistically, there are lot of different
ways to get a particular value of \(y\), and so actually getting that value isn&amp;rsquo;t too surprising.
Each value of \(x\), however, is more surprising. Since information content increases with surprise,
we learn more by observing \(x\) than we do \(y\), and so they cannot have maximum mutual information.&lt;/p&gt;
&lt;p&gt;Finally, we can &lt;em&gt;minimize&lt;/em&gt; mutual information by introducing noise that isn&amp;rsquo;t shared between our signals.
We get a value of 0 when there is nothing in common between \(X\) and \(Y\):
For example,&lt;/p&gt;
\[
\begin{align}
X &amp;\sim \mathcal{U}(0, 20) \\
Y &amp;\sim \mathcal{U}(0, 20) \\
\end{align}
\]&lt;div id=&#34;uncorrelated-plot&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;uncorrelated-text&#34;&gt;&lt;/code&gt;
&lt;script type=&#34;module&#34;&gt;
import {get_2d_mi_chart} from &#34;./mi_charts.js&#34;;
let x = Array(2000).fill(0).map((_) =&gt; Math.random() * 20);
let y = Array(2000).fill(0).map((_) =&gt; Math.random() * 20);
spawn_plot(&#34;uncorrelated-plot&#34;, (id) =&gt; get_2d_mi_chart(id, x.map((xi, i) =&gt; [xi, y[i]]), 5));
const worker = new Worker(&#34;./worker.js&#34;, { type: &#34;module&#34;} );
worker.onmessage = (e) =&gt; {
    document.getElementById(&#34;uncorrelated-text&#34;).textContent = `Estimated Mutual Information = ${e.data}`;
};
worker.postMessage([&#34;MI&#34;, x.map((x, i) =&gt; [x, y[i]]), 5]);
&lt;/script&gt;
&lt;p&gt;Like we said earlier, it&amp;rsquo;s clear that neither \(n_x\) nor \(n_y\) are capturing anywhere close to the full
\(N\) points in the x-y plane. However, because \(x\) and \(y\) are uncorrelated, the amount of points
falling in each bin is roughly \(\frac{\text{bin width}}{\text{total width}}\).&lt;/p&gt;
&lt;p&gt;Imagine the space our points live in as a square with area \(n^2\). Then, our side-lengths would
be \(n\). We could divide the square into wide strips of height 1, giving us \(n\)
strips of area \(n\), or we could divide it into tall strips of width 1, also giving us \(n\)
strips of area \(n\).&lt;/p&gt;
&lt;p&gt;If we just rename \(n^2\) to \(N\), our total number of points, we get the expectation
that if our points are uniformly distributed in the x-y space,
the number of points captured in a wide strip of height 1 (or a tall
strip of width 1) should be \(\sqrt{N}\). In other words, if the orange square
that holds our K nearest neighbors held 1 point, we should expect \(n_x\) and \(n_y\)
to both hold \(\sqrt{N}\) points in this uncorrelated case.&lt;/p&gt;
\[
    \psi(n) \approx 2 \cdot \psi(\sqrt{n})
\]&lt;p&gt;Also, we know our equation for mutual information is:&lt;/p&gt;
\[
        I(X;Y) \approx \psi(k) + \psi(N) - \frac{1}{N} \sum_{i=0}^N \psi(n_x + 1) + \psi(n_y + 1)
\]&lt;p&gt;So, very roughly, if \(n_x\) and \(n_y\) capture \(\sqrt{N}\) points each (as they would if
the points were uniformly distributed along the x and y axes), the mutual information would
tend to zero. (\(n_x\) or \(n_y\) need to be slightly larger to cancel out the \(\psi(k)\)
term. This could be seen as compensating for the fact that our \(n_x\) and \(n_y\) bins are
not infinitely thin, and so capture the same points multiple times).&lt;/p&gt;
&lt;p&gt;For non-uniform (but still uncorrelated) distributions, this analogy still
works. We just have to remember that the KNN algorithm
makes the bins smaller in more dense regions, and larger in less dense regions. So, we could imagine
this process as the algorithm first clustering or spreading out points so that they
are evenly distributed, and then counting the area in each constant-width strip.&lt;/p&gt;
&lt;p&gt;Finally, let&amp;rsquo;s look at our 3 signals from much earlier in the article. Recall,&lt;/p&gt;
\[
\begin{align}
            X_1 &amp;\sim \mathcal{U}(0, 20) \\
            X_2 &amp;\sim \mathcal{U}(-5, 5) \\
            Y &amp;= \sin(X_1) \sin(X_2)\;X_1\;X_2\\
\end{align}
\]&lt;p&gt;We can calculate the mutual information between \(X_1\) and \(Y\):&lt;/p&gt;
&lt;div id=&#34;2d-hero-plot&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;mi-text-2d&#34;&gt;&lt;/code&gt;
&lt;p&gt;While the mutual information isn&amp;rsquo;t as high as it would be for a purely bijective
function, it&amp;rsquo;s still significant. Even though the average slope of \(X_1\) vs \(Y\)
is flat, and even despite the noise from the unaccounted for \(X_2\), mutual information
is successful in telling us that, yes, our signals are correlated.&lt;/p&gt;
&lt;p&gt;As we increase the number of samples, the estimated mutual information will continue to climb.
Potentially, we could tackle this would by normalizing the mutual information estimate against
it&amp;rsquo;s maximum possible value - something like:&lt;/p&gt;
\[
    \hat{I}(X;Y) = \frac{\psi(k) + \psi(N) - \frac{1}{N} \sum_{i=0}^N \psi(n_x + 1) + \psi(n_y + 1)}{\psi(N)}
\]&lt;p&gt;Here, \(\hat{I}\) close to 1 implies maximum information shared, and \(\hat{I} = 0\) implies
no information shared between \(X_1\) and \(Y\). It&amp;rsquo;s not completely clear whether this quantity
has a direct link back to information theory, though. It&amp;rsquo;s somewhat close to the &lt;a href=&#34;https://en.wikipedia.org/wiki/Mutual_information#Metric&#34;&gt;Rajski Distance&lt;/a&gt;,
defined as:&lt;/p&gt;
\[
    D(X, Y) = 1 - \frac{I(X;Y)}{H(X,Y)}
\]&lt;p&gt;Perhaps we could derive a mathematically sound version of this metric that converges
to a useful value, and would give us a useful, normalized criteria for comparing signals.&lt;/p&gt;
&lt;h3 id=&#34;handling-the-second-input&#34;&gt;Handling the Second Input&lt;/h3&gt;
&lt;p&gt;We can&amp;rsquo;t let \(X_1\) have all the fun. Let&amp;rsquo;s calculate the mutual
information between \(X_2\) and \(Y\).&lt;/p&gt;
&lt;div id=&#34;2d-hero-plot-x2&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;mi-text-2d-x2&#34;&gt;&lt;/code&gt;
&lt;p&gt;We should pause for a moment, though. This approach doesn&amp;rsquo;t really take into account the fact that we need
both \(X_1\) and \(X_2\) to fully define a value of \(Y\). Looking only at
one input and one output at a time also doesn&amp;rsquo;t tell us whether \(X_1\) carries
unique information about \(Y\) that \(X_2\) does not, or if we&amp;rsquo;re just double-counting
the same information each time.&lt;/p&gt;
&lt;p&gt;To figure out if both \(X_1\) and \(X_2\) are correlated to \(Y\), &lt;strong&gt;and&lt;/strong&gt; that \(X_2\)
carries information \(X_2\) does not, we need to go deeper.&lt;/p&gt;
&lt;h1 id=&#34;conditional-mutual-information&#34;&gt;Conditional Mutual Information&lt;/h1&gt;
&lt;p&gt;There are a lot of extensions of mutual information to more variables. For our example,
we&amp;rsquo;re interested in the &lt;a href=&#34;https://en.wikipedia.org/wiki/Conditional_mutual_information&#34;&gt;Conditional Mutual Information&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Although it&amp;rsquo;s typically written as \(I(X;Y|Z)\), we&amp;rsquo;ll use the terminology \(I(X_1;Y|X_2)\). This way, we write the
inputs the same we&amp;rsquo;ll use them in our signal processing example.&lt;/p&gt;
&lt;p&gt;Conditional mutual information tells us how much of the mutual information \(I(X_1;Y)\) between
\(X_1\) and \(Y\) is &lt;em&gt;not&lt;/em&gt; found in \(X_2\). In other words, if \(I(X_2;Y) &gt; 0\), we know
that \(X_2\) and \(Y\) share some information; if \(I(X_1;Y|X_2) = 0\), we then know that
all the information \(X_2\) told us about \(Y\) could have been learned by observing
\(X_1\) instead.&lt;/p&gt;
&lt;p&gt;As you can probably tell by the notation, conditional mutual information treats
its inputs differently. There is still some symmetry:&lt;/p&gt;
\[
I(X_1;Y|X_2) = I(Y;X_1|X_2)
\]&lt;p&gt;However, interchanging \(X_2\) with the other inputs gives us a different result. This
is important because if \(X_2\) is completely irrelevant (i.e. uncorrelated random noise),
the conditional mutual information reduces to:&lt;/p&gt;
\[
    I(X_1;Y|X_2) = I(X_1;Y)
\]&lt;div id=&#34;3d-plot&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;mi-text&#34;&gt;&lt;/code&gt;
&lt;p&gt;So, how do we calculate conditional mutual information? Well, it&amp;rsquo;s actually very similar
to how we calculated mutual information in the 2d case. We can use &lt;a href=&#34;https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.99.204101&#34;&gt;Frenzel and Pompe&amp;rsquo;s&lt;/a&gt;
modification of the &lt;a href=&#34;https://arxiv.org/pdf/cond-mat/0305641&#34;&gt;KSG estimator&lt;/a&gt; from earlier.&lt;/p&gt;
&lt;p&gt;For each point p, we calculate
the distance \(d\) to the k-th nearest neighbor (again using the infinity norm), and then count:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;\(n_{x_2}\) - the number of points within a distance \(d\) from p, ignoring both the
\(x_1\) and \(y\) coordinates.&lt;/li&gt;
&lt;li&gt;\(n_{x_1, x_2}\) - the number of points within a distance \(d\) from p, ignoring
the \(y\) coordinate.&lt;/li&gt;
&lt;li&gt;\(n_{x_2, y}\) - the number of points within a distance \(d\) from p, ignoring
the \(x_1\) coordinate.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Even though we now have 3 hyper-rectangles to keep track of, the process is very similar to before - we&amp;rsquo;re
basically taking a number of 2d-slices of our 3d space, and computing the mutual information
within each slice. \(n_{x_2}\) can be thought of as \(N\), the total number of points in our
MI estimator; \(n_{x_1, x_2}\) is analogous to \(n{x_1}\) and \(n_{x_2, y}\) is analogous to
\(n_{y}\).&lt;/p&gt;
&lt;p&gt;So, the formula is:&lt;/p&gt;
\[
        I(X_1;Y|X_2) \approx \psi(k) - \frac{1}{N} \sum_{i=0}^N \psi(n_{x2}) - \psi(n_{x_1,x_2}) - \psi(n_{x_2,y}) 
\]&lt;p&gt;So, conditional mutual information is high if for each slice of \(X_2\), we have high mutual information between
\(X_1\) and \(Y\).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(The nearest-neighbor hypercube in the 3d plots might look a little squashed. This is just a plotting
artifact, because the variance of our function is much larger in the z-direction than x or y. The cube is
still a cube, we just have a squashed z-direction.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One important test we defined earlier is being able to distinguish between a random variable that is
&lt;em&gt;in distribution&lt;/em&gt;, but not actually correlated to the signal, and a correlated variable with the same
distribution. For example we could define an unrelated variable \(Q\) with \(X_1\text{&#39;s}\) distribution:&lt;/p&gt;
\[
            Q \sim \mathcal{U}(0, 20) \\
\]&lt;p&gt;Does conditional mutual information distinguish between these two cases?&lt;/p&gt;
&lt;div id=&#34;3d-plot-2&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;mi-text-2&#34;&gt;&lt;/code&gt;
&lt;p&gt;Recall that conditional mutual information \(I(X_1;Y|X_2)\) becomes equivalent to mutual information \(I(X_1;Y)\) if
the conditioning variable, \(X_2\), is uncorrelated to \(X_1\) and \(Y.\) In this case, we know that \(Q\) is
uncorrelated, and so \(I(X_2;Y|Q)\) should equal the value of \(I(X_2;Y)\) we calculated in the previous section.
While the value is close, it&amp;rsquo;s not an exact match. This is likely an issue of finite sample sizes, and should
improve as the number of points sampled increases.&lt;/p&gt;
&lt;p&gt;At the very least, we appear to get a much stronger (~1.0) result when calculating \(I(X_1;Y|X_2)\) vs
the ~0.3 we get with \(I(X_2;Y|Q)\). Visualizing why this is the case,
we can see that for each \(n_{x_2}\), we highlight a bunch of noise where we
would be seeing a christmas tree if \(Q\) was swapped for \(X_1\). &lt;em&gt;(These exact numbers vary a lot with the exact points
sampled, since all the estimated mutual information scores are calculated dynamically on your device.)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Recall, also, that conditional mutual information is not symmetric. Since \(Q\) carries no information
about \(Y\), we should be able to swap the order of signals and get back a result of 0. I.e.
\(I(Q;Y|X_1) = I(Q;Y) = 0\).&lt;/p&gt;
&lt;p&gt;If we run this through our estimator, we do in fact get back 0:&lt;/p&gt;
&lt;p&gt;&lt;code id=&#34;mi-text-q2&#34;&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Finally, we should consider what happens when \(X_1\) and \(X_2\) carry the same information. They don&amp;rsquo;t
have to be identical signals, provided the transformation is bijective, and in fact we can show this by calculating&lt;/p&gt;
\[
    I(X_1;Y|X_1^2)
\]&lt;p&gt;That is, we just take \(X_1\) and square it to get our second signal. This carries no extra information over \(X_1\),
but certainly looks quite different. Will the conditional mutual information algorithm be able to pick this up?&lt;/p&gt;
&lt;div id=&#34;3d-plot-3&#34;&gt;&lt;/div&gt;
&lt;code id=&#34;mi-text-3&#34;&gt;&lt;/code&gt;
&lt;p&gt;Not a problem! In fact, this plot gives us a clear example of what \(X_1\) and \(X_2\) carrying the same
information looks like. Just like earlier where thin, sharp lines meant high mutual information, the same
shapes on the x1-x2 plane imply zero conditional mutual information.&lt;/p&gt;
&lt;script type=&#34;module&#34;&gt;
import {get_2d_mi_chart, get_3d_mi_chart} from &#34;./mi_charts.js&#34;;
let x = Array(10_000).fill(0).map((_) =&gt; Math.random() * 20);
let y = Array(10_000).fill(0).map((_) =&gt; (Math.random() - 0.5) * 10);
let z = x.map((xi, i) =&gt; 0.25 * Math.sin(xi) * Math.sin(y[i]) * xi * y[i] + Math.random() * 0.5);
//
import {mutual_information, partial_mutual_information} from &#34;./knn.js&#34;;
spawn_plot(&#34;2d-hero-plot&#34;, (id) =&gt; get_2d_mi_chart(id, x.map((xi, i) =&gt; [xi, z[i]]), 5));
;
// 
spawn_plot(&#34;2d-hero-plot-x2&#34;, (id) =&gt; get_2d_mi_chart(id, y.map((xi, i) =&gt; [xi, z[i]]), 5));
// 
spawn_plot(&#34;3d-plot&#34;, (id) =&gt; get_3d_mi_chart(id, x.map((xi, i) =&gt; [xi, y[i], z[i]]), 5));
//
spawn_plot(&#34;3d-plot-2&#34;, (id) =&gt; get_3d_mi_chart(id, x.map((xi, i) =&gt; [x[(i + 1) % x.length], y[i], z[i]]), 5));
//
spawn_plot(&#34;3d-plot-3&#34;, (id) =&gt; get_3d_mi_chart(id, x.map((xi, i) =&gt; [xi, xi**2, z[i]]), 5));

let queue = [
    [[&#34;MI&#34;, x.map((x, i) =&gt; [x, z[i]]), 5],
    (e) =&gt; {document.getElementById(&#34;mi-text-2d&#34;).textContent = `Estimated I(X1;Y) = ${e.data}`;}],
    [[&#34;MI&#34;, y.map((x, i) =&gt; [x, z[i]]), 5],
    (e) =&gt; {document.getElementById(&#34;mi-text-2d-x2&#34;).textContent = `Estimated I(X2;Y) = ${e.data}`;}],
    [[&#34;PMI&#34;, x, y, z, 5], 
    (e) =&gt; {document.getElementById(&#34;mi-text&#34;).textContent = `Estimated I(X1;Y|X2) = ${e.data}`;}],
    [[&#34;PMI&#34;, y, z, x.map((_, i) =&gt; x[(i+1)%x.length]), 5],
    (e) =&gt; {document.getElementById(&#34;mi-text-2&#34;).textContent = `Estimated I(X2;Y|Q) = ${e.data}`;}],
    [[&#34;PMI&#34;, y.map((_, i) =&gt; x[(i+1)%x.length]), z, y, 5],
    (e) =&gt; {document.getElementById(&#34;mi-text-q2&#34;).textContent = `Estimated I(Q;Y|X2) = ${e.data}`;}],
    [[&#34;PMI&#34;, x, z, x.map((x) =&gt; x**2), 5],
    (e) =&gt; {document.getElementById(&#34;mi-text-3&#34;).textContent = `Estimated I(X1;Y|X1^2) = ${e.data}`;}]
];
const worker = new Worker(&#34;worker.js&#34;, { type: &#34;module&#34; });

let i = 0;

worker.onmessage = (e) =&gt; {
    // call the most recent callback
    queue[i][1](e);  

    i += 1;
    if (i &gt; queue.length) {
        // exit the loop
        worker.onmessage = () =&gt; {};
    } else {
        // send the next job
        worker.postMessage(queue[i][0]);
    }
}

worker.postMessage(queue[0][0]);


&lt;/script&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Well done for making it all this way! If you, like me, started this article without a solid grasp on what information
entropy actually is, I hope you now have an intuitive feeling for not just what it represents, but why it might be useful.&lt;/p&gt;
&lt;p&gt;More than that, I hope you&amp;rsquo;ve been able to see how even quite involved information theory measures like &lt;em&gt;conditional
mutual information&lt;/em&gt; can be explained geometrically. If a few of the concepts haven&amp;rsquo;t quite clicked - that&amp;rsquo;s ok! Come back
in a few days when you&amp;rsquo;ve had some time to think about it, play around with the plots again, and try and understand
&lt;em&gt;why&lt;/em&gt; a given plot has high or low entropy, mutual information, or partial mutual information.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Why Is Measuring Composition So Difficult?</title>
      <link>https://willsnell.com/posts/math_composition/</link>
      <pubDate>Sat, 12 Oct 2024 19:57:00 +1300</pubDate>
      
      <guid>https://willsnell.com/posts/math_composition/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;This post was inspired by, and heavily leans upon, the structure set out in
&lt;a href=&#34;https://transformer-circuits.pub/2021/framework/index.html&#34;&gt;&amp;ldquo;A Mathematical Framework for Transformer Circuits.&amp;rdquo;&lt;/a&gt;
In it, the authors present
a compelling way to decompose the transformer architecture into individual,
more interpretable pieces. &lt;br&gt;
&lt;br&gt;
If you haven&amp;rsquo;t read it yet, I&amp;rsquo;d recommend doing so. Most of what I present
won&amp;rsquo;t make sense without context.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;A transformer&amp;rsquo;s ability to process long sequences of text is
facilitated by multiple attention layers, which we can decompose into
multiple attention &lt;em&gt;heads&lt;/em&gt; per layer.&lt;/p&gt;</description>
      <content>&lt;blockquote&gt;
&lt;p&gt;This post was inspired by, and heavily leans upon, the structure set out in
&lt;a href=&#34;https://transformer-circuits.pub/2021/framework/index.html&#34;&gt;&amp;ldquo;A Mathematical Framework for Transformer Circuits.&amp;rdquo;&lt;/a&gt;
In it, the authors present
a compelling way to decompose the transformer architecture into individual,
more interpretable pieces. &lt;br&gt;
&lt;br&gt;
If you haven&amp;rsquo;t read it yet, I&amp;rsquo;d recommend doing so. Most of what I present
won&amp;rsquo;t make sense without context.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;A transformer&amp;rsquo;s ability to process long sequences of text is
facilitated by multiple attention layers, which we can decompose into
multiple attention &lt;em&gt;heads&lt;/em&gt; per layer.&lt;/p&gt;
&lt;p&gt;Because all information moving between tokens in a sequence must pass through an attention head,
tracing how they are wired together should give us a circuit diagram of where a good chunk of
the internal information is moving, and might let us
decompose the monolithic transformer into many smaller, interconnected pieces.&lt;/p&gt;
&lt;p&gt;While MLPs can and do move information, attention heads can &lt;em&gt;only&lt;/em&gt; move and scale information,
and do so in an almost linear way.&lt;/p&gt;
&lt;p&gt;We have a strong motivation to want to analyse a model by direct inspection of its weights,
rather than by actually using the model for inference. Firstly, running models can be computationally expensive, while
inspecting weights is typically quite cheap.
Secondly, if we have to run the model, we need data for it to process. If we want to make
strong conclusions about our observations, we need a breadth and depth of data, and often
we need to curate the data appropriately. Direct inspection of weights bypasses all of that - the
numbers that make up the model are unchanging (once trained) and easily accessible.&lt;/p&gt;
&lt;p&gt;If we can treat attention head information movement as linear, we gain access to a host of linear
algebra tools to analyse the system. The promise of this approach is a large and reasonably comprehensive circuit diagram,
purely by inspecting the values of the models&amp;rsquo; various weight matrices.&lt;/p&gt;
&lt;p&gt;I am not the first to try and measure composition this way. In
&lt;a href=&#34;https://transformer-circuits.pub/2021/framework/index.html&#34;&gt;A Mathematical Framework&lt;/a&gt;,
the authors use the Frobenius norm to measure how much two heads compose with one another.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&#34;https://www.lesswrong.com/posts/vaHxk9jSfmGbzvztT/thoughts-on-formalizing-composition&#34;&gt;Thoughts on Formalizing Composition&lt;/a&gt;,
Lieberum takes this further, axiomatizing what it means to measure composition. These axioms can
be summarized (imprecisely) as follows:&lt;/p&gt;
&lt;h3 id=&#34;lieberums-axioms&#34;&gt;Lieberum&amp;rsquo;s Axioms&lt;/h3&gt;
\[B \in \mathbb{R}^{m \times n}, \;A \in \mathbb{R}^{n \times m}\]&lt;p&gt;\(A\) is the matrix in an early head that &lt;strong&gt;writes to&lt;/strong&gt; the residual stream.&lt;/p&gt;
&lt;p&gt;\(B\) is the matrix in a later head that &lt;strong&gt;reads from&lt;/strong&gt; the residual stream.&lt;/p&gt;
\[C(A,B)\]&lt;p&gt;\(C \) takes the two matrices and outputs some kind of a score.&lt;/p&gt;
&lt;h4 id=&#34;axiom-1&#34;&gt;Axiom 1:&lt;/h4&gt;
&lt;p&gt;If \(C(A,B) = 1\) - that is, two heads are composing as much as possible - \(A\) should only
write where \(B\) can read.&lt;/p&gt;
&lt;h4 id=&#34;axiom-2&#34;&gt;Axiom 2:&lt;/h4&gt;
&lt;p&gt;If \(C(A,B) = 0\) - the two heads are not composing at all - \(B\) cannot read anything that
\(A\) writes.&lt;/p&gt;
&lt;h4 id=&#34;axiom-3&#34;&gt;Axiom 3:&lt;/h4&gt;
&lt;p&gt;\(C\) should vary &amp;lsquo;smoothly&amp;rsquo; and &amp;lsquo;monotonically&amp;rsquo; in some sense, i.e. if there is more overlap, then \(C\)
should be larger, and vice versa.&lt;/p&gt;
&lt;p&gt;Axiom 3 is fairly complicated, and really says 2 different things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;\(C\) should be smooth: We cannot just count the number of overlapping dimensions
between our writing and reading heads. Instead, there now exists a grey area where
a writing dimension partially overlaps a reading dimension, and our metric must account
for this. In some sense, we can describe this as how much the reading head is &amp;ldquo;focused&amp;rdquo;
on the writing head, versus just randomly reading in some of its outputs as background noise.&lt;/li&gt;
&lt;li&gt;\(C\) should be monotonic: More overlap should lead to a higher \(C\) score.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We can extend this definition to make it more rigorous, in the spirit of what Axiom 3 was trying
to convey. We will then show that, assuming communication in the residual stream is linear (i.e. ignoring input norm and MLPs),
none of the current methods for analysing composition meet axioms 3 and 4.&lt;/p&gt;
&lt;h4 id=&#34;proposed-axiom-4&#34;&gt;(Proposed) Axiom 4:&lt;/h4&gt;
&lt;p&gt;\(C\) should measure the underlying information flow, and thus the relative ordering of composition scores between
pairs of heads should be preserved when the model is changed in a way that does not affect information flow.&lt;/p&gt;
\[
\begin{align}
C(A^*, B^*) &gt; C(A^*, D^*) &amp;\iff C(A, B) &gt; C(A, D) \\
\\
    \text{Where } A^* &amp;= T\:A \\
    B^* &amp;= T^{-1}\:B \\
    D^* &amp;= T^{-1}\:D \\
\end{align}
\]&lt;p&gt;Where \(T\) is an invertible matrix which exploits a symmetry of the model to leave information flow unchanged.&lt;/p&gt;
&lt;p&gt;A concrete example of \(T\) which will effectively always work is&lt;/p&gt;
\[
T = \begin{bmatrix}
        0&amp; 1&amp; ... &amp;0\\
        1&amp; 0&amp; ... &amp;0\\
        \vdots &amp; \vdots &amp; \vdots &amp; \vdots\\
        0 &amp;... &amp;...  &amp; 1\\
\end{bmatrix}
\]&lt;p&gt;That is, we simply swap the order of the first and second residual stream directions, and leave everything
else unchanged. Heads which previously wrote to direction 1 will now write to direction 2, and vice versa.
A head which previously read from direction 1 will now read from direction 2, etc. The actual information
flow has not changed, and we have effectively just relabelled the axes.&lt;/p&gt;
&lt;p&gt;All our typical tools for measuring composition easily survive this relabelling, and so they should!
We will see through the remainder of this post that there are subtler manipulations we can use which
pose actual problems if we hope to meet axioms 3 and 4.&lt;/p&gt;
&lt;h1 id=&#34;linear-analysis&#34;&gt;Linear Analysis&lt;/h1&gt;
&lt;p&gt;Following the work in &lt;a href=&#34;https://transformer-circuits.pub/2021/framework/index.html&#34;&gt;[1]&lt;/a&gt; and
&lt;a href=&#34;https://www.lesswrong.com/posts/vaHxk9jSfmGbzvztT/thoughts-on-formalizing-composition&#34;&gt;[2]&lt;/a&gt;,
we will begin by ignoring MLP layers and layer normalization. We know that both of these
non-linearities can contribute to information movement, and hence composition. Later on,
we&amp;rsquo;ll touch on layer normalization.&lt;/p&gt;
&lt;p&gt;For now, removing them gives us purely linear communication from component to component
in the residual stream.&lt;/p&gt;
&lt;h2 id=&#34;the-unavoidable-symmetries-of-the-residual-stream&#34;&gt;The unavoidable symmetries of the residual stream.&lt;/h2&gt;
&lt;h4 id=&#34;symmetries-inside-heads&#34;&gt;Symmetries &lt;em&gt;Inside&lt;/em&gt; Heads&lt;/h4&gt;
&lt;p&gt;&amp;ldquo;A Mathematical Framework&amp;rdquo; points out that the specific
vector we get when looking inside a transformer head is not
particularly meaningful. We&amp;rsquo;ll work through the OV-circuit
to show why this is the case.&lt;/p&gt;
&lt;p&gt;Denoting the residual stream a given head can read from as \(\vec{x}_0\), the residual stream the same
head writes to as \(\vec{x}_1\), and
the hidden layer inside the head itself as \(\vec{y}\), the OV circuit is implemented as:&lt;/p&gt;
\[
\begin{align}
    \vec{x}_1 &amp;= W_O\:\vec{y} \\
    \vec{y}   &amp;= W_V\:\vec{x}_0
\end{align}
\]&lt;p&gt;We can make \(\vec{y}\) disappear by combining the O and V matrices, without any
loss of generality:&lt;/p&gt;
\[
\begin{align}
    \vec{x}_1 &amp;= (W_O W_V) \vec{x}_0 \\
              &amp;= W_{OV} \vec{x}_0 \\
\end{align}
\]&lt;p&gt;It&amp;rsquo;s common to think of the combination of the \(W_O\) and \(W_V\) matrices
as a single low-rank matrix \(W_{OV}\), exactly because we have so many
different ways to slice up \(W_O\) and \(W_V\), all of which are valid.&lt;/p&gt;
&lt;p&gt;To be precise, for any invertible matrix of appropriate shape \(T\):&lt;/p&gt;
\[
\begin{align}
    \vec{x}_1 &amp;= W_O\:(T\:T^{-1})\:\vec{y} \\
              &amp;= (W_O\:T)(T^{-1}\:W_V)\:\vec{x}_0 \\
              &amp;= (W_O^*)(W_V^*)\:\vec{x}_0 \\
    \vec{y}^* &amp;= W_V^*\:\vec{x}_0
\end{align}
\]&lt;p&gt;We can pick the basis of \(\vec{y}^*\) by any (invertible) transformation.
The dimensionality of \(\vec{y}^*\) cannot be changed (because then \(T\) wouldn&amp;rsquo;t be invertible),
but otherwise we are free to do whatever we want.&lt;/p&gt;
&lt;p&gt;More than that, we should &lt;strong&gt;expect&lt;/strong&gt; any applicable \(T\) to have &lt;strong&gt;already been applied&lt;/strong&gt; by the time
we are handed our model to analyse.&lt;/p&gt;
&lt;p&gt;Our model and any techniques we apply must respect
that \(\vec{y}\) is &lt;strong&gt;symmetric&lt;/strong&gt; with respect to the
&lt;a href=&#34;https://en.wikipedia.org/wiki/General_linear_group&#34;&gt;group \[\text{GL}_n(\mathbb{R})\]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In other words, there are an infinite collection of \(W_O\)&amp;rsquo;s, and for every one a partner \(W_V\).
However, there is only one unique \(W_{OV}\).&lt;/p&gt;
&lt;p&gt;The same analysis can be applied to the matrix used to compute the dot-product attention, \(W_Q^T\:W_K\).&lt;/p&gt;
&lt;h4 id=&#34;symmetries-between-heads&#34;&gt;Symmetries &lt;em&gt;Between&lt;/em&gt; Heads&lt;/h4&gt;
&lt;p&gt;If we&amp;rsquo;re serious about ignoring LayerNorm (or its equivalent), we can extend this idea of symmetry
outwards, to the residual stream (\(\vec{x}\)) itself.&lt;/p&gt;
&lt;p&gt;Looking at the first few layers, for a single attention head:&lt;/p&gt;
\[
\begin{align}
            \vec{x}_0 &amp;= W_E \\
            \vec{x}_n &amp;= \mathbb{A} \cdot W_O W_V \vec{x}_{n-1} \\
            \mathbb{A} &amp;= f(\vec{x}_{n-1}^T W_Q^T W_K \vec{x}_{n-1}) \\
            \ell &amp;= W_U \vec{x}_{n}
\end{align}
\]&lt;p&gt;Where \(W_E\) is the embedding matrix, \(\mathbb{A}\) is the attention pattern calculated
between sequence positions, and \(\ell\) the log-probabilities.&lt;/p&gt;
&lt;p&gt;(For simplicity, this notation hides the fact that the attention mechanism moves information
between the residual streams of &lt;em&gt;different tokens&lt;/em&gt;, and so we really have &lt;em&gt;many&lt;/em&gt; residual
streams. For the analysis we&amp;rsquo;re doing here, this adds complexity but doesn&amp;rsquo;t provide extra insight.)&lt;/p&gt;
&lt;p&gt;We can multiply anything which writes to the residual stream by an invertible matrix \(T\),
and anything which reads from the residual stream
by its inverse \(T^{-1}\).
The following system is identical to the previous:&lt;/p&gt;
\[
\begin{align}
            T \vec{x}_0 &amp;= T\: W_E \\
\\
            T \vec{x}_n &amp;= \mathbb{A} \cdot T\;W_O W_V\;T^{-1}\;T\vec{x}_{n-1} \\ 
                        &amp;= \mathbb{A} \cdot (T W_O W_V T^{-1})\;T\vec{x}_{n-1} \\ 
\\
            \mathbb{A} &amp;= f((T \vec{x}_{n-1})^T (T^{-1})^T W_Q^T W_K T^{-1}\;T \vec{x}_{n-1}) \\
                       &amp;= f((T \vec{x}_{n-1})^T (T^{-T} W_Q^T W_K T^{-1})\;T \vec{x}_{n-1}) \\
\\
            \ell &amp;= W_U\;T^{-1}\;T\;\vec{x}_{n}\\
\end{align}
\]&lt;p&gt;In other words, there are an infinite family of symmetric models. These are, for all intents and
purposes, &lt;strong&gt;the same model&lt;/strong&gt;, but have completely different weights.&lt;/p&gt;
&lt;p&gt;Just as \(W_O\) and \(W_V\) were not unique in our previous example, the aggregate matrices
\(W_O W_V\) and \(W_Q^T W_K\) are symmetric, and can be arbitrarily modified by our choice of \(T\).
The residual stream is symmetric about the group \(\text{GL}_n\), and (ignoring non-linearities), our
analysis must respect that.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s worth pointing out that \(W_{OV}\) and \(W_Q^T\:W_K\) transform differently.
\(W_{OV}\) transforms by \(T (.) T^{-1}\), while \(W_Q^T\:W_K\) transforms by \(T^{-T}\:(.)\:T^{-1}\).&lt;/p&gt;
&lt;p&gt;The composite matrix \(W_{Q}^TW_K\:W_{OV}\) therefore transforms by \(T^{-T}\:(.)\:T^{-1}\).&lt;/p&gt;
&lt;h4 id=&#34;a-concrete-example&#34;&gt;A Concrete Example&lt;/h4&gt;
&lt;p&gt;To make real the concepts presented above, let&amp;rsquo;s examine the
V-composition scores between one upstream head and two downstream heads, denoted \(W_{OV}^{up}\),
\(W_{OV}^{down, 1}\) and \(W_{OV}^{down, 2}\).&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll describe these matrices using their compact &lt;a href=&#34;https://en.wikipedia.org/wiki/Singular_value_decomposition&#34;&gt;Singular Value Decomposition&lt;/a&gt;.
That is, they are of the form&lt;/p&gt;
\[W_{OV} = U \Sigma V^T\]&lt;p&gt;Where \(U\) is an &lt;em&gt;m x r&lt;/em&gt; rectangular matrix describing where in the residual stream the matrix reads from, \(V\) is an
&lt;em&gt;n x r&lt;/em&gt; matrix which describes where in the residual stream is written to, and \(\Sigma\) describes how the
vectors that are read in are scaled, before being written out. &lt;em&gt;m&lt;/em&gt; is the dimension of the residual stream,
and &lt;em&gt;r&lt;/em&gt; is the rank of the matrix.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s imagine we have a 3-dimensional residual stream, and our \(W_{OV}\) matrices are rank 1 &lt;em&gt;(m=3, r=1)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Lets imagine our matrices are:&lt;/p&gt;
\[
\begin{align}
    W_{OV}^\text{up} = \begin{bmatrix}
                    0 &amp; 5 &amp; 0 \\
                    0 &amp; 0 &amp; 0 \\
                    0 &amp; 0 &amp; 0 \\
                  \end{bmatrix}
                =
                  \begin{bmatrix} 
                        1 \\
                        0 \\
                        0 \\
                  \end{bmatrix}
                  \begin{bmatrix}
                        5 \\
                  \end{bmatrix}
                  \begin{bmatrix}
                        0 &amp; 1 &amp; 0 \\
                  \end{bmatrix}
\end{align}
\]&lt;p&gt;The &lt;em&gt;3 x 3&lt;/em&gt; matrix in the middle is the expanded form, and the 3 matrices on the right are
\(U\), \(\Sigma\), and \(V^T\), respectively.&lt;/p&gt;
&lt;p&gt;\(U\) tells us this matrix reads exclusively from the first dimension of the residual stream,
\(\Sigma\) tells us it multiplies what it reads by 5, and \(V\) tells us it writes the result
to the second dimension of the residual stream.&lt;/p&gt;
&lt;p&gt;For our remaining two matrices, we&amp;rsquo;ll just look at the SVD form:&lt;/p&gt;
\[
\begin{align}
    W_{OV}^\text{down,1} = \begin{bmatrix} 
                        0 \\
                        \frac{1}{\sqrt{2}} \\
                        \frac{1}{\sqrt{2}} \\
                  \end{bmatrix}
                  \begin{bmatrix}
                        1 \\
                  \end{bmatrix}
                  \begin{bmatrix}
                        0 &amp; 0 &amp; 1 \\
                  \end{bmatrix}
\end{align}
\]\[
\begin{align}
    W_{OV}^\text{down,2} = \begin{bmatrix} 
                        \frac{1}{\sqrt{2}} \\
                        \frac{1}{\sqrt{2}} \\
                        0 \\
                  \end{bmatrix}
                  \begin{bmatrix}
                        1 \\
                  \end{bmatrix}
                  \begin{bmatrix}
                        0 &amp; 0 &amp; 1 \\
                  \end{bmatrix}
\end{align}
\]&lt;p&gt;Right now, we might expect the composition scores of our two downstream heads to be the same. Why?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The angle between their reading vectors and the vector \(W_{OV}^\text{up}\) writes to
are the same.&lt;/li&gt;
&lt;li&gt;They both scale what they read by the same amount&lt;/li&gt;
&lt;li&gt;They both write to the same dimension&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we pick a composition measure such as proposed by &lt;a href=&#34;https://docs.google.com/presentation/d/1sDvhes-36GjUJxHtmya33alggx0gA0o0kOnC8NK6rZE/edit#slide=id.g132679aefe9_0_596&#34;&gt;Turner &amp;amp; Strand&lt;/a&gt;,
we should see that we do, indeed, get identical scores:&lt;/p&gt;
\[
    C(A, B) = \frac{\vert \vert BA \vert \vert_F }{\vert \vert \sigma^B \odot \sigma^A \vert \vert_2}
\]&lt;p&gt;Where \(\vert \vert . \vert \vert_F\) is the Frobenius norm, \(\sigma^A\) and \(\sigma^B\) are the
singular values of A and B, and \(\odot\) is the elementwise product.&lt;/p&gt;
\[
\begin{align}
C(W_{OV}^\text{down,1}, W_{OV}^\text{up}) &amp;\approx 0.707 \\
C(W_{OV}^\text{down,2}, W_{OV}^\text{up}) &amp;\approx 0.707 \\
\end{align}
\]&lt;p&gt;However, we can manipulate these composition scores by
warping the residual stream. Let&amp;rsquo;s choose a transformation matrix&lt;/p&gt;
\[ T = \begin{bmatrix}
        1 &amp; 0 &amp; 0 \\
        0 &amp; 1 &amp; 0 \\
        0 &amp; 0 &amp; 10 \\
        \end{bmatrix}
\]&lt;p&gt;Likewise,&lt;/p&gt;
\[ T^{-1} = \begin{bmatrix}
        1 &amp; 0 &amp; 0 \\
        0 &amp; 1 &amp; 0 \\
        0 &amp; 0 &amp; 0.1 \\
        \end{bmatrix}
\]&lt;p&gt;That is, we increase the magnitude of direction 3 by 10x, and leave directions 1 and 2 unchanged.
By our transformation rules from above, \(W_{OV} \rightarrow T W_{OV} T^{-1} \).&lt;/p&gt;
&lt;p&gt;Note: we have &lt;strong&gt;not&lt;/strong&gt; modified anything about the information flow (as explained in the previous section).
However, our new scores are:&lt;/p&gt;
\[
\begin{align}
C(W_{OV}^\text{down,1}, W_{OV}^\text{up}) &amp;\approx 0.0995 \\
C(W_{OV}^\text{down,2}, W_{OV}^\text{up}) &amp;\approx 0.707 \\
\end{align}
\]&lt;p&gt;If we wanted to make \(C(W_{OV}^\text{down,1}, W_{OV}^\text{up})\) higher than
\(C(W_{OV}^\text{down,2}, W_{OV}^\text{up})\), we could scale &lt;strong&gt;down&lt;/strong&gt; direction 3
by 10x (i.e. swap the definition of \(T\) and \(T^{-1}\)) and we&amp;rsquo;d get the opposite
effect.&lt;/p&gt;
&lt;p&gt;In other words, we can swap the order of our two composition scores at will. We can also
make the scores for a particular set of heads very close to 0, or very close to 1. There
are some caveats:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We need the downstream matrices to read from slightly different directions
to one another, lest we be unable to separate them&lt;/li&gt;
&lt;li&gt;We need the composition score to not start at 0 or 1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For real matrices in real models, these conditions are effectively always met.&lt;/p&gt;
&lt;h4 id=&#34;why-does-this-matter&#34;&gt;Why does this matter?&lt;/h4&gt;
&lt;p&gt;\(\text{GL}_N(\mathbb{R})\) is a very extensive group. Not only does it contain the group
of all rotations and reflections \(\text{O}(n)\), but it allows us to arbitrarily scale
different directions of the residual stream, or shear different directions to bring them
arbitrarily close together (but never parallel), or far apart.&lt;/p&gt;
&lt;p&gt;If we continue to work in this symmetric basis, we are left with very few linear algebra tools
to measure composition
that could not be confounded by an adversarial choice of \(T\). To enumerate:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We can&amp;rsquo;t rely on the angle between vectors (e.g. writing directions vs reading directions)
to be meaningful (unless they are exactly parallel or perpendicular), because a small angle could
just be the result of an adversarial \(T\) shearing directions to be close together.&lt;/li&gt;
&lt;li&gt;We can&amp;rsquo;t rely on the ordering of singular values (or eigenvalues). A singular value could be large
merely because an adversarial \(T\) scaled down the direction in the residual stream we
are reading from, or scaled up the direction we are writing to.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;a-way-out&#34;&gt;A Way Out&lt;/h4&gt;
&lt;p&gt;Possible ways to get out of this symmetry are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Observe the model during runtime, collecting statistics on the residual stream directions.
Use this data to rescale the residual stream to something more regular (assuming such a regularization
exists).&lt;/li&gt;
&lt;li&gt;Gather statistics of the weight matrices of the model, which exploit the fact
that the same \(T\) and \(T^{-1}\) must be applied to all heads in the model at the same time,
and use these to normalize our measures of composition.&lt;/li&gt;
&lt;li&gt;Perform the measurements in a way that removes the symmetry.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Option 2 is actually fairly easy to do without leaving our linear world. This uses the same technique
that gave us the \(W_{OV}\) combined matrix, namely: climb out of the hidden layer where the symmetry exists.&lt;/p&gt;
&lt;p&gt;Instead of analysing \(W_{OV}\) and \(W_{QK}\) within the residual stream,
we analyse them in the token space. That is, when performing measurements,
instead of considering \(W_{OV}\) we consider&lt;/p&gt;
\[
        W_U W_O W_V W_E = W_U\:T^{-1}\:T\:W_O W_V\:T^{-1}\:T\:W_E \\
\]&lt;p&gt;and instead of \(W_Q^T\:W_K\), we look at&lt;/p&gt;
\[
        W_E^T W_Q^T W_K W_E = W_E^T\:(T\:T^{-1})^T W_Q^T\;W_K\:T^{-1}\:T\:W_E \\
\]&lt;p&gt;This is a lot more unwieldy, given we&amp;rsquo;ve gone from a ~1,000 dimensional space to 50,000+.
But, it does mean that all our linear analysis tools start working again.&lt;/p&gt;
&lt;p&gt;Operating in the token space works because \(W_E\) only ever receives one-hot vectors,
and \(W_U\) must output into the token space for decoding, and so neither are symmetric
(beyond global scaling, which can be easily ignored.)&lt;/p&gt;
&lt;h1 id=&#34;what-about-normalization&#34;&gt;What about Normalization?&lt;/h1&gt;
&lt;p&gt;Our linear model is well and good, but real transformers have normalization between reading the residual stream
and feeding it into the Q, K, and V matrices. Adding normalization to our simplified transformer:&lt;/p&gt;
\[
\begin{align}
            \vec{x}_0 &amp;= W_E \\
            \vec{x}_n &amp;= \mathbb{A} \cdot W_O W_V\;\mathcal{G}(\vec{x}_{n-1}) \\
            \mathbb{A} &amp;= f(\mathcal{G}(\vec{x}_{n-1})^T W_Q^T W_K\:\mathcal{G}(\vec{x}_{n-1})) \\
            \ell &amp;= W_U\;\mathcal{G}(\vec{x}_{n})
\end{align}
\]&lt;p&gt;Where \(\mathcal{G}\) is a non-linear normalization function.&lt;/p&gt;
&lt;p&gt;For our purposes, we&amp;rsquo;ll consider &lt;a href=&#34;https://arxiv.org/pdf/1910.07467&#34;&gt;RMS norm&lt;/a&gt;, used
in models like LLaMA and Gemma. This has the functional form:&lt;/p&gt;
\[
\begin{align}
            \mathcal{G}(\vec{x}) = \frac{\vec{x}}{\text{RMS}(\vec{x})} \\
            \\
            \text{where RMS}(\vec{x}) = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} x_i^2} \\ 
\end{align}
\]&lt;p&gt;Importantly for us, although the residual stream is still symmetric with this transformation,
it is only symmetric with respect to a matrix \(R\) that preserves the relation:&lt;/p&gt;
\[
\begin{align}
            R^{-1}\:\mathcal{G}(R\:\vec{x}) &amp;= \mathcal{G}(\vec{x})\\
            \therefore \mathcal{G}(R\:\vec{x}) &amp;= R \mathcal{G}(\vec{x})\\
\end{align}
\]&lt;p&gt;\(\text{RMS}(\vec{x})\) is just \(\frac{1}{\sqrt{n}} \cdot \vert \vert \vec{x} \vert \vert_2\), and
so we can satisfy this relation with any matrix \(R\) that scales all distances from the origin by the
same value, \(\alpha\). This gives us the group \(\mathcal{O}(n)\) in combination with any scalar \(\alpha\) applied
globally.&lt;/p&gt;
&lt;p&gt;Because \(\mathcal{O}(n)\) comprises all the reflections and rotations about the origin, it preserves not only
angles between vectors, but also the magnitude of singular values. In some sense, RMS norm leaves us only with
the most boring symmetries, implying &lt;strong&gt;all&lt;/strong&gt; of our typical tools for measuring composition should be valid.&lt;/p&gt;
\[
            W_U\:W_{OV}\:W_E \neq W_U\:W_{OV}\:\mathcal{G}(W_E)\\
\]&lt;h2 id=&#34;things-get-murkier&#34;&gt;Things Get Murkier&lt;/h2&gt;
&lt;p&gt;Real models use input normalizations, and so we should be able to conclude that the residual stream in a real
model is unique, modulo a rotation, reflection, or global scaling. Hence, any metric which is
invariant under these simple symmetries (the inner product, for one, or the relative sizes of singular values)
can be used to measure interactions in the residual stream.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;However&lt;/strong&gt;, things are unfortunately not so simple. There is no clear consensus on what normalization does
at inference time, nor on whether its impact is meaningful:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2409.13710&#34;&gt;Heimersheim&lt;/a&gt; removed LayerNorm entirely from GPT-2. After fine-tuning,
the resulting model performed almost as well as the original.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1911.07013&#34;&gt;Xu et. al&lt;/a&gt; find that LayerNorm provides most of its benefits by regularizing
&lt;strong&gt;gradients&lt;/strong&gt; during &lt;strong&gt;backpropagation&lt;/strong&gt;. They trained and evaluated models with LayerNorm, without LayerNorm, and with DetachNorm,
which behaves like LayerNorm but does not allow the gradients of the mean and variance terms to back-propagate.
DetachNorm performs the worst of the three, suggesting LayerNorm&amp;rsquo;s benefit does not originate from
its effect at inference time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://aclanthology.org/2023.findings-acl.895.pdf&#34;&gt;Brody, Alon, &amp;amp; Yahav&lt;/a&gt; argue the opposite - that LayerNorm
is crucial to the ability of attention heads to learn and express certain functions easily. A major caveat is that
they studied very small models (8-dimensional residual stream, with 2-dimensional hidden head layers).&lt;/p&gt;
&lt;p&gt;As models grow in size, they suggest the benefits of LayerNorm become less useful.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we really can ignore input normalizations and treat the residual stream as linear, then we are left with a
highly symmetric residual stream and need to use a technique that breaks the symmetry (such as working in token space.)
Actually removing the normalization functions with fine-tuning (as &lt;a href=&#34;https://arxiv.org/pdf/2409.13710&#34;&gt;Heimersheim did&lt;/a&gt;)
is not ideal, because it requires considerable compute and leaves us analysing a different model than what we started with.&lt;/p&gt;
&lt;p&gt;If input normalization &lt;em&gt;is&lt;/em&gt; important to the expressivity and performance of a transformer, there still remains the question
of whether the residual stream is a meaningful-enough basis to analyse it in. As the dimensionality of the residual stream grows,
the impact of
any one direction on the normalization statistics (such as variance) shrinks. It&amp;rsquo;s not hard to imagine scaling up
or down residual stream directions, perhaps enough to reorder the singular values in a few attention heads, without
meaningfully changing the effect of input normalization. We are no longer talking about &lt;strong&gt;identical&lt;/strong&gt; models related by
a perfect symmetry, and so our conclusions are not quite so strong.&lt;/p&gt;
&lt;p&gt;Nonetheless, if we work purely in the residual stream,
there still appears room for inner-products between vectors, or singular values of matrices, to be nudged
such that any score relying on these two metrics could be altered without meaningfully altering how the involved heads communicate
with one another.&lt;/p&gt;
&lt;p&gt;In the formalism of axiom 4, it&amp;rsquo;s hard to prove that two very similar (but not strictly identical) models will always
preserve \(C(A, B) &gt; C(A, D) \therefore C(A^*, B^*) &gt; C(A^*, D^*)\).&lt;/p&gt;
&lt;p&gt;Finally, there&amp;rsquo;s the (reasonably likely) case where the non-linearity offered by input normalization
is used by the model to do something useful, but which is orthogonal to interpretability. Said another way:
a model can transmit (effectively) the same information with a range of transformations \(T\),
but might learn a \(T\) to exploit non-linearities in the model for some other reason. If our composition scores
are sensitive to this \(T\), we can&amp;rsquo;t assume we are measuring composition - and only composition - when we use linear algebra
to compute \(C(A, B)\).&lt;/p&gt;
&lt;h1 id=&#34;whats-next&#34;&gt;What&amp;rsquo;s next?&lt;/h1&gt;
&lt;p&gt;I&amp;rsquo;m fairly convinced at this point that trying to measure composition directly in the residual stream, using
linear algebra tools, is not as straightforward as hoped.
That&amp;rsquo;s not to say, however, that we have no avenues left to pursue. Three options
available are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Analyse composition in the token basis. This lets us confidently work with angles between vectors,
and with relative ordering of (if not the absolute value of) singular values. However, this requires
once again ignoring the effects of input normalization, which I am not yet convinced is completely valid.&lt;/li&gt;
&lt;li&gt;Find some way of normalizing the weight matrices, without resorting to actual model inference, in order
to bolster the linear algebra tools enough that they pass axiom 4.&lt;/li&gt;
&lt;li&gt;Use some kind of inference-time methods that pass data through the network to measure composition. This gives up
a lot of our linear algebra tools, but lets us actually characterise what non-linear parts of the system
(the input normalizations and especially the MLPs) are doing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;rsquo;m currently planning on how to pursue #3 - in particular, I suspect we have a lot of useful information via
the compute graphs and gradient functions embedded in the models, and intended for network training.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Navigating Hyperspace</title>
      <link>https://willsnell.com/posts/hyperspace/</link>
      <pubDate>Tue, 06 Aug 2024 09:55:22 +1200</pubDate>
      
      <guid>https://willsnell.com/posts/hyperspace/</guid>
      <description>Hyperspaces are unintuitive, strange, and fascinating places. Let&amp;rsquo;s explore them together, interactively.</description>
      <content>&lt;script src=&#34;https://cdn.plot.ly/plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;observer.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;math_lib.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;charts.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;vector_math.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;interp.js&#34;&gt;&lt;/script&gt;
&lt;details&gt;
    &lt;summary&gt;&lt;span class=&#34;button&#34; style=&#34;padding: 0.5rem&#34;&gt;Executive Summary&lt;/span&gt;&lt;/summary&gt;
&lt;ul&gt;
&lt;li&gt;In higher dimensional spaces, vectors sampled from typical random distributions
form a hyperspherical shell.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slerp&lt;/code&gt;, a.k.a. &amp;lsquo;spherical linear interpolation&amp;rsquo;, is often recommended for traversing these
spaces instead of linear interpolation (&lt;code&gt;lerp&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;I visualize the formation of these hypershells, and provide some explanations for why they form.&lt;/li&gt;
&lt;li&gt;I present &lt;code&gt;slerp2&lt;/code&gt;, a modification of &lt;code&gt;slerp&lt;/code&gt; which performs better in lower dimensions and for
pessimized cases in higher dimensions.&lt;/li&gt;
&lt;li&gt;I experiment with each interpolation scheme in &lt;a href=&#34;https://github.com/NVlabs/stylegan2-ada-pytorch&#34;&gt;StyleGAN2&amp;rsquo;s&lt;/a&gt;
latent &amp;lsquo;Z&amp;rsquo;-space. In this case, the choice of interpolation scheme makes no difference to the results.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;slerp2-and-higher-dimensional-space-projected&#34;&gt;Slerp2 and Higher-Dimensional Space, Projected&lt;/h1&gt;
&lt;div id=&#34;e_container&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const vec_space_1000 = rand(10_000, 1000);
spawn_plot_with_vector(&#34;e_container&#34;,
    (plot_id, vec_id) =&gt; {
        let redraw_chart = get_interpolated_chart(vec_space_1000, plot_id, slerp2, vec_space_1000[0], vec_space_1000[1],
                                              vecs_to_spherical);
        let widget2 = get_vector_widget(vec_space_1000[0], vec_id, redraw_chart, 1);
        },
);
&lt;/script&gt;
&lt;/details&gt;
&lt;h1 id=&#34;why-explore-hyperspace&#34;&gt;Why explore hyperspace?&lt;/h1&gt;
&lt;p&gt;Hyperspace might seem exotic - and it is - but learning better ways to explore it can be both useful
and (dare I say) fun.&lt;/p&gt;
&lt;p&gt;Spaces with dimensionality higher than 3 or 4 might be outside of our lived experience, but
that doesn&amp;rsquo;t mean they don&amp;rsquo;t exist, or that they can&amp;rsquo;t be useful.
For example, hyperspaces frequently shows up in neural networks. By
learning to explore hyperspace, we can try gain a better understanding
of how they work.&lt;/p&gt;
&lt;p&gt;The motivating
example for this article comes from the sub-field of &lt;a href=&#34;https://developers.google.com/machine-learning/gan&#34;&gt;Generative Adversarial Networks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following portraits were generated by StyleGAN2 &lt;a href=&#34;https://github.com/NVlabs/stylegan2-ada-pytorch&#34;&gt;(Karras, et. al)&lt;/a&gt;:&lt;/p&gt;
&lt;hr&gt;
&lt;div style=&#34;display: flex; justify-content: space-around;&#34;&gt;
&lt;img src=&#34;near_origin_scale/lerp/0.jpg&#34;
alt=&#34;A painting of a woman, looking to the left&#34; style=&#34;box-sizing: border-box; width: calc(min(45%, 400px))&#34;/&gt;
&lt;img src=&#34;near_origin_scale/lerp/1.jpg&#34;
alt=&#34;A painting of a man, looking to the right&#34; style=&#34;box-sizing: border-box; width: calc(min(45%, 400px))&#34;/&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;To dramatically oversimplify, these neural networks take an input vector,
do some transformations on it, and produce an image. The input vector
is typically random noise, and the vector is often quite long - hundreds or thousands of elements long.&lt;/p&gt;
&lt;p&gt;These vectors make up the &lt;strong&gt;latent space&lt;/strong&gt; of the model. Because these
vectors are long, the latent space is high dimensional.
Manipulating the outputs of these models relies on us
being able to chart paths through their latent space.&lt;/p&gt;
&lt;p&gt;As an example: if we want to smoothly blend from the first painting above to the second,
we need a way to traverse from the vector representing one image
to the vector representing the other.&lt;/p&gt;
&lt;h2 id=&#34;the-obvious-answer-is-wrong&#34;&gt;The obvious answer (is wrong)&lt;/h2&gt;
&lt;p&gt;To get from point A to point B, the obvious answer is to go in as straight a
line as possible. The simplest answer here is also the shortest.
Indeed, when working with latent spaces, going in a straight line does generally work,
with varying degrees of success. This is known as linear interpolation (lerp), and
would be written something like this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;lerp&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; start_vec)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;In 3D-space, this looks like:&lt;/p&gt;
&lt;div id=&#34;3d_lerp&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const demo_start = [-0.5012528962436638, -0.9103151253007502, 0.5048315888047492];
const demo_stop = [0.905189016060779, -0.28742159270964684, -0.0913802767988876];
spawn_plot(&#34;3d_lerp&#34;, (div_id) =&gt; {
    let redraw_3d_lerp = get_interpolated_chart(vec_space_1000, div_id, lerp, demo_start, demo_stop,
                                          identity_transform);
    redraw_3d_lerp(3, 0, identity_transform);
}
);
&lt;/script&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: Most of the plots on this page are interactive! Have a play!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While exploring this topic, I came across a &lt;a href=&#34;https://github.com/soumith/dcgan.torch/issues/14&#34;&gt;befuddling thread&lt;/a&gt;
which suggested that the best path was &lt;strong&gt;not, in fact, a straight line&lt;/strong&gt;. Rather, a function called
&lt;code&gt;slerp&lt;/code&gt;, or &amp;ldquo;spherical linear interpolation&amp;rdquo;, was suggested. This has the rather complicated
functional form:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;slerp&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec), stop_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec)), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;# Revert to linear interpolation if the two vectors are pi radians apart&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;            &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; fraction) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_vec &lt;span style=&#34;color:#75715e&#34;&gt;# L&amp;#39;Hopital&amp;#39;s rule/LERP&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fraction)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_vec
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Even more confusingly, when plotted in 3D space, this function gives a path that looks like
this:&lt;/p&gt;
&lt;div id=&#34;3d_slerp&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot(&#34;3d_slerp&#34;, (div_id) =&gt; {
let redraw_3d_slerp = get_interpolated_chart(vec_space_1000, div_id, slerp, demo_start, demo_stop,
                                          identity_transform);
redraw_3d_slerp(3, 0, identity_transform);
});
&lt;/script&gt;
&lt;p&gt;When thinking about what a &amp;ldquo;good&amp;rdquo; interpolation path might look like, a few
different ideas come to mind. We want it to be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Smooth&lt;/em&gt; - in my experience, jagged, jerky paths do not work well
for blending between two latent vectors.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Relatively short&lt;/em&gt;, since we care about capturing the changes
between two specific points, rather than going sightseeing
to irrelevant destinations&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Well-trodden&lt;/em&gt; - We&amp;rsquo;ve trained our neural net on a limited set of data.
If our interpolation takes us far outside anything the neural net
has ever seen, it&amp;rsquo;s unlikely to perform well.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looking at slerp, we can see:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is &lt;em&gt;smooth&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;It doesn&amp;rsquo;t look particularly short. In fact, it&amp;rsquo;s much &lt;em&gt;longer&lt;/em&gt;
than our straight-line path.&lt;/li&gt;
&lt;li&gt;It doesn&amp;rsquo;t seem to stick particularly closely to the data we&amp;rsquo;ve
trained the network on. In fact, it sometimes goes &lt;strong&gt;outside
of our (-1, 1) domain&lt;/strong&gt; entirely!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In 2D and 3D space, linear interpolation simply doesn&amp;rsquo;t have the issues
that slerp does. &lt;strong&gt;Yet, slerp is consistently recommended.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Clearly, something about hyperspace behaves very non-intuitively!&lt;/p&gt;
&lt;p&gt;Strap in&amp;hellip; because it&amp;rsquo;s time to go exploring.&lt;/p&gt;
&lt;h1 id=&#34;windows-into-hyperspace&#34;&gt;Windows into Hyperspace&lt;/h1&gt;
&lt;p&gt;Let&amp;rsquo;s start with the concept of vectors.&lt;/p&gt;
&lt;p&gt;A vector is just a collection of numbers,
arranged in a single column or row, like so:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{3} = \begin{bmatrix}
        1.9 \\
        4.7 \\
        -3.1 \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;An n-dimensional vector is \(n\) items long:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{n} = \begin{bmatrix}
        x_{1} \\
        \vdots \\
        x_{n}
    \end{bmatrix}
\end{align}
\]&lt;p&gt;Vectors can be used to represent all sorts of things, but here we&amp;rsquo;re
going to use them to represent &lt;em&gt;cartesian coordinates&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;1-space&#34;&gt;1-space&lt;/h2&gt;
&lt;p&gt;If we had only 1 spatial dimension to play with, we could represent every
possible position with a 1-dimensional vector:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{1} = \begin{bmatrix}
        x_{1} \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;If we were to fill our space with lots of random points, uniformly
distributed from -1 to 1, it would look like this:&lt;/p&gt;
&lt;div id=&#34;1d_space_chart&#34; class=&#34;plotly&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const vec_space = rand(1000, 1);
spawn_plot(&#34;1d_space_chart&#34;, (div_id) =&gt; {
    get_2d_chart(vec_space, div_id, 0, [&#34;&#34;, &#34;&#34;, &#34;&#34;]);
});
&lt;/script&gt;
&lt;p&gt;Hopefully, this result is pretty unsurprising.&lt;/p&gt;
&lt;h2 id=&#34;2-space&#34;&gt;2-space&lt;/h2&gt;
&lt;p&gt;If we extend our vectors into two dimensions, and perform the same exercise, we&amp;rsquo;ll get
something like this:&lt;/p&gt;
&lt;div id=&#34;2d_space_chart&#34; class=&#34;plotly&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const vec_space_2 = rand(1_000, 2);
spawn_plot(&#34;2d_space_chart&#34;, (div_id) =&gt; {
    get_2d_chart(vec_space_2, div_id, 0, [&#34;&#34;, &#34;&#34;, &#34;&#34;]);
});
&lt;/script&gt;
&lt;p&gt;For every possible location in this space, we can
define an exact point through something like:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{2} = \begin{bmatrix}
        -0.85 \\
        0.24 \\
    \end{bmatrix}
\end{align}
\]&lt;h2 id=&#34;3-space&#34;&gt;3-space&lt;/h2&gt;
&lt;p&gt;Extending up to 3D is quite straightforward, where we
now have 3-long vectors like this:&lt;/p&gt;
&lt;div id=&#34;3_vec&#34;&gt;
\[
\begin{align}
    \vec{v}_{3} = \begin{bmatrix}
        0.26 \\
        -0.88 \\
        -0.9 \\
    \end{bmatrix}
\end{align}
\]
&lt;/div&gt;
&lt;p&gt;Let&amp;rsquo;s again scatter some points uniformly between -1 and 1,
this time in 3 dimensions:&lt;/p&gt;
&lt;div id=&#34;3d_space_chart&#34; style=&#34;width: 100%;&#34;&gt;&lt;/div&gt;
&lt;script&gt;
const vec_space_3 = rand(10_000, 3);
spawn_plot(&#34;3d_space_chart&#34;, (div_id) =&gt; {
    get_3d_chart(vec_space_3, div_id, 0, [&#34;&#34;, &#34;&#34;, &#34;&#34;]);
});
&lt;/script&gt;
&lt;p&gt;We&amp;rsquo;re very used to looking at 3D space through these kinds of visualizations, where
our brain can reconstruct a series of 2D images into a 3D representation.&lt;/p&gt;
&lt;h2 id=&#34;flattening-space&#34;&gt;Flattening Space&lt;/h2&gt;
&lt;p&gt;What if we wanted to look at &lt;strong&gt;this 4D&lt;/strong&gt; vector
inside its vector space:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{4} = \begin{bmatrix}
        0.93  \\
        -0.43 \\
        0.67  \\
        0.12  \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;We could &lt;em&gt;try&lt;/em&gt; using time as an extra dimension,
but we&amp;rsquo;ve already run out of spatial dimensions.&lt;/p&gt;
&lt;p&gt;Of course, we want to go far beyond a mere &lt;em&gt;four&lt;/em&gt; dimensions.
Even if we used time, how would we visualize something like this?&lt;/p&gt;
\[
\begin{align}
    \vec{v}_{1000} = \begin{bmatrix}
        x_{1}      \\
        x_{2}      \\
        \vdots     \\
        x_{1000}   \\
    \end{bmatrix}
\end{align}
\]&lt;h2 id=&#34;projecting&#34;&gt;Projecting&lt;/h2&gt;
&lt;p&gt;To glimpse higher dimensions, we&amp;rsquo;re
necessarily going to need to make compromises.
With &lt;em&gt;up to&lt;/em&gt; 3 dimensions to play with, any given
viewport will need to choose what information to show and what to hide.&lt;/p&gt;
&lt;p&gt;A natural way to project higher dimensions is to just take
the first \(n\) dimensions we can display, and ignore the rest.&lt;/p&gt;
&lt;p&gt;We can visualize what this looks like by creating a vector space
in three dimensions, and visualizing it with two.&lt;/p&gt;
&lt;p&gt;If we want to display the vector:&lt;/p&gt;
\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        0.21   \\
        -0.85  \\
        -0.32  \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;We can display the first 2 elements, i.e.:&lt;/p&gt;
\[
\begin{align}
    \vec{c}_2 = \begin{bmatrix}
        0.21  \\
        -0.85 \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;Where \(\vec{c}_2\) represents a &lt;strong&gt;cartesian projection&lt;/strong&gt;
down to 2 dimensions.&lt;/p&gt;
&lt;p&gt;We can write this as an equation:&lt;/p&gt;
\[
    \vec{v}_3 \mapsto \vec{c}_2
\]&lt;p&gt;Where the arrow \(\mapsto\) means
&amp;ldquo;maps to&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Visualized, it looks like so:&lt;/p&gt;
&lt;div id=&#34;3d_into_2d&#34; style=&#34;width: 100%;&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot(&#34;3d_into_2d&#34;, (div_id) =&gt; {
    get_2d_3d_chart(vec_space_3, div_id);
});
&lt;/script&gt;
&lt;p&gt;We can pick any 2 elements to display, of course.
Representing our 3-space in 2 dimensions could
be done equally validly by picking two different
elements, such as the last element \(x_{3}\)
and the second element \(x_{2}\):&lt;/p&gt;
\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        -0.32 \\
        -0.85 \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;What does our 2D projection tell us about the 3D space?
Well, we effectively get the same view as if we rotated
our 3D view until we were just looking at one face.&lt;/p&gt;
&lt;p&gt;If we&amp;rsquo;re plotting, say, \(x_{1}\) and \(x_{2}\),
we get a perfect understanding of how our points are
distributed in those two dimensions.&lt;/p&gt;
&lt;p&gt;Should we want to know
what portion of points have \(x_{1}\) &amp;gt; 0
and \(x_{2}\) &amp;lt; 0, we can
look at the 2D chart and easily see the answer is
~25%.&lt;/p&gt;
&lt;p&gt;However, we get absolutely no information about the
rest of our vector. It wouldn&amp;rsquo;t matter if we were
plotting a vector of length 3 or a vector of length
3000 - from this viewpoint, they all look the same.&lt;/p&gt;
&lt;h2 id=&#34;different-projections&#34;&gt;Different Projections&lt;/h2&gt;
&lt;p&gt;So far, we&amp;rsquo;ve been exploring space with &lt;em&gt;cartesian&lt;/em&gt; coordinates.&lt;/p&gt;
&lt;p&gt;Without completely justifying it, I&amp;rsquo;m going to introduce
a completely different coordinate system - &lt;a href=&#34;https://en.wikipedia.org/wiki/Spherical_coordinate_system&#34;&gt;spherical coordinates&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most people are used to cartesian coordinates. In the following
image, it seems natural to define the position of the red cross based
on two distances, which we typically call x and y.
&lt;img src=&#34;xy.svg&#34;&gt;&lt;/p&gt;
&lt;p&gt;We could represent this point as a vector:&lt;/p&gt;
\[
\begin{align}
    \vec{v}_2 = \begin{bmatrix}
        x \\
        y \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;In higher dimensions, we can add more directions, provided they are
perpendicular to all the other directions. Hence, for 3d, we might
use (x, y, z).&lt;/p&gt;
&lt;p&gt;In a spherical coordinate system, however, a point in space is defined
not by \(n\) orthogonal coordinates (e.g. x, y, and z), but rather
as a &lt;em&gt;radial distance&lt;/em&gt; \(r\), and then a series of angles.&lt;/p&gt;
&lt;p&gt;To fully describe any point in 2D-space, we need two coordinates.
Since we already have one (the distance from the origin \(r\)),
we need one more. Hence, a 2D spherical coordinate system would have
one angle, \(\theta_1\).&lt;/p&gt;
&lt;img src=&#34;radial.svg&#34;&gt;
&lt;p&gt;We can also represent this point as a vector:&lt;/p&gt;
\[
\begin{align}
    \vec{s}_2 = \begin{bmatrix}
        r          \\
        \theta_{1} \\
    \end{bmatrix}
\end{align}
\]&lt;p&gt;Notice that &lt;strong&gt;both \(\vec{v}_2\) and \(\vec{s}_2\)&lt;/strong&gt; refer to
the exact same point in space. The actual numbers inside the vectors,
and the coordinate &lt;strong&gt;system&lt;/strong&gt; used are very different, but the point
in space is the same.&lt;/p&gt;
&lt;h3 id=&#34;adding-dimensions&#34;&gt;Adding Dimensions&lt;/h3&gt;
&lt;p&gt;In 3-space, we need a third coordinate. For cartesian coordinates, we add z
to our existing x and y. For spherical coordinates, we add
another angle \(\theta_2\).&lt;/p&gt;
&lt;p&gt;These two vectors represent the same position:&lt;/p&gt;
\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        0.54  \\
        -0.87 \\
        0.26  \\
    \end{bmatrix}_{[x,y,z]}
    = \vec{s} = \begin{bmatrix}
        1.06  \\
        -1.02 \\
        1.32  \\
    \end{bmatrix}_{[r, \theta_1, \theta_2]}
\end{align}
\]&lt;h3 id=&#34;why-bother-with-spherical-coordinates&#34;&gt;Why bother with spherical coordinates?&lt;/h3&gt;
&lt;p&gt;How does this help us? After all, you still
need an n-length vector to represent a point in n-space.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s interesting, however, is when you start looking at
higher dimensions. Since the length \(r\) takes into account
the entire vector, plotting the first 2 or 3 elements in the
spherical vector gives us a different view on higher dimensions.&lt;/p&gt;
&lt;p&gt;Importantly, &lt;strong&gt;we always keep the magnitude of the full vector&lt;/strong&gt;
when using spherical coordinates.&lt;/p&gt;
&lt;p&gt;We then get to select 1 angle (for a 2D plot) or 2 angles (for
a 3D plot). These angles represent the relative positioning
between &lt;strong&gt;some, but not all&lt;/strong&gt; elements of the vector.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://willsnell.com/posts/hyperspace/#projecting&#34;&gt;Earlier, we projected higher-dimensional space&lt;/a&gt; into 2D and 3D
cartesian plots. We got to pick 2 elements from our larger vector, and had to
throw away the rest.&lt;/p&gt;
&lt;p&gt;We have to do a similar thing in spherical coordinates. However, we &lt;em&gt;always&lt;/em&gt;
keep the magnitude. This means that we&amp;rsquo;re left with the ability to pick
one angle (for a 2d plot) or 2 angles (for a 3d plot) from our larger
vector.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Below, you can increase the dimensionality of the space being
visualized.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Before you do&lt;/strong&gt;, make a guess about what you think
will happen as the number of dimensions increases.&lt;/p&gt;
&lt;p&gt;Remember, we&amp;rsquo;re keeping the &lt;em&gt;vector magnitude&lt;/em&gt;, but
can only keep one angle (for the 2D plot) or 2
angles (for the 3D plot).&lt;/p&gt;
&lt;p&gt;How many dimensions do you think we can plot before
the spherical projection will start to look different
to the cartesian projection?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;spherical&#34; style=&#34;width: 100%;&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;spherical_vec&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;tooltip-1space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 1-space&lt;/p&gt;
&lt;p&gt;1-space is boring as ever&amp;hellip;&lt;/p&gt;
&lt;p&gt;Jump to the next space with the &amp;ldquo;Dimensions (+)&amp;rdquo; button.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-2space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 2-space&lt;/p&gt;
&lt;p&gt;In 2-space, both the 2D and the 3D plot display the same
thing. This is also the exact same view we would get if we were
using cartesian coordinates. Because any 2-length vector losslessly
describes this space, we can freely switch between them without issue.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-3space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Important&lt;/strong&gt;: understanding the 2D and 3D plots at for a 3D space
is critical to understanding the rest of this article. Take the time
to try and wrap your head around the link between these two plots.&lt;/p&gt;
&lt;p&gt;// 3-space&lt;/p&gt;
&lt;p&gt;Our &lt;strong&gt;3D plot&lt;/strong&gt; still holds enough
dimensionality to perfectly represent our vector, and so our view is
identical to the cartesian plot we had earlier. That is,
our mapping \(\vec{v} \mapsto \vec{s}\) is lossless.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;2D plot&lt;/strong&gt;, however, is different. We&amp;rsquo;re fundamentally
losing some information when projecting from \(\vec{v}_3\) to \(\vec{s}_2\).
Notably, even though our points are randomly
distributed between -1 and 1, we are starting to see points shift outside
of that range.&lt;/p&gt;
&lt;p&gt;Remember that the distance from the origin (0, 0) in our 2D plot now
represents the absolute distance from the origin in &lt;strong&gt;n-space&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Questions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Looking at the 3D view of the cube, which points do you think
have a distance to
the origin (a &lt;em&gt;vector magnitude&lt;/em&gt;) greater than 1?&lt;/p&gt;
&lt;p&gt;Interestingly, a hole has started to appear in the centre of the plot.
Why do you think this is?&lt;/p&gt;
&lt;p&gt;What might you expect to see happen as we continue to increase the dimensionality
of our space?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-4space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 4-space&lt;/p&gt;
&lt;p&gt;This is the first space that cannot be fully represented by the
spatial dimensions we have at hand. If you&amp;rsquo;ve been watching the 2D
plot over the last few dimensionalities, you should be able to guess
what&amp;rsquo;s coming for our 3-space plot.&lt;/p&gt;
&lt;p&gt;This is also the first dimensionality where we get multiple 3D and 2D
plots to hop between. By pressing the &amp;ldquo;Elements (-)&amp;rdquo; or &amp;ldquo;Elements (+)&amp;rdquo;
buttons, we can move through the vector, choosing different elements
to act as the &amp;ldquo;direction&amp;rdquo; component of our spherical projection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;tooltip-5space&#34; style=&#34;display: none;&#34;&gt;
&lt;blockquote&gt;
&lt;p&gt;// 5-space and beyond&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll leave you be as you explore the next few dimensions.&lt;/p&gt;
&lt;p&gt;Have a play around, and try and build an intuition for
what these charts are telling you about the spaces.&lt;/p&gt;
&lt;p&gt;Remember, the &lt;strong&gt;Dimensions&lt;/strong&gt; buttons change the dimensionality
of the underlying vector space, and the &lt;strong&gt;Elements&lt;/strong&gt; buttons
change which elements of \(\vec{v}\) we&amp;rsquo;re using to calculate
\(\theta_1\) and \(\theta_2\).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;p&gt;You can also change the noise distribution to:
&lt;span&gt;&lt;button id=&#34;noise_gaussian&#34; style=&#34;display: block;&#34; onclick=&#34;
// change which button is displayed
document.getElementById(&#39;noise_uniform&#39;).style.display = &#39;block&#39;;
document.getElementById(&#39;noise_gaussian&#39;).style.display = &#39;none&#39;;
// redraw the last chart
selected_space = gaussian_space_1000;
redraw_proj(selected_space);
&#34;&gt;gaussian&lt;/button&gt;&lt;/span&gt;
&lt;span&gt;&lt;button id=&#34;noise_uniform&#34; style=&#34;display: none;&#34; onclick=&#34;
// change which button is displayed
document.getElementById(&#39;noise_gaussian&#39;).style.display = &#39;block&#39;;
document.getElementById(&#39;noise_uniform&#39;).style.display = &#39;none&#39;;
// redraw the last chart
let selected_space = vec_space_1000;
redraw_proj(selected_space);
&#34;&gt;uniform&lt;/button&gt;&lt;/span&gt;&lt;/p&gt;
&lt;script&gt;
let dims_with_text = [1, 2, 3, 4, 5];
let gaussian_space_1000 = randn(10000, 1000);
// keep the button and plots in sync through despawn/respawn
let selected_space = vec_space_1000;
function redraw_proj(vector_space) {
    document.getElementById(&#39;spherical&#39;).innerHTML = &#39;&#39;;
    document.getElementById(&#39;spherical_vec&#39;).innerHTML = &#39;&#39;;

    let redraw_spherical = get_projected_chart(vector_space, &#39;spherical&#39;, [&#34;&#34;, &#34;&#34;, &#34;&#34;], vecs_to_spherical);
    let callback = (dimensions, slice_offset) =&gt; {
        for (let dim of dims_with_text) {
            if (dim == dimensions) {
                document.getElementById(`tooltip-${dimensions}space`).style.display = &#34;block&#34;;
            } else if (dimensions &gt; dims_with_text[dims_with_text.length - 1]) {
                document.getElementById(`tooltip-${dims_with_text[dims_with_text.length - 1]}space`).style.display = &#34;block&#34;;
            } else {
                document.getElementById(`tooltip-${dim}space`).style.display = &#34;none&#34;;
            }
        }
        redraw_spherical(dimensions, slice_offset);
    }
    let widget = get_vector_widget(vector_space[0], &#39;spherical_vec&#39;, callback, 1);
}
spawn_plot(&#34;spherical&#34;, 
    // spawn
    (div_id) =&gt; {
        redraw_proj(selected_space);
    },
    // custom teardown
    (div_id) =&gt; {
        document.getElementById(&#39;spherical&#39;).innerHTML = &#39;&#39;;
        document.getElementById(&#39;spherical_vec&#39;).innerHTML = &#39;&#39;;
    });
&lt;/script&gt;
&lt;h2 id=&#34;whats-going-on&#34;&gt;What&amp;rsquo;s going on?&lt;/h2&gt;
&lt;p&gt;Our projection has shown us an unintuitive, but true, fact about
hyperspace - as the dimensionality increases, our points converge
to a hyperspherical shell. The radius of this shell scales with
the square root of our initial distribution&amp;rsquo;s variance, \(\sqrt{\sigma^2} = \sigma\),
and with the square root of our dimensionality, \(\sqrt{n}\).&lt;/p&gt;
&lt;p&gt;The exact formula for the radius varies depending on the type of
noise used (results for a &lt;a href=&#34;https://stats.stackexchange.com/questions/317095/expectation-of-square-root-of-sum-of-independent-squared-uniform-random-variable/317475#317475&#34;&gt;uniform distribution&lt;/a&gt;
and this &lt;a href=&#34;https://www.johndcook.com/blog/2011/09/01/multivariate-normal-shell/&#34;&gt;great post with results for normal distributions&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For both uniform and normal distributions, the hyperspherical
shell has a relatively constant thickness as the dimensionality
increases, leading to an increasingly shell-like distribution of points.&lt;/p&gt;
&lt;h3 id=&#34;what-does-this-mean&#34;&gt;What does this mean?&lt;/h3&gt;
&lt;p&gt;In lower dimension spaces (2D, 3D, etc.) the radius of our hypershell
is of the same order as the variance of the distribution. This means
that, in general, there isn&amp;rsquo;t much of a &amp;ldquo;hole&amp;rdquo; at the origin. However,
even in 3D (using our 2D plot), we start to see a gap open up near the
origin.&lt;/p&gt;
&lt;p&gt;Below are two different ways to interpret the
existence of a hyperspherical shell.&lt;/p&gt;
&lt;h4 id=&#34;geometric-interpretation&#34;&gt;Geometric Interpretation&lt;/h4&gt;
&lt;p&gt;As explained in &lt;a href=&#34;https://www.johndcook.com/blog/2011/09/01/multivariate-normal-shell/&#34;&gt;John D. Cook&amp;rsquo;s post&lt;/a&gt;,
volume &lt;strong&gt;grows faster&lt;/strong&gt; in higher dimensions.
For our uniform distribution, our probability density is constant between its bounds of (-1, 1),
and so we can pretty much ignore it.&lt;/p&gt;
&lt;p&gt;Volume, however, is proportional to \(r^n\), where \(r\) is the distance
from the origin and \(n\) is the dimensionality of our space.
If \(n = 1000\) dimensions, the difference between a sphere of radius
0.999 and radius 1.000 is&lt;/p&gt;
\[
1.000^{1000} - 0.99^{1000} \approx 0.9999
\]&lt;p&gt;In other words, &amp;gt;99% of all of our volume is contained in an outer shell, with
thickness of 1% the radius of our space.
The reason this collosal growth of volume with radius is not intuitive, is because
in 3D, the same calculation would give around 3% of the volume in the outermost
shell of our sphere:&lt;/p&gt;
\[
1.000^3 - 0.99^3 \approx 0.03 
\]&lt;p&gt;Hence, even though our probability density function is constant in space,
when we go to higher dimensions, &lt;strong&gt;the amount of space near the origin is astronomically
low, and the amount at the outer perimeter is astronomically high.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Because so much space is so far out, our points will inevitably &amp;ldquo;cluster&amp;rdquo;
there.&lt;/p&gt;
&lt;h4 id=&#34;statistical-interpretation&#34;&gt;Statistical Interpretation&lt;/h4&gt;
&lt;p&gt;We can also think about this result statistically.&lt;/p&gt;
&lt;p&gt;All the elements in our vectors are independent and identically distributed.
The more elements we have, the more we will expect to see strong statistical
trends in the overall properties of our vector, even while individual
elements remain random.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s imagine we&amp;rsquo;re rolling a fair die, with sides labelled 0, 1, 2, 3, 4, and 5.
The expected value of our roll is 2.5, but we wouldn&amp;rsquo;t be surprised with a 0
or a 5.&lt;/p&gt;
&lt;p&gt;If we now roll 2 dice, make a graph, and plot our first roll on the x axis
and our second on the y axis, we again get a fairly even distribution.&lt;/p&gt;
&lt;p&gt;However, if we instead added the total of our two dice together, we
would be looking at a score between 0 and 10, with 5 being our expected value.
Already, our sum is starting to cluster, with 5 much more likely than
either 0 or 10.&lt;/p&gt;
&lt;p&gt;The more dice we roll:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The bigger we expect our total score to be, and&lt;/li&gt;
&lt;li&gt;The less and less likely we are to have a sum near 0 (or near the absolute
highest possible score of \(5 \times n\) rolls.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The same process, roughly, is going on with the magnitude of our vectors.
Instead of just summing our rolls, we&amp;rsquo;re squaring each roll, summing the
squares, and then taking the square root. These functions warp and
compress space a bit, but our intuition should generally still hold.&lt;/p&gt;
&lt;p&gt;We should intuitively expect that the more dice we roll,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The bigger our square-root sum of squares is, and&lt;/li&gt;
&lt;li&gt;The less and less likely we are to have a point near the origin
(or in the corners of our hypercube.)&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;tracing-lines-through-hyperspace&#34;&gt;Tracing Lines Through Hyperspace&lt;/h1&gt;
&lt;p&gt;Hopefully, you now have a solid grip on the spherical projections
we&amp;rsquo;ll be using from this point onwards. Remember, the distance
from a point to the origin in each plot represents the vector magnitude of
the &lt;em&gt;full vector&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Under this lens, what does linear interpolation (our &lt;code&gt;lerp&lt;/code&gt; function from earlier)
look like?&lt;/p&gt;
&lt;div id=&#34;spherical_lerp&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot_with_vector(&#34;spherical_lerp&#34;,
    (plot_id, vec_id) =&gt; {
        let redraw_chart = get_interpolated_chart(vec_space_1000, plot_id, lerp, vec_space_1000[0], vec_space_1000[1],
                                              vecs_to_spherical);
        let widget2 = get_vector_widget(vec_space_1000[0], vec_id, redraw_chart, 1);
        },
);
&lt;/script&gt;
&lt;p&gt;At low dimensions, lerp behaves exactly how we expect it to. But by the time we reach
around 20 dimensions, there&amp;rsquo;s a clear problem. Our linear path is well outside
the bounds of all the points in our vector space.&lt;/p&gt;
&lt;p&gt;As we increase the dimensionality of our space, the problem gets worse. At 1000 dimensions,
lerp spends almost the entirety of its path completely outside of the hyperspherical shell
that makes up the points in our vector space.&lt;/p&gt;
&lt;p&gt;In a machine learning context, this would mean that the interpolation is feeding in data
well outside the bounds of anything the model has been trained on.&lt;/p&gt;
&lt;h2 id=&#34;why-does-lerp-behave-like-this-in-higher-dimensional-spaces&#34;&gt;Why Does Lerp Behave Like This in Higher Dimensional Spaces?&lt;/h2&gt;
&lt;p&gt;To understand why &lt;code&gt;lerp&lt;/code&gt; diverges from our hyperspherical shell in higher
dimensions, we have to think about what it&amp;rsquo;s doing. For each element \(x_i\) in \(\vec{v}^1\)
and \(y_i\) in \(\vec{v}^2\), the output of &lt;code&gt;lerp&lt;/code&gt; can
never be larger than \(\max(x_i, y_i)\) and can never
be smaller than \(\min(x_i, y_i)\). Unless \(x_i\) and \(y_i\) both happen
to fall at exact opposite ends of their distributions, &lt;code&gt;lerp&lt;/code&gt; will necessarily
be operating in a smaller domain.&lt;/p&gt;
&lt;p&gt;Right at the midpoint, where &lt;code&gt;fraction=0.5&lt;/code&gt;, &lt;code&gt;lerp&lt;/code&gt; will give a vector that is
the average of \(\vec{v}^1\) and \(\vec{v}^2\). The average is the point where
all values will be the most &amp;ldquo;smoothed out&amp;rdquo;. Because a particularly large element
is equally likely to appear in \(\vec{v}^1\) or \(\vec{v}^2\), averaging the two
vectors should give the point in the interpolation with minimum variance.
Because the distributions are centred about 0, minium variance corresponds to
minimum distance from the origin.&lt;/p&gt;
&lt;p&gt;If you want to try visualize this, change the &lt;code&gt;lerp&lt;/code&gt; visualization &lt;a href=&#34;https://willsnell.com/posts/hyperspace/#tracing-lines-through-hyperspace&#34;&gt;here&lt;/a&gt;
to have 3 dimensions. Imagine connecting any two points in the space with a
straight line. For every pair of points, the midpoint of a straight line
connecting them is closer to the origin than either point.&lt;/p&gt;
&lt;p&gt;Interestingly enough, the fact that lerp averages between the two vectors means that
the distribution of the vector becomes less and less uniform the closer to &lt;code&gt;fraction=0.5&lt;/code&gt;
we get. But that&amp;rsquo;s a topic for another post.&lt;/p&gt;
&lt;h1 id=&#34;slerp&#34;&gt;Slerp&lt;/h1&gt;
&lt;p&gt;Now that you&amp;rsquo;ve seen &lt;code&gt;lerp&lt;/code&gt; in a spherical projection, it&amp;rsquo;s only fair to
show &lt;code&gt;slerp&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;What do &lt;strong&gt;you&lt;/strong&gt; think will happen as the dimensionality increases?&lt;/p&gt;
&lt;p&gt;Was your intuition right?&lt;/p&gt;
&lt;div id=&#34;spherical_slerp&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot_with_vector(&#34;spherical_slerp&#34;,
    (plot_id, vec_id) =&gt; {
        let redraw_slerp = get_interpolated_chart(vec_space_1000, plot_id, slerp, vec_space_1000[0], vec_space_1000[1],
                                          vecs_to_spherical);
        let widget3 = get_vector_widget(vec_space_1000[0], vec_id, redraw_slerp, 1);
    }
);
&lt;/script&gt;
&lt;h1 id=&#34;what-is-slerp-actually-doing&#34;&gt;What Is Slerp Actually Doing?&lt;/h1&gt;
&lt;p&gt;Remember the definition of the slerp function &lt;a href=&#34;https://willsnell.com/posts/hyperspace/#the-obvious-answer-is-wrong&#34;&gt;from earlier?&lt;/a&gt;
Let&amp;rsquo;s break down where it came from, and what it&amp;rsquo;s actually doing.&lt;/p&gt;
&lt;p&gt;By looking at the projections above, you hopefully have a good intuition for
&lt;em&gt;what&lt;/em&gt; slerp is doing. The hints are in its name - spherical linear interpolation.
The function works by &lt;strong&gt;rotating&lt;/strong&gt; about the origin. Instead of translating from
point A to point B, slerp rotates between the two points, and scales the magnitude
of the vector while doing so.&lt;/p&gt;
&lt;p&gt;As our spherical coordinate projections &lt;a href=&#34;https://willsnell.com/posts/hyperspace/#why-bother-with-spherical-coordinates&#34;&gt;above showed,&lt;/a&gt;
higher dimensional spaces converge to a hyperspherical shell. To stay in this shell, we
want to orbit around the origin, keeping the vector magnitude (approximately) constant. This
is what slerp does, or tries to do.&lt;/p&gt;
&lt;p&gt;To actually get to the code, we have two parts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Rotating in hyperspace.&lt;/li&gt;
&lt;li&gt;Scaling between the two vectors&amp;rsquo; magnitudes.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Part 1) is provided to us by Shoemake &amp;amp; Davis, in the paper
&lt;a href=&#34;https://dl.acm.org/doi/pdf/10.1145/325334.325242&#34;&gt;Animating Rotation with Quaternion Curves&lt;/a&gt;.
In it, a rotation between two &lt;a href=&#34;https://www.youtube.com/watch?v=zjMuIxRvygQ&#34;&gt;quaternions&lt;/a&gt;,
\(q_1\) and \(q_2\), is given by the formula:&lt;/p&gt;
\[
    \text{Slerp}(q_1, q_2; u) = \frac{\sin( (1 - u)\omega)}{\sin \omega} q_1 + \frac{\sin u\omega}{\sin \omega} q_2
\]&lt;p&gt;Where \(u\) is the &lt;code&gt;fraction&lt;/code&gt; parameter between 0 and 1, and \(q_1 \cdot q_2 = \cos \omega\).&lt;/p&gt;
&lt;p&gt;It turns out that this equation generalizes to n-dimensional vectors. Hence, we have part 1): a function to
rotate from one vector to another. I&amp;rsquo;m unclear how &amp;ldquo;optimal&amp;rdquo; this rotation is, since there are many ways to
rotate between two vectors in hyperspace. However, rotation - or &amp;ldquo;distance preserving linear maps&amp;rdquo; - are
very complicated and dimension-specific, so sticking with a general formula that works is a good plan.&lt;/p&gt;
&lt;p&gt;If we recall the definition of the dot product of two vectors:&lt;/p&gt;
\[
    a \cdot b = \vert \vert a \vert \vert  \space  \vert \vert b \vert \vert \cos \omega
\]&lt;p&gt;Where \(\omega\) is the angle between the two vectors. We need \(\omega\) for our
slerp formula. So, we can rewrite the formula as:&lt;/p&gt;
\[
    \omega = \arccos( \frac{a}{\vert\vert a \vert \vert} \cdot \frac{b}{\vert \vert b \vert \vert} )
\]&lt;p&gt;Another way of thinking about \(\frac{a}{\vert \vert a \vert \vert}\) is that is this is \(\hat{a}\)
(pronounced a-hat) - the unit (length 1) vector which represents only the direction components of a.&lt;/p&gt;
&lt;p&gt;This is indeed what the python slerp function does:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec), stop_vec&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec)), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Now that we have \(\omega\), we can plug it into Shoemake &amp;amp; Davis&amp;rsquo; Slerp, to get:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;start_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;stop_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;new_direction &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fraction)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_hat  &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_hat
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This &lt;strong&gt;isn&amp;rsquo;t&lt;/strong&gt; what the slerp code from &lt;a href=&#34;https://github.com/soumith/dcgan.torch/issues/14&#34;&gt;the DCGAN thread&lt;/a&gt;
does. Rather, this is the actual code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;fraction)&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_vec
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;There&amp;rsquo;s a subtle difference - the vectors used in slerp - above titled \(q_1\) and \(q_2\) are not
normalized. And, rather than just calculating the angle, this line also does part 2), the vector
magnitude scaling.&lt;/p&gt;
&lt;p&gt;What this means is that &lt;code&gt;slerp&lt;/code&gt; is only performing a pure rotation
when \(\vert \vert a \vert \vert \approx \vert \vert b \vert \vert\). In that case,
it&amp;rsquo;s effectively doing this:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;slerp&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||a||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||b||, approx. ||a||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; start_mag &lt;span style=&#34;color:#75715e&#34;&gt;# a_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; stop_mag &lt;span style=&#34;color:#75715e&#34;&gt;# b_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_hat, stop_hat), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; fraction) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; start_mag &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; angle
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When the magnitudes of the two vectors are not particularly close,
such as in lower dimensions, this formula can give quite strange
results. This is exacerbated where the vectors are (almost) pi radians
apart from one another. (Since the vector spaces on this page are randomly
generated, if you refresh a few times, you&amp;rsquo;re bound to see some strange
slerp results in lower dimensions.)&lt;/p&gt;
&lt;p&gt;A slight improvement can be had by explicitly treating the interpolation between
the two vectors&amp;rsquo; magnitudes, and normalizing the vectors before performing the
slerp. This results in visually smoother paths,
and tends to overshoot the data bounds less when there are large changes in vector
magnitude.&lt;/p&gt;
&lt;p&gt;We treat the vector magnitude explicitly, and just linearly interpolate (&lt;code&gt;lerp&lt;/code&gt;) between
the magnitude of the first vector and the magnitude of the second vector. For the
purposes of this article, and at risk of being conceited, I&amp;rsquo;ll call this function &lt;code&gt;slerp2&lt;/code&gt;.
It is moderately more complicated than &lt;code&gt;slerp&lt;/code&gt;. The implementation here is formatted for
readability, not performance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;slerp2&lt;/span&gt;(fraction, start_vec, stop_vec):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(start_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||a||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_mag &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;linalg&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;norm(stop_vec) &lt;span style=&#34;color:#75715e&#34;&gt;# ||b||&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    start_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; start_mag &lt;span style=&#34;color:#75715e&#34;&gt;# a_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    stop_hat &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; stop_vec &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; stop_mag &lt;span style=&#34;color:#75715e&#34;&gt;# b_hat&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    omega &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arccos(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;clip(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dot(start_hat, stop_hat), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    so &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(omega)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    magnitude &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; start_mag &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; (start_mag &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; stop_mag) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; fraction &lt;span style=&#34;color:#75715e&#34;&gt;# lerp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    angle &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;          np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin((&lt;span style=&#34;color:#ae81ff&#34;&gt;1.0&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; fraction) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; start_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(fraction &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; omega) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; so &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; stop_hat
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        )
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; magnitude &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; angle
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;slerp2&#34;&gt;Slerp2&lt;/h1&gt;
&lt;div id=&#34;spherical_slerp2&#34;&gt;&lt;/div&gt;
&lt;script&gt;
spawn_plot_with_vector(&#34;spherical_slerp2&#34;, 
    (plot_id, vec_id) =&gt; {
        let redraw_slerp2 = get_interpolated_chart(vec_space_1000, plot_id, slerp2, vec_space_1000[0], vec_space_1000[1],
                                                  vecs_to_spherical);
        let widget3_2 = get_vector_widget(vec_space_1000[0], vec_id, redraw_slerp2, 1);
    }
);
&lt;/script&gt;
&lt;h1 id=&#34;using-it-in-practice&#34;&gt;Using it in practice&lt;/h1&gt;
&lt;p&gt;It&amp;rsquo;s all well and good talking abstractly of hyperspheres, but
you&amp;rsquo;re probably wondering: does &lt;code&gt;slerp&lt;/code&gt; actually perform better
in real-world applications?&lt;/p&gt;
&lt;p&gt;At the start of this post, I wrote about &lt;code&gt;StyleGAN&lt;/code&gt;. I picked it
because it is a more modern network building on the principals of
other GANs like &lt;a href=&#34;https://arxiv.org/abs/1511.06434v2&#34;&gt;DCGAN&lt;/a&gt;. DCGAN,
you might remember, is where the thread on &lt;code&gt;slerp&lt;/code&gt; originated that
kicked off this whole journey.&lt;/p&gt;
&lt;p&gt;I didn&amp;rsquo;t want to &lt;em&gt;just&lt;/em&gt; explore DCGAN, where there are &lt;a href=&#34;https://github.com/Newmu/dcgan_code/issues/12&#34;&gt;known dead zones
near the origin of the latent space&lt;/a&gt;.
Instead, I wanted to explore whether this is still the case with newer
networks.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;StyleGAN&lt;/code&gt; actually has &lt;strong&gt;two&lt;/strong&gt; latent spaces to explore:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Z-space, which is sampled from a normal distribution with 512 dimensions.&lt;/li&gt;
&lt;li&gt;W-space, which is internal to the network itself and is the result of
&lt;em&gt;learned&lt;/em&gt; transformations on the Z-space vectors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;rsquo;ll probably explore W-space in the future, but for now, Z-space
matches the kind of latent spaces we&amp;rsquo;ve been exploring in this article,
so that&amp;rsquo;s what we&amp;rsquo;ll explore.&lt;/p&gt;
&lt;h2 id=&#34;degenerate-case-1-almost-passing-through-the-origin&#34;&gt;Degenerate Case 1: (Almost) passing through the origin&lt;/h2&gt;
&lt;p&gt;I have a secret to confess: the two portraits I presented at the start of
this article were not exactly &lt;em&gt;randomly&lt;/em&gt; picked. The second portrait is
an (almost) exact opposite of the first - that is, the vector \(\vec{v}^2\)
used to generate the second image was calculated as:&lt;/p&gt;
\[
    \vec{v}^2 = - \vec{v}^1 + \epsilon
\]&lt;p&gt;Where \(\epsilon\) was a very small offset necessary to prevent &lt;code&gt;slerp&lt;/code&gt; and &lt;code&gt;slerp2&lt;/code&gt; from blowing
up with a \(\frac{1}{\sin(0)}\) term. \(\vec{v}^1\) was a random vector
from the correct distribution.&lt;/p&gt;
&lt;p&gt;This means our &lt;code&gt;lerp&lt;/code&gt; from the first portrait to the second is a straight
line (nearly) through the origin.&lt;/p&gt;
&lt;p&gt;This is a degenerate case which should show whether vector magnitude actually
matters. Play around with the slider below to see the results for yourself.&lt;/p&gt;
&lt;div id=&#34;through_origin&#34;&gt;&lt;/div&gt;
&lt;script&gt;
let stylegan_space = randn(1000, 512);
let interp_points = [0.00, 0.14, 0.29, 0.43, 0.57, 0.71, 0.86, 1.00];
fetch(&#34;vecs.json&#34;)
    .then(response =&gt; response.json())
    .then(jvecs =&gt; {
    let start_through_origin = jvecs.z;
    let stop_through_origin = add(mult(jvecs.z, -1), 1e-4);
    spawn_plot(&#34;through_origin&#34;,
        (div_id) =&gt; {
            let redraw = get_multi_interp_chart(stylegan_space, div_id, {lerp: lerp, slerp: slerp, slerp2: slerp2}, start_through_origin, stop_through_origin, 
                                        &#34;./near_origin&#34;, interp_points,
                                        vecs_to_spherical);
        });
    });
&lt;/script&gt;
&lt;p&gt;You can see that the image generated by the &lt;code&gt;lerp&lt;/code&gt;-ed vector doesn&amp;rsquo;t meaningfully change
until passing the origin, where it immediately changes to the output image. This is interesting,
and might suggest that for StyleGAN2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Vector magnitude is unimportant, in comparison to vector direction.&lt;/li&gt;
&lt;li&gt;The learned transformations between Z-space and W-space might discard
magnitude information, or else are only sensitive to magnitude within the
tight range for which all input data (in Z-space) was provided.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;degenerate-case-2-almost-passing-through-the-origin-with-elevation-changes&#34;&gt;Degenerate Case 2: (Almost) passing through the origin with elevation changes&lt;/h2&gt;
&lt;p&gt;This second degenerate case is similar to the first, excepting a slight
change in vector magnitude between \(\vec{v}^1\) and \(\vec{v}^2\). In this case,
I multiplied \(\vec{v}^1\) by 0.9999 and \(\vec{v}^2\) by 1.0001. This was to
see if vector magnitude had an impact on the images produced, and whether
&lt;code&gt;slerp&lt;/code&gt; or &lt;code&gt;slerp2&lt;/code&gt; handled it better.&lt;/p&gt;
&lt;div id=&#34;through_origin_with_scale&#34;&gt;&lt;/div&gt;
&lt;script&gt;
fetch(&#34;vecs.json&#34;)
    .then(response =&gt; response.json())
    .then(jvecs =&gt; {
    let start_scale = mult(jvecs.z, 0.9999);
    let stop_scale = add(mult(jvecs.z, -1.0001), 1e-4);
    spawn_plot(&#34;through_origin_with_scale&#34;,
        (div_id) =&gt; {
            let redraw_scale = get_multi_interp_chart(stylegan_space, div_id, {lerp: lerp, slerp: slerp, slerp2: slerp2}, 
                                                start_scale, stop_scale, &#34;./near_origin_scale&#34;, 
                                                interp_points, vecs_to_spherical);
        });
    });
&lt;/script&gt;
&lt;p&gt;This case exacerbates an odd quirk of &lt;code&gt;slerp&lt;/code&gt; - when vector magnitudes are relatively
different (and when angles are relatively aligned), the interpolation can produce
truly bizarre paths. This is a little unfair on regular &lt;code&gt;slerp&lt;/code&gt;, though, since this case
will statistically never be seen when interpolating between two random vectors.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;slerp2&lt;/code&gt; performs best here, presumably because it most evenly sweeps between angles
from start to finish. But all three interpolators are producing meaningful results.
This is really a testament to the robustness of StyleGAN.&lt;/p&gt;
&lt;h2 id=&#34;comparing-the-lerps-with-real-vectors&#34;&gt;Comparing the &amp;rsquo;lerps with real vectors&lt;/h2&gt;
&lt;p&gt;It&amp;rsquo;s only fair to compare interpolation between two actually random vectors,
and that&amp;rsquo;s exactly what&amp;rsquo;s going on here.&lt;/p&gt;
&lt;div id=&#34;random&#34;&gt;&lt;/div&gt;
&lt;script&gt;
fetch(&#34;vecs.json&#34;)
    .then(response =&gt; response.json())
    .then(jvecs =&gt; {
    let start_random = jvecs.random_start;
    let stop_random = jvecs.random_stop;
    spawn_plot(&#34;random&#34;, 
        (div_id) =&gt; {
            let redraw_scale = get_multi_interp_chart(stylegan_space, div_id, 
                                                        {lerp: lerp, slerp: slerp, slerp2: slerp2}, 
                                                        start_random, stop_random, &#34;./random&#34;, 
                                                        interp_points, vecs_to_spherical);
        }
    );
    }
);
&lt;/script&gt;
&lt;p&gt;You&amp;rsquo;ll note that even though &lt;code&gt;lerp&lt;/code&gt; shows its characteristically out-of-family
vector magnitude, the results produced by all 3 interpolators are functionally
identical.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;As &lt;a href=&#34;https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf&#34;&gt;Pedro Domingos famously put it&lt;/a&gt;,
&lt;em&gt;Intuition Fails in High Dimensions&lt;/em&gt;. Before setting out on this journey, I didn&amp;rsquo;t expect
higher dimensional vectors to form hyperspherical shells, nor did I expect spherical interpolation
to be a better way of interpolating between two such vectors.&lt;/p&gt;
&lt;p&gt;When all is said and done, though, the importance of how one navigates in hyperspace may
not matter, and certainly depends on the actual system being studied.&lt;/p&gt;
&lt;p&gt;Sometimes, the best solution really is the simplest one.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Why does my GAN do that?</title>
      <link>https://willsnell.com/posts/gans/</link>
      <pubDate>Mon, 22 Jul 2024 09:25:17 +1200</pubDate>
      
      <guid>https://willsnell.com/posts/gans/</guid>
      <description>&lt;h2 id=&#34;what-are-gans&#34;&gt;What are GANs?&lt;/h2&gt;
&lt;p&gt;Much ink has already been spilled on the class of machine learning networks called
GANs, or Generative Adversarial Networks, so I will only summarize it here.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re interested in learning more, &lt;a href=&#34;https://developers.google.com/machine-learning/gan/gan_structure&#34;&gt;this short course is a great resource.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Although replaced in contemporary applications by diffusion models for
tasks like image generation, GANs provide a unique opportunity
to study the interplay of two tightly-coupled systems, each seeking a
different goal.&lt;/p&gt;</description>
      <content>&lt;h2 id=&#34;what-are-gans&#34;&gt;What are GANs?&lt;/h2&gt;
&lt;p&gt;Much ink has already been spilled on the class of machine learning networks called
GANs, or Generative Adversarial Networks, so I will only summarize it here.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you&amp;rsquo;re interested in learning more, &lt;a href=&#34;https://developers.google.com/machine-learning/gan/gan_structure&#34;&gt;this short course is a great resource.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Although replaced in contemporary applications by diffusion models for
tasks like image generation, GANs provide a unique opportunity
to study the interplay of two tightly-coupled systems, each seeking a
different goal.&lt;/p&gt;
&lt;p&gt;GANs consist of two distinct networks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a generator, which tries to generate new, convincingly realistic content, and&lt;/li&gt;
&lt;li&gt;a discriminator, which tries to tell real content from fake.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generally, during training, the generator is allowed to back-propagate gradients
all the way through both the discriminator (as it assesses the generated images)
and the generator itself. Conversely, the discriminator has no special knowledge
of the inner workings of the generator.
Hence, if a generator&amp;rsquo;s output fails to fool the discriminator, the
generator gets immediate feedback about what parts of the image tipped the discriminator off
to the fakery. But if a discriminator is repeatedly hoodwinked, it can only look inward to
understand how to improve.&lt;/p&gt;
&lt;p&gt;Although GANs can technically generate any type of content, this post will focus on the generation
of images.&lt;/p&gt;
&lt;h2 id=&#34;visualizing-dcgans&#34;&gt;Visualizing DCGANs&lt;/h2&gt;
&lt;p&gt;I particularly like using visualisation to get a deeper grip on a complex system
I am working with, and Deep Convolutional GANs (&lt;a href=&#34;https://arxiv.org/pdf/1511.06434&#34;&gt;as introduced in Radford, Metz &amp;amp; Chintala&lt;/a&gt;)
offered the perfect opportunity for some interesting visualisations.&lt;/p&gt;

  &lt;figure class=&#34;left&#34; &gt;
    &lt;img src=&#34;dcgan_gen_architecture.png&#34;   /&gt;
    
      &lt;figcaption class=&#34;center&#34; &gt;The DCGAN architecture (Radford, Metz &amp; Chintala), specifically the generator, with a 100-tall vector being processed through convolutional blocks that gradually decrease in feature depth and increase in resolution, until being projected to a 64 x 64 pixel RGB image.&lt;/figcaption&gt;
    
  &lt;/figure&gt;


&lt;p&gt;DCGANs use ordinary 2-dimensional convolutions in the discriminator to repeatedly downsample the image, building up
more and more internal features as the spatial resolution decreases.
In this way, they a variant of a typical convolutional image classifier.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The architecture presented in the DCGAN paper omits residual/skip-connections, à la &lt;a href=&#34;https://arxiv.org/pdf/1512.03385&#34;&gt;ResNet&lt;/a&gt;.
However, the two networks were introduced at similar times, and so the DCGAN&amp;rsquo;s authors probably didn&amp;rsquo;t shun them on purpose.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The generator does effectively the same thing, but in reverse, taking a large (in this case 100-long)
vector of random noise, and up-projecting it via transposed convolutions to gradually increase the
image resolution while decreasing the depth of the feature dimension.&lt;/p&gt;
&lt;p&gt;Because this network processes images, the very
first layer of the discriminator and the very last layer of the generator
should produce kernels that take in/out image data directly.&lt;/p&gt;
&lt;p&gt;For a (4x4 kernel) convolutional
layer that takes in an RGB image and produces a 128-feature output, this comes out to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;128 individual kernels (1 for each feature in the output layer),&lt;/li&gt;
&lt;li&gt;of depth 3 (i.e. each kernel has different weights for how much it activates
on a red, green, or blue pixel)&lt;/li&gt;
&lt;li&gt;of size 4 x 4&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Because each kernel has a depth of 3, we can visualize its weights using RGB images. In essence,
we get 128 x (4 high x 4 wide) images, where a bright red pixel indicates a part of the kernel
that activates strongly on red pixels, but not on green or blue, and a black pixel indicates no
activation for any input colour.&lt;/p&gt;
&lt;p&gt;We can use this process in reverse to visualize the generator&amp;rsquo;s &lt;strong&gt;output&lt;/strong&gt; kernels, where a 128-feature
space is projected up into an RGB image by transpose convolutions (effectively, but not quite, a convolution in reverse.)
The generator&amp;rsquo;s kernels are the different brushes with which the network paints the output image. Just like an artist might
need brushes of different sizes and shapes to effectively draw broad strokes and details, so the network might be expected
to need to specialize into different output kernels.&lt;/p&gt;
&lt;p&gt;At least, that&amp;rsquo;s my intuition for what would be expected to appear. In image classifiers (read: the discriminator),
the input kernels are often visualized in this way.&lt;/p&gt;
&lt;p&gt;For example, this image shows (centre) the kernels of a ResNet as visualized by &lt;a href=&#34;https://www.researchgate.net/publication/321192231&#34;&gt;Jiang, et. al&lt;/a&gt;:
&lt;img alt=&#34;Resnet in Jiang, et. al&#34; src=&#34;https://www.researchgate.net/publication/321192231/figure/fig4/AS:963217320841220@1606660313749/Visualization-of-first-layer-convolution-kernels-and-feature-maps-for-the-CS-ResCNN.gif&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;hypothesis-1&#34;&gt;Hypothesis 1&lt;/h2&gt;
&lt;p&gt;Before running the experiment, I expected that the discriminator would
develop clearly identifiable features in its kernels, such as
alternating black/white lines in various orientations (useful for edge-detection,) potentially filters
of one main colour, etc.&lt;/p&gt;
&lt;p&gt;I suspected the generator would be similar, but was less confident in this. After all, the kernel
visualizations I had seen, to date, were all of classifiers/discriminators, which serve a different
purpose to the generator I was going to train.&lt;/p&gt;
&lt;p&gt;What I saw, however, was much more surprising.&lt;/p&gt;
&lt;h2 id=&#34;exploring-my-dcgan&#34;&gt;Exploring my DCGAN&lt;/h2&gt;
&lt;p&gt;I started with a DCGAN with feature layers of depth [128, 256, 512], kernel size (4 x 4), and which took in an 64x64 RGB image.
The generator had an input vector of size 100, and was trained on normally distributed random noise.&lt;/p&gt;
&lt;p&gt;Training on the &lt;a href=&#34;https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html&#34;&gt;CelebA&lt;/a&gt; dataset, I used a batch-size of 8, using PyTorch
with an Adam optimizer using default settings for both the generator and the discriminator.&lt;/p&gt;
&lt;p&gt;The results from this first run are presented below.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: I&amp;rsquo;ve used a non-linear
time-step in the video since the model should change less and less as it gets further
and further through its training.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;https://willsnell.com/posts/gans/gan_full.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;https://willsnell.com/posts/gans/gan_full.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;&lt;em&gt;Training a [128, 256, 512] feature DCGAN on CelebA for 3 epochs.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;These results were very surprising -
essentially the exact opposite of what I expected to see.
While I had suspected the generator kernels might be inscrutable, many of
them instead appeared to have an identifiable function.&lt;/p&gt;
&lt;p&gt;On the other hand, the discriminator kernels appeared to not change at all
from their initialisation. Although I suspected an issue with the code,
further investigation showed the discriminator&amp;rsquo;s kernels were, in fact, changing
throughout the run - just not enough to be discernible.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The values in the input kernels to the discriminator do change, slightly.
In the visualization, the layer becomes noticeably less saturated from start to finish, even though
the absolute values of the layer weights do not change substantially. Since I normalize
each frame by the max and min pixel values, this suggests to me that a few pixels are
&amp;lsquo;going hot&amp;rsquo;, but that
they are not doing so in a recognisable pattern.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hypothesis-2&#34;&gt;Hypothesis 2&lt;/h2&gt;
&lt;p&gt;My hypothesis, based on the above results, is as follows:&lt;/p&gt;
&lt;p&gt;Assumptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The capacity of a network to learn information during training should be correlated to
the size of the network.&lt;/li&gt;
&lt;li&gt;A layer retaining its initial values, or something very close to them, suggests that
the exact distribution of these layers is unimportant to the network.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Based on these (admittedly unproven) assumptions, I would make a few predictions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If a layer is unimportant to the network, the network is probably over-sized for the task it is being
trained on&lt;/li&gt;
&lt;li&gt;Therefore, a smaller network (with its initial layer decreased in size) should be able to do equally well
on the task.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Doing equally well on the task&amp;rdquo;, in this context, is not strictly what the discriminator is evaluated on (i.e. its ability
to distinguish real from fake images), but rather is the quality of images produced after the GAN is fully trained.&lt;/li&gt;
&lt;li&gt;A well sized discriminator will show specialization in its input kernels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Boiling this down, I suspected that decreasing the number of input kernels of the discriminator (leaving the generator untouched)
would have little to no impact on the quality of images produced after training. I also suspected the combined network would
work equally well up to the point where the discriminator&amp;rsquo;s input kernels showed strong specialization (i.e. something similar to
the generator&amp;rsquo;s output kernels.)&lt;/p&gt;
&lt;h2 id=&#34;testing-hypothesis-2&#34;&gt;Testing Hypothesis 2&lt;/h2&gt;
&lt;p&gt;The obvious test was to decrease the number of input kernels for the discriminator
(i.e. the first-layer feature depth) from 128 to 64, and see what happens.&lt;/p&gt;
&lt;p&gt;Even though GANs are notoriously unstable during training, this change didn&amp;rsquo;t cause the network to diverge.
This suggests to me that the discriminator might have an
easier job to do than the generator, and so the smaller network was not immediately defeated
by its adversary.&lt;/p&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;https://willsnell.com/posts/gans/first_layer_64.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;https://willsnell.com/posts/gans/first_layer_64.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;There are some interesting takeaways from these results:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The output kernels from the generator look very similar to those from the previous
model. This suggests these kernels represent features useful to the generator,
regardless of the exact distribution of features in the hidden layers.&lt;/li&gt;
&lt;li&gt;The discriminator&amp;rsquo;s first layer still looks remarkably random. Despite being half as big,
the fully trained layer still looks like a desaturated version of the starting layer. At
least one recognisable feature seems to have appeared, though, in the 3rd column, 1st row.&lt;/li&gt;
&lt;li&gt;The image quality produced by the fully trained generator looks noticeably worse than for
the previous network. Although broad facial features are still present, the images qualitatively
look desaturated and hazy.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These findings suggest that although the input kernel&amp;rsquo;s exact weights may not be important, it is important
for the discriminator to have access to lots of them. Even if the feature representation inside the model
is ultimately fed by a series of random convolutions, having that feature depth seems to give the discriminator
more tools with which to sniff out fraudulent images. Consequently, a smaller number of input kernels lets the
generator get away with worse images.&lt;/p&gt;
&lt;h2 id=&#34;putting-the-hypothesis-properly-to-bed&#34;&gt;Putting the Hypothesis Properly to Bed&lt;/h2&gt;
&lt;p&gt;To check that these findings hold, I ran 3 more models with smaller and smaller input kernels. In particular,
the number of input features to the discriminator were decreased to 32, 16, and then 8. Mainly, I wanted to see
if the discriminator would eventually need to start specializing these kernel weights, even if it didn&amp;rsquo;t want to.&lt;/p&gt;
&lt;h3 id=&#34;32-input-kernels&#34;&gt;32 Input Kernels&lt;/h3&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;https://willsnell.com/posts/gans/first_layer_32.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;https://willsnell.com/posts/gans/first_layer_32.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;The 32 input-kernel network follows the same trend as the 64 input-kernel model: increasingly hazy, desaturated images.&lt;/p&gt;
&lt;p&gt;Two interesting notes, though:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Even as the image quality is degraded, the quality of the facial features looks pretty similar.&lt;/li&gt;
&lt;li&gt;More egregious structured artifacts are beginning to appear. In the lower left of this image, for example,
you can see a clear checker-boarding pattern in the background. Such patterns are commonly produced by
this network.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt=&#34;Blocky, repeating artifacts visible in the lower-left-corner&#34; src=&#34;https://willsnell.com/posts/gans/artefacts.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Together, these findings suggest to me that deeper layers of the discriminator
are still learning a good representation of facial features. However, the constrained
first layer has hindered the ability of the discriminator to notice and penalize noise and
overall &amp;ldquo;image-quality&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;I imagine each decrease in input kernels as the discriminator looking through an increasingly blurry
or perhaps tinted lens at the image, able to make out broad strokes but missing areas of high spatial frequency,
and seeing an increasingly desaturated version of the world.
The analogy isn&amp;rsquo;t quite right, since the spatial dimensions the network receives are unchanged, but it&amp;rsquo;s a start.&lt;/p&gt;
&lt;h3 id=&#34;the-edge-of-functionality---8-input-kernels&#34;&gt;The Edge of Functionality - 8 Input Kernels&lt;/h3&gt;
&lt;p&gt;During training, the 16-kernel GAN diverged, meaning the last model left to explore has 8 input kernels.&lt;/p&gt;
&lt;video controls preload=&#34;auto&#34; width=&#34;500px&#34;  autoplay loop playsinline class=&#34;html-video&#34;&gt;
    &lt;source src=&#34;https://willsnell.com/posts/gans/first_layer_8.mp4&#34; type=&#34;video/mp4&#34;&gt;
  &lt;span&gt;Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can &lt;a href=&#34;https://willsnell.com/posts/gans/first_layer_8.mp4&#34;&gt;download it&lt;/a&gt; and watch it with your favorite video player!&lt;/span&gt;
&lt;/video&gt;
&lt;p&gt;Finally, we see clear changes from the input kernels at the start to those at the end. However, this is
not enough to save the network, and the fully trained GAN produces images with little colour saturation,
degraded facial features, little separation between background and foreground, and most obviously, serious
checker-boarding artifacts across every part of the image.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s perhaps remarkable that such a constrained discriminator could cause the generator to build up anything
resembling a human face, but the final results are indisputably bad, and much worse than previous models.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Even though the input kernels to the discriminator in a DCGAN did not show much specialization during training,
reducing the number of input kernels available showed obvious reductions in image quality produced by the generator
after training. Further, the input kernels to the discriminator, no matter how few they were,
never showed the kind of specialization apparent in the final layers of the generator.&lt;/p&gt;
&lt;h3 id=&#34;other-wild-geese-to-chase&#34;&gt;Other Wild Geese to Chase&lt;/h3&gt;
&lt;p&gt;Even though the DCGAN&amp;rsquo;s Discriminator and Generator are largely symmetric, there are some key differences
that might explain the apparent lack of specialization in the discriminator&amp;rsquo;s first layer.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Activation functions: the generator uses Tanh between the transpose convolution and the final generated image,
while the discriminator a) uses LeakyReLU and b) places the activation function after the convolution. I haven&amp;rsquo;t
visualized the effect of these activation functions (since doing so would require an input to be run through
the network, and the result would depend on said input.) It&amp;rsquo;s quite possible the answer to this mystery lies
here.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The discriminator is not actually trained in the same way as typical classifiers. Although the architecture is
similar, the output of this discriminator is a single value (real or fake.)
It&amp;rsquo;s possible random noise is perfectly sufficient for
this task, whereas specialization only becomes necessary for classifiers that need to distinguish between
multiple different classes of image.&lt;/p&gt;
&lt;p&gt;Testing this would be as simple* as changing datasets (e.g. to &lt;a href=&#34;https://github.com/zalandoresearch/fashion-mnist&#34;&gt;fashion-MNIST&lt;/a&gt;
or &lt;a href=&#34;https://www.cs.toronto.edu/~kriz/cifar.html&#34;&gt;CIFAR-10&lt;/a&gt;), and changing the discriminator to
choose from 11 categories (the 10 from CIFAR-10, plus 1 extra denoting &amp;ldquo;fake&amp;rdquo;).&lt;/p&gt;
&lt;p&gt;&lt;em&gt;*No guarantees it will be this simple&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The flow of gradients through the network for a GAN is asymmetric: the generator gets access
to the entire state of the discriminator for backprop, while the discriminator only gets its
own network&amp;rsquo;s response to stimulus to learn from. Why this mismatch would lead to such a
difference in layer specialization is unknown, to me at least. Perhaps patterned specialization
in the discriminator&amp;rsquo;s layer closest to the generator&amp;rsquo;s own layers would provide an easy
attack vector for the generator to learn and defeat the discriminator?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Is the first layer actually random?&lt;/em&gt; The lack of human-identifiable structure in the kernels
doesn&amp;rsquo;t strictly mean the discriminator isn&amp;rsquo;t specializing them. Freezing this layer and comparing
performance to the original network could tell whether the discriminator is, in fact, getting
value from this layer after all.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    </item>
    
    <item>
      <title></title>
      <link>https://willsnell.com/drafts/hyperspace/testing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://willsnell.com/drafts/hyperspace/testing/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script src=&#34;plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;div id=&#34;myDiv&#34;&gt;&lt;/div&gt;
&lt;button onclick=&#34;vector_position = Math.min(VEC_LEN, vector_position + 1); redraw_background();&#34;&gt; + &lt;/button&gt;
  &lt;span id=&#34;vector_display&#34;&gt;&lt;/span&gt;
&lt;button onclick=&#34;vector_position = Math.max(0, vector_position - 1); redraw_background();&#34;&gt; - &lt;/button&gt;
&lt;button onclick=&#34;vec_pos = Math.max(0, vec_pos - 1); calc_vecs(); redraw_background();&#34;&gt; vec_len - &lt;/button&gt;
  &lt;span id=&#34;vec_len&#34;&gt;&lt;/span&gt;
&lt;button onclick=&#34;vec_pos = Math.min(vec_pos + 1, VEC_LENGTHS.length - 1); calc_vecs(); redraw_background();&#34;&gt; vec_len + &lt;/button&gt;

  &lt;div id=&#34;hyperspace&#34; style=&#34;flexbox&#34;&gt;
    &lt;div id=&#34;circular&#34;&gt;&lt;/div&gt;
    &lt;div id=&#34;spherical&#34;&gt;&lt;/div&gt;
  &lt;/div&gt;

&lt;div class=&#34;slidecontainer&#34;&gt;
  &lt;input type=&#34;range&#34; min=&#34;0.&#34; max=&#34;1.&#34; value=&#34;0.5&#34; class=&#34;slider&#34; id=&#34;myRange&#34;
    oninput=&#34;frac = this.value; draw_point();&#34;&gt;
&lt;/div&gt;

&lt;script&gt;

const NUM_VECS = 10_000;

const VEC_LENGTHS = [1, 2, 3, 4, 5, 6, 10, 20, 50, 100, 1000];
let vec_pos = 2;
let VEC_LEN = VEC_LENGTHS[vec_pos];


// Hopefully all this configuration stuff can be
// pulled in from CSS from the site...
const point_color = &#39;grey&#39;;
const DEFAULT_MARKER_SIZE = 2.0;

// User-selectable elements
let vector_position = 0;

function gaussianRandom(mean=0, stdev=1) {
  const u = 1 - Math.random();
  const v = Math.random();
  const z = Math.sqrt( -2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);
  return z * stdev + mean;
}

function uniformRandom(min=-1, max=1) {
  return Math.random() * (max - min) + min;
}

function vec_to_spherical_xyz(vec, elem0=0, elem1=1, elem2=2) {
  // Consider only calculating this once, when generating the
  // vectors.
  const two_norm = Math.sqrt(vec.reduce((acc, x) =&gt; (acc + x**2), 0));
  if (vec.length == 0) {
    return [0, 0, 0];
  }
  if (vec.length == 1) {
    return [two_norm, 0, 0];
  }
  if (vec.length == 2 | elem2 == null) {
    let angle_1 = Math.atan2(vec[elem1], vec[elem0]);
    return [two_norm * Math.cos(angle_1), two_norm * Math.sin(angle_1), 0];
  }

  let angle_1 = Math.atan2(vec[elem1], vec[elem0]);
  let angle_2 = Math.atan2(vec[elem2], Math.sqrt(vec[elem0]**2 + vec[elem1]**2));

  return [
    two_norm * Math.cos(angle_1) * Math.cos(angle_2), 
    two_norm * Math.sin(angle_1) * Math.cos(angle_2), 
    two_norm * Math.sin(angle_2)
  ];
}

function vec_norm(vec) {
  let acc = 0;
  for (var i = 0; i &lt; vec.length; i++) {
    acc += vec[i]**2;
  }
  return Math.sqrt(acc);
}

function vec_to_spherical_maybe_faster(vec, elem0=0, elem1=1, elem2=2) {
  if (vec.length == 1) {
    return [vec[elem0], 0, 0];
  }
  const norm = vec_norm(vec);

  if (vec.length == 2 | elem2 == null) {
    // This feels like cheating, but really 
    // we don&#39;t need to do anything up until 
    // 4 dimensions
    return [vec[elem0], vec[elem1], 0];
  }

  const dir_norm = vec_norm([vec[elem0], vec[elem1], vec[elem2]]);
  const mag = norm / dir_norm;
  return [vec[elem0] * mag, vec[elem1] * mag, vec[elem2] * mag];
}

function vecs_to_spherical(vecs, elem0=0, elem1=1, elem2=2) {
  let x = [];
  let y = [];
  let z = [];

  vecs.map((vec) =&gt; {
    let [vec_x, vec_y, vec_z] = vec_to_spherical_xyz(vec, elem0, elem1, elem2);
    x.push(vec_x);
    y.push(vec_y);
    z.push(vec_z);
  });

  return [x, y, z];
}

function newVec(initializer) {
  return Array.from({length: VEC_LEN}, (x, i) =&gt; initializer());
}
  
let vecs = [];

function calc_vecs() {
  VEC_LEN = VEC_LENGTHS[vec_pos];
  vecs = [];
  for (let i = 0; i &lt; NUM_VECS; i++) {
    vecs.push(newVec(gaussianRandom));
  }
}

function slice_arrays(index, array) {
  let x = [];
  let y = [];
  let z = [];
  
  for (var i = 0; i &lt; array.length; i++) {
    x.push(array[i][index]);
    y.push(array[i][index + 1]);
    z.push(array[i][index + 2]);
  }
  return [x, y, z];
}


let layout = {
  width: &#34;30%&#34;,
  paper_bgcolor: &#39;rgba(0,0,0,0)&#39;,
  plot_bgcolor: &#39;rgba(0,0,0,0)&#39;,
  hovermode: false,
  
  xaxis: {
    zeroline: false,
    tickmode: &#34;array&#34;,
    tickvals: [-3, 0, 3], 
  },
  yaxis: {
    zeroline: false,
    tickmode: &#34;array&#34;,
    tickvals: [-3, 0, 3], 
  },
  scene: {
    aspectmode: &#39;data&#39;,
    xaxis: {
      zeroline: false,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    },
    yaxis: {
      zeroline: false,
      scaleanchor: &#34;x&#34;,
      scaleratio: 1,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    },
    zaxis: {
      zeroline: false,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    }
  }
};

calc_vecs();

let [x, y, z] = slice_arrays(vector_position, vecs);
/* let [hero_x, hero_y, hero_z] = slice_arrays(vector_position, hero_vec); */

const data = [
  {
    type: &#39;scatter3d&#39;,
    mode: &#39;markers&#39;,
    x: x,
    y: y,
    z: z,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      }
    }
  },
  // {
  //   type: &#39;scatter3d&#39;,
  //   mode: &#39;markers&#39;,
  //   x: hero_x,
  //   y: hero_y,
  //   z: hero_z,
  //   marker: {
  //     size: 2,
  //     color: &#39;red&#39;,
  //   }
  //}
]
data[0].marker.color[0] = &#39;red&#39;;
data[0].marker.color[1] = &#39;red&#39;;
data[0].marker.size[0] = 6;
data[0].marker.size[1] = 6;

const config = {
  displayModeBar: false,
  dragMode: false,
  scrollZoom: true,
};

let plot = document.getElementById(&#34;myDiv&#34;);
let spherical = document.getElementById(&#34;spherical&#34;);
let circular = document.getElementById(&#34;circular&#34;);
let vec_display = document.getElementById(&#34;vector_display&#34;);

function redraw_background() {
  let [x, y, z] = slice_arrays(vector_position, vecs);
  data[0].x = x;
  data[0].y = y;
  data[0].z = z;
  data[0].marker.color[0] = &#39;red&#39;;
  data[0].marker.color[1] = &#39;red&#39;;
  data[0].marker.size[0] = 6;
  data[0].marker.size[1] = 6;

  Plotly.react(plot, data, layout, config);

  let [s_x, s_y, s_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, vector_position + 2);
  spherical_data[0].x = s_x;
  spherical_data[0].y = s_y;
  spherical_data[0].z = s_z;
  spherical_data[0].marker.color[0] = &#39;red&#39;;
  spherical_data[0].marker.color[1] = &#39;red&#39;;
  spherical_data[0].marker.size[0] = 6;
  spherical_data[0].marker.size[1] = 6;

  layout.scene.xaxis.tickmode = &#34;array&#34;;
  layout.scene.yaxis.tickmode = &#34;array&#34;;
  layout.scene.zaxis.tickmode = &#34;array&#34;;
  let sigma = 1.0;
  let bound = Math.ceil(Math.sqrt(vecs[0].length) * sigma);
  layout.scene.xaxis.tickvals = [-bound, bound];
  layout.scene.yaxis.tickvals = [-bound, bound];
  layout.scene.zaxis.tickvals = [-bound, bound];
  layout.xaxis.tickvals = [-bound, bound];
  layout.yaxis.tickvals = [-bound, bound];


  Plotly.react(spherical, spherical_data, layout, config);


  let [c_x, c_y, c_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, null);
  circular_data[0].x = c_x;
  circular_data[0].y = c_y;
  circular_data[0].marker.color[0] = &#39;red&#39;;
  circular_data[0].marker.color[1] = &#39;red&#39;;
  circular_data[0].marker.size[0] = 6;
  circular_data[0].marker.size[1] = 6;
  circular_data[0].test = &#34;true&#34;;

  Plotly.react(circular, circular_data, layout, config);

  // show interpolation
  let lerp_path = draw_interp(vecs, lerp);
  let [p_x, p_y, p_z] = slice_arrays(vector_position, lerp_path);
  let new_data = {
    type: &#39;scatter3d&#39;,
    mode: &#39;lines&#39;,
    x: p_x,
    y: p_y,
    z: p_z,
  }

  Plotly.addTraces(plot, new_data);
  Plotly.deleteTraces(plot, 1);

  let [ns_x, ns_y, ns_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, vector_position + 2);
  let new_sphere = {
    type: &#39;scatter3d&#39;,
    mode: &#39;lines&#39;,
    x: ns_x,
    y: ns_y,
    z: ns_z,
  }

  Plotly.deleteTraces(spherical, 1);
  Plotly.addTraces(spherical, new_sphere);

  let [nc_x, nc_y, nc_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, null);
  let new_circ = {
    type: &#39;scattergl&#39;,
    mode: &#39;lines&#39;,
    x: nc_x,
    y: nc_y,
  }

  Plotly.deleteTraces(circular, 1);
  Plotly.addTraces(circular, new_circ);

  showVecText();
  draw_point();
}

function showVecText() {
  let vec_string = &#34;[&#34;;
  if (vector_position &gt; 0) {
    vec_string += &#34;..., &#34;; 
  }

  // TODO bounds check on vector_position
  const NUM_DISPLAYED = 3;
  for (var pos = vector_position; pos &lt; Math.min(VEC_LEN, vector_position + NUM_DISPLAYED); pos++) {
    vec_string += `${vecs[0][pos].toFixed(2)}, `;
  }

  if (vector_position + NUM_DISPLAYED &lt; VEC_LEN) {
    vec_string += &#34;...&#34;;
  }

  vec_string += &#34;]&#34;;
  
  vec_display.textContent = vec_string;

  let vec_len = document.getElementById(&#34;vec_len&#34;);
  vec_len.textContent = VEC_LEN;
}

Plotly.newPlot(plot, data, layout, config);

// 3-sphere
let [s_x, s_y, s_z] = vecs_to_spherical(vecs);


const spherical_data = [
  {
    type: &#39;scatter3d&#39;,
    mode: &#39;markers&#39;,
    x: s_x,
    y: s_y,
    z: s_z,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      } 
    }
  },
]
spherical_data[0].marker.color[0] = &#39;red&#39;;
spherical_data[0].marker.color[1] = &#39;red&#39;;
spherical_data[0].marker.size[0] = 6;
spherical_data[0].marker.size[1] = 6;

Plotly.newPlot(spherical, spherical_data, layout, config);

// 2-sphere
let [c_x, c_y, c_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, null);

const circular_data = [
  {
    type: &#39;scattergl&#39;,
    mode: &#39;markers&#39;,
    x: c_x,
    y: c_y,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      } 
    }
  },
]
circular_data[0].marker.color[0] = &#39;red&#39;;
circular_data[0].marker.color[1] = &#39;red&#39;;
circular_data[0].marker.size[0] = 6;
circular_data[0].marker.size[1] = 6;

Plotly.newPlot(circular, circular_data, layout, config);
// Plotly.restyle(plot, &#39;marker.size&#39;, [[&#39;red&#39;]]);
showVecText();

// lerp

function lerp(fraction, start, stop) {
  let out = [];
  for (var i = 0; i &lt; start.length; i++) {
    out[i] = start[i] + fraction * (stop[i] - start[i]);
  }
  return out;
}

function _v(func, array) {
  // Apply a function along a vector.
  return array.map((x) =&gt; func(x));
}

function clamp(val, min, max) {
  // Mirror&#39;s numpy&#39;s &#39;clip&#39; function
  return Math.max(min, Math.min(val, max));
}

function mult(array, num) {
  // elemwise multiplication
  return array.map((x) =&gt; x * num);
}

function dot(arr1, arr2) {
  // Implicitly assumes arr1 and arr2 
  // have the same length.
  acc = 0;
  for (var i = 0; i &lt; arr1.length; i++) {
    acc += arr1[i] * arr2[i]; 
  }
  return acc;
}

function slerp(fraction, start, stop) {
  const norm_start = mult(start, 1 / vec_norm(start));
  const norm_stop = mult(stop, 1 / vec_norm(stop));

  const omega = Math.acos(clamp(dot(norm_start, norm_stop), -1, 1));
  const so = Math.sin(omega);

  let out = new Array(start.length);

  if (so == 0) {
    for (let i = 0; i &lt; start.length; i++) {
      out[i] = (1.0 - fraction) * start[i] + fraction * stop[i];
    }
  }
  else {
    let s_omega_minus = Math.sin((1.0 - fraction) * omega) / so;
    let s_omega_plus = Math.sin(fraction * omega) / so;
    for (let i = 0; i &lt; start.length; i++) {
      out[i] = s_omega_minus * start[i] + s_omega_plus * stop[i];
    }
  }
  return out;
}

// Returns an array of vectors, i.e. NOT transformed into x, y, z
function draw_interp(vecs, interpolator, num_steps=100) {
  let tweens = Array.from({ length: num_steps}, (v, i) =&gt; i / (num_steps - 1));
  
  return tweens.map((fraction) =&gt; interpolator(fraction, vecs[0], vecs[1]));
     
}

// show interpolation
let lerp_path = draw_interp(vecs, lerp);
let [p_x, p_y, p_z] = slice_arrays(vector_position, lerp_path);
let new_data = {
  type: &#39;scatter3d&#39;,
  mode: &#39;lines&#39;,
  x: p_x,
  y: p_y,
  z: p_z,
}

Plotly.addTraces(plot, new_data);

let [ns_x, ns_y, ns_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, vector_position + 2);
let new_sphere = {
  type: &#39;scatter3d&#39;,
  mode: &#39;lines&#39;,
  x: ns_x,
  y: ns_y,
  z: ns_z,
}

Plotly.addTraces(spherical, new_sphere);

let [nc_x, nc_y, nc_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, null);
let new_circ = {
  type: &#39;scattergl&#39;,
  mode: &#39;lines&#39;,
  x: nc_x,
  y: nc_y,
}

Plotly.addTraces(circular, new_circ);

let frac = 0.5;

function draw_point(del_old=true) {
  let midpoint = slerp(frac, vecs[0], vecs[1]);
  midpoint_circ = vecs_to_spherical([midpoint], vector_position, vector_position + 1, null);
  midpoint_spher = vecs_to_spherical([midpoint], vector_position, vector_position + 1, vector_position + 2);
  if (del_old) {
    Plotly.deleteTraces(spherical, 1);
    Plotly.deleteTraces(circular, 1);
    Plotly.deleteTraces(plot, 1);
  }
  let spher_point = {
    type: &#39;scatter3d&#39;,
    mode: &#39;marker&#39;,
    x: midpoint_spher[0],
    y: midpoint_spher[1],
    z: midpoint_spher[2],
  }
  let circ_point = {
    type: &#39;scattergl&#39;,
    mode: &#39;marker&#39;,
    x: midpoint_circ[0],
    y: midpoint_circ[1],
  } 
  let point = {
    type: &#39;scatter3d&#39;,
    mode: &#39;marker&#39;,
    x: midpoint[0],
    y: midpoint[1],
    z: midpoint[2],
  }

  Plotly.addTraces(spherical, spher_point);
  Plotly.addTraces(circular, circ_point);
  Plotly.addTraces(plot, point);
}

draw_point(false);


&lt;/script&gt;
&lt;/body&gt;</description>
      <content>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script src=&#34;plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;div id=&#34;myDiv&#34;&gt;&lt;/div&gt;
&lt;button onclick=&#34;vector_position = Math.min(VEC_LEN, vector_position + 1); redraw_background();&#34;&gt; + &lt;/button&gt;
  &lt;span id=&#34;vector_display&#34;&gt;&lt;/span&gt;
&lt;button onclick=&#34;vector_position = Math.max(0, vector_position - 1); redraw_background();&#34;&gt; - &lt;/button&gt;
&lt;button onclick=&#34;vec_pos = Math.max(0, vec_pos - 1); calc_vecs(); redraw_background();&#34;&gt; vec_len - &lt;/button&gt;
  &lt;span id=&#34;vec_len&#34;&gt;&lt;/span&gt;
&lt;button onclick=&#34;vec_pos = Math.min(vec_pos + 1, VEC_LENGTHS.length - 1); calc_vecs(); redraw_background();&#34;&gt; vec_len + &lt;/button&gt;

  &lt;div id=&#34;hyperspace&#34; style=&#34;flexbox&#34;&gt;
    &lt;div id=&#34;circular&#34;&gt;&lt;/div&gt;
    &lt;div id=&#34;spherical&#34;&gt;&lt;/div&gt;
  &lt;/div&gt;

&lt;div class=&#34;slidecontainer&#34;&gt;
  &lt;input type=&#34;range&#34; min=&#34;0.&#34; max=&#34;1.&#34; value=&#34;0.5&#34; class=&#34;slider&#34; id=&#34;myRange&#34;
    oninput=&#34;frac = this.value; draw_point();&#34;&gt;
&lt;/div&gt;

&lt;script&gt;

const NUM_VECS = 10_000;

const VEC_LENGTHS = [1, 2, 3, 4, 5, 6, 10, 20, 50, 100, 1000];
let vec_pos = 2;
let VEC_LEN = VEC_LENGTHS[vec_pos];


// Hopefully all this configuration stuff can be
// pulled in from CSS from the site...
const point_color = &#39;grey&#39;;
const DEFAULT_MARKER_SIZE = 2.0;

// User-selectable elements
let vector_position = 0;

function gaussianRandom(mean=0, stdev=1) {
  const u = 1 - Math.random();
  const v = Math.random();
  const z = Math.sqrt( -2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);
  return z * stdev + mean;
}

function uniformRandom(min=-1, max=1) {
  return Math.random() * (max - min) + min;
}

function vec_to_spherical_xyz(vec, elem0=0, elem1=1, elem2=2) {
  // Consider only calculating this once, when generating the
  // vectors.
  const two_norm = Math.sqrt(vec.reduce((acc, x) =&gt; (acc + x**2), 0));
  if (vec.length == 0) {
    return [0, 0, 0];
  }
  if (vec.length == 1) {
    return [two_norm, 0, 0];
  }
  if (vec.length == 2 | elem2 == null) {
    let angle_1 = Math.atan2(vec[elem1], vec[elem0]);
    return [two_norm * Math.cos(angle_1), two_norm * Math.sin(angle_1), 0];
  }

  let angle_1 = Math.atan2(vec[elem1], vec[elem0]);
  let angle_2 = Math.atan2(vec[elem2], Math.sqrt(vec[elem0]**2 + vec[elem1]**2));

  return [
    two_norm * Math.cos(angle_1) * Math.cos(angle_2), 
    two_norm * Math.sin(angle_1) * Math.cos(angle_2), 
    two_norm * Math.sin(angle_2)
  ];
}

function vec_norm(vec) {
  let acc = 0;
  for (var i = 0; i &lt; vec.length; i++) {
    acc += vec[i]**2;
  }
  return Math.sqrt(acc);
}

function vec_to_spherical_maybe_faster(vec, elem0=0, elem1=1, elem2=2) {
  if (vec.length == 1) {
    return [vec[elem0], 0, 0];
  }
  const norm = vec_norm(vec);

  if (vec.length == 2 | elem2 == null) {
    // This feels like cheating, but really 
    // we don&#39;t need to do anything up until 
    // 4 dimensions
    return [vec[elem0], vec[elem1], 0];
  }

  const dir_norm = vec_norm([vec[elem0], vec[elem1], vec[elem2]]);
  const mag = norm / dir_norm;
  return [vec[elem0] * mag, vec[elem1] * mag, vec[elem2] * mag];
}

function vecs_to_spherical(vecs, elem0=0, elem1=1, elem2=2) {
  let x = [];
  let y = [];
  let z = [];

  vecs.map((vec) =&gt; {
    let [vec_x, vec_y, vec_z] = vec_to_spherical_xyz(vec, elem0, elem1, elem2);
    x.push(vec_x);
    y.push(vec_y);
    z.push(vec_z);
  });

  return [x, y, z];
}

function newVec(initializer) {
  return Array.from({length: VEC_LEN}, (x, i) =&gt; initializer());
}
  
let vecs = [];

function calc_vecs() {
  VEC_LEN = VEC_LENGTHS[vec_pos];
  vecs = [];
  for (let i = 0; i &lt; NUM_VECS; i++) {
    vecs.push(newVec(gaussianRandom));
  }
}

function slice_arrays(index, array) {
  let x = [];
  let y = [];
  let z = [];
  
  for (var i = 0; i &lt; array.length; i++) {
    x.push(array[i][index]);
    y.push(array[i][index + 1]);
    z.push(array[i][index + 2]);
  }
  return [x, y, z];
}


let layout = {
  width: &#34;30%&#34;,
  paper_bgcolor: &#39;rgba(0,0,0,0)&#39;,
  plot_bgcolor: &#39;rgba(0,0,0,0)&#39;,
  hovermode: false,
  
  xaxis: {
    zeroline: false,
    tickmode: &#34;array&#34;,
    tickvals: [-3, 0, 3], 
  },
  yaxis: {
    zeroline: false,
    tickmode: &#34;array&#34;,
    tickvals: [-3, 0, 3], 
  },
  scene: {
    aspectmode: &#39;data&#39;,
    xaxis: {
      zeroline: false,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    },
    yaxis: {
      zeroline: false,
      scaleanchor: &#34;x&#34;,
      scaleratio: 1,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    },
    zaxis: {
      zeroline: false,
      tickmode: &#34;array&#34;,
      tickvals: [-3, 0, 3], 
    }
  }
};

calc_vecs();

let [x, y, z] = slice_arrays(vector_position, vecs);
/* let [hero_x, hero_y, hero_z] = slice_arrays(vector_position, hero_vec); */

const data = [
  {
    type: &#39;scatter3d&#39;,
    mode: &#39;markers&#39;,
    x: x,
    y: y,
    z: z,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      }
    }
  },
  // {
  //   type: &#39;scatter3d&#39;,
  //   mode: &#39;markers&#39;,
  //   x: hero_x,
  //   y: hero_y,
  //   z: hero_z,
  //   marker: {
  //     size: 2,
  //     color: &#39;red&#39;,
  //   }
  //}
]
data[0].marker.color[0] = &#39;red&#39;;
data[0].marker.color[1] = &#39;red&#39;;
data[0].marker.size[0] = 6;
data[0].marker.size[1] = 6;

const config = {
  displayModeBar: false,
  dragMode: false,
  scrollZoom: true,
};

let plot = document.getElementById(&#34;myDiv&#34;);
let spherical = document.getElementById(&#34;spherical&#34;);
let circular = document.getElementById(&#34;circular&#34;);
let vec_display = document.getElementById(&#34;vector_display&#34;);

function redraw_background() {
  let [x, y, z] = slice_arrays(vector_position, vecs);
  data[0].x = x;
  data[0].y = y;
  data[0].z = z;
  data[0].marker.color[0] = &#39;red&#39;;
  data[0].marker.color[1] = &#39;red&#39;;
  data[0].marker.size[0] = 6;
  data[0].marker.size[1] = 6;

  Plotly.react(plot, data, layout, config);

  let [s_x, s_y, s_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, vector_position + 2);
  spherical_data[0].x = s_x;
  spherical_data[0].y = s_y;
  spherical_data[0].z = s_z;
  spherical_data[0].marker.color[0] = &#39;red&#39;;
  spherical_data[0].marker.color[1] = &#39;red&#39;;
  spherical_data[0].marker.size[0] = 6;
  spherical_data[0].marker.size[1] = 6;

  layout.scene.xaxis.tickmode = &#34;array&#34;;
  layout.scene.yaxis.tickmode = &#34;array&#34;;
  layout.scene.zaxis.tickmode = &#34;array&#34;;
  let sigma = 1.0;
  let bound = Math.ceil(Math.sqrt(vecs[0].length) * sigma);
  layout.scene.xaxis.tickvals = [-bound, bound];
  layout.scene.yaxis.tickvals = [-bound, bound];
  layout.scene.zaxis.tickvals = [-bound, bound];
  layout.xaxis.tickvals = [-bound, bound];
  layout.yaxis.tickvals = [-bound, bound];


  Plotly.react(spherical, spherical_data, layout, config);


  let [c_x, c_y, c_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, null);
  circular_data[0].x = c_x;
  circular_data[0].y = c_y;
  circular_data[0].marker.color[0] = &#39;red&#39;;
  circular_data[0].marker.color[1] = &#39;red&#39;;
  circular_data[0].marker.size[0] = 6;
  circular_data[0].marker.size[1] = 6;
  circular_data[0].test = &#34;true&#34;;

  Plotly.react(circular, circular_data, layout, config);

  // show interpolation
  let lerp_path = draw_interp(vecs, lerp);
  let [p_x, p_y, p_z] = slice_arrays(vector_position, lerp_path);
  let new_data = {
    type: &#39;scatter3d&#39;,
    mode: &#39;lines&#39;,
    x: p_x,
    y: p_y,
    z: p_z,
  }

  Plotly.addTraces(plot, new_data);
  Plotly.deleteTraces(plot, 1);

  let [ns_x, ns_y, ns_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, vector_position + 2);
  let new_sphere = {
    type: &#39;scatter3d&#39;,
    mode: &#39;lines&#39;,
    x: ns_x,
    y: ns_y,
    z: ns_z,
  }

  Plotly.deleteTraces(spherical, 1);
  Plotly.addTraces(spherical, new_sphere);

  let [nc_x, nc_y, nc_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, null);
  let new_circ = {
    type: &#39;scattergl&#39;,
    mode: &#39;lines&#39;,
    x: nc_x,
    y: nc_y,
  }

  Plotly.deleteTraces(circular, 1);
  Plotly.addTraces(circular, new_circ);

  showVecText();
  draw_point();
}

function showVecText() {
  let vec_string = &#34;[&#34;;
  if (vector_position &gt; 0) {
    vec_string += &#34;..., &#34;; 
  }

  // TODO bounds check on vector_position
  const NUM_DISPLAYED = 3;
  for (var pos = vector_position; pos &lt; Math.min(VEC_LEN, vector_position + NUM_DISPLAYED); pos++) {
    vec_string += `${vecs[0][pos].toFixed(2)}, `;
  }

  if (vector_position + NUM_DISPLAYED &lt; VEC_LEN) {
    vec_string += &#34;...&#34;;
  }

  vec_string += &#34;]&#34;;
  
  vec_display.textContent = vec_string;

  let vec_len = document.getElementById(&#34;vec_len&#34;);
  vec_len.textContent = VEC_LEN;
}

Plotly.newPlot(plot, data, layout, config);

// 3-sphere
let [s_x, s_y, s_z] = vecs_to_spherical(vecs);


const spherical_data = [
  {
    type: &#39;scatter3d&#39;,
    mode: &#39;markers&#39;,
    x: s_x,
    y: s_y,
    z: s_z,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      } 
    }
  },
]
spherical_data[0].marker.color[0] = &#39;red&#39;;
spherical_data[0].marker.color[1] = &#39;red&#39;;
spherical_data[0].marker.size[0] = 6;
spherical_data[0].marker.size[1] = 6;

Plotly.newPlot(spherical, spherical_data, layout, config);

// 2-sphere
let [c_x, c_y, c_z] = vecs_to_spherical(vecs, vector_position, vector_position + 1, null);

const circular_data = [
  {
    type: &#39;scattergl&#39;,
    mode: &#39;markers&#39;,
    x: c_x,
    y: c_y,
    opacity: 1,
    marker: {
      size: vecs.map((x) =&gt; DEFAULT_MARKER_SIZE),
      color: vecs.map((x) =&gt; point_color),
      line: {
        width: 0,
      } 
    }
  },
]
circular_data[0].marker.color[0] = &#39;red&#39;;
circular_data[0].marker.color[1] = &#39;red&#39;;
circular_data[0].marker.size[0] = 6;
circular_data[0].marker.size[1] = 6;

Plotly.newPlot(circular, circular_data, layout, config);
// Plotly.restyle(plot, &#39;marker.size&#39;, [[&#39;red&#39;]]);
showVecText();

// lerp

function lerp(fraction, start, stop) {
  let out = [];
  for (var i = 0; i &lt; start.length; i++) {
    out[i] = start[i] + fraction * (stop[i] - start[i]);
  }
  return out;
}

function _v(func, array) {
  // Apply a function along a vector.
  return array.map((x) =&gt; func(x));
}

function clamp(val, min, max) {
  // Mirror&#39;s numpy&#39;s &#39;clip&#39; function
  return Math.max(min, Math.min(val, max));
}

function mult(array, num) {
  // elemwise multiplication
  return array.map((x) =&gt; x * num);
}

function dot(arr1, arr2) {
  // Implicitly assumes arr1 and arr2 
  // have the same length.
  acc = 0;
  for (var i = 0; i &lt; arr1.length; i++) {
    acc += arr1[i] * arr2[i]; 
  }
  return acc;
}

function slerp(fraction, start, stop) {
  const norm_start = mult(start, 1 / vec_norm(start));
  const norm_stop = mult(stop, 1 / vec_norm(stop));

  const omega = Math.acos(clamp(dot(norm_start, norm_stop), -1, 1));
  const so = Math.sin(omega);

  let out = new Array(start.length);

  if (so == 0) {
    for (let i = 0; i &lt; start.length; i++) {
      out[i] = (1.0 - fraction) * start[i] + fraction * stop[i];
    }
  }
  else {
    let s_omega_minus = Math.sin((1.0 - fraction) * omega) / so;
    let s_omega_plus = Math.sin(fraction * omega) / so;
    for (let i = 0; i &lt; start.length; i++) {
      out[i] = s_omega_minus * start[i] + s_omega_plus * stop[i];
    }
  }
  return out;
}

// Returns an array of vectors, i.e. NOT transformed into x, y, z
function draw_interp(vecs, interpolator, num_steps=100) {
  let tweens = Array.from({ length: num_steps}, (v, i) =&gt; i / (num_steps - 1));
  
  return tweens.map((fraction) =&gt; interpolator(fraction, vecs[0], vecs[1]));
     
}

// show interpolation
let lerp_path = draw_interp(vecs, lerp);
let [p_x, p_y, p_z] = slice_arrays(vector_position, lerp_path);
let new_data = {
  type: &#39;scatter3d&#39;,
  mode: &#39;lines&#39;,
  x: p_x,
  y: p_y,
  z: p_z,
}

Plotly.addTraces(plot, new_data);

let [ns_x, ns_y, ns_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, vector_position + 2);
let new_sphere = {
  type: &#39;scatter3d&#39;,
  mode: &#39;lines&#39;,
  x: ns_x,
  y: ns_y,
  z: ns_z,
}

Plotly.addTraces(spherical, new_sphere);

let [nc_x, nc_y, nc_z] = vecs_to_spherical(lerp_path, vector_position, vector_position + 1, null);
let new_circ = {
  type: &#39;scattergl&#39;,
  mode: &#39;lines&#39;,
  x: nc_x,
  y: nc_y,
}

Plotly.addTraces(circular, new_circ);

let frac = 0.5;

function draw_point(del_old=true) {
  let midpoint = slerp(frac, vecs[0], vecs[1]);
  midpoint_circ = vecs_to_spherical([midpoint], vector_position, vector_position + 1, null);
  midpoint_spher = vecs_to_spherical([midpoint], vector_position, vector_position + 1, vector_position + 2);
  if (del_old) {
    Plotly.deleteTraces(spherical, 1);
    Plotly.deleteTraces(circular, 1);
    Plotly.deleteTraces(plot, 1);
  }
  let spher_point = {
    type: &#39;scatter3d&#39;,
    mode: &#39;marker&#39;,
    x: midpoint_spher[0],
    y: midpoint_spher[1],
    z: midpoint_spher[2],
  }
  let circ_point = {
    type: &#39;scattergl&#39;,
    mode: &#39;marker&#39;,
    x: midpoint_circ[0],
    y: midpoint_circ[1],
  } 
  let point = {
    type: &#39;scatter3d&#39;,
    mode: &#39;marker&#39;,
    x: midpoint[0],
    y: midpoint[1],
    z: midpoint[2],
  }

  Plotly.addTraces(spherical, spher_point);
  Plotly.addTraces(circular, circ_point);
  Plotly.addTraces(plot, point);
}

draw_point(false);


&lt;/script&gt;
&lt;/body&gt;
</content>
    </item>
    
    <item>
      <title></title>
      <link>https://willsnell.com/drafts/hyperspace/testing2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://willsnell.com/drafts/hyperspace/testing2/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script type=&#34;text/javascript&#34; id=&#34;MathJax-script&#34; async
  src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;
&lt;/script&gt;
&lt;script src=&#34;plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
&lt;div id=&#39;vector&#39;&gt;&lt;/div&gt;

&lt;script&gt;
const VEC_ELEMS_DISPLAYED = 8;
const AVAILABLE_DIMENSIONS = [1, 2, 3, 4, 5, 6, 10, 20, 50, 100, 1000];


function latexize_vector(vector, element_id, slice_offset, dimensions, num_selected) {
  if (dimensions &gt; vector.length) throw(&#34;Dimensions &gt; vector length&#34;);
  let latex_str = `
    \\[
    \\mathbf{
    \\begin{align}
\\vec{v_{${dimensions}}} = \\begin{bmatrix}`;

  const start = Math.max(0, Math.min(slice_offset, dimensions - VEC_ELEMS_DISPLAYED));
  const desired_stop = Math.min(dimensions, slice_offset + VEC_ELEMS_DISPLAYED);
    
  // Adding dots increases the size of the vector, so we need
  // this check to stop the vector increasing and decreasing
  // in length as we scroll through.
  const stop = (start &gt; 0 &amp;&amp; desired_stop &lt; dimensions) ? desired_stop - 1 : desired_stop;

  if (start &gt; 0) latex_str += `\\vdots \\\\`;
  for (let i = start; i &lt; stop; i++) {
    if ((i - slice_offset) &gt;= 0 &amp;&amp; (i - slice_offset) &lt; num_selected) {
      latex_str += `\\mathbf{${vector[i].toFixed(2)}} \\\\`
    } else {
      latex_str += `${vector[i].toFixed(2)} \\\\`
    }
  }
  if (stop &lt; dimensions) latex_str += `\\vdots \\\\`;

  latex_str += `\\end{bmatrix}
              \\end{align}
            }
            \\]`;
  document.getElementById(element_id).innerHTML = latex_str;
}

function get_vector_widget(vector, id, start_dims=0, start_offset=0, num_selected=2) {
  let current_dims = start_dims;
  let current_offset = start_offset;

  const container = document.getElementById(id);
  const dim_plus = container.appendChild(document.createElement(&#34;button&#34;));
  const dim_minus = container.appendChild(document.createElement(&#34;button&#34;));
  const slice_plus = container.appendChild(document.createElement(&#34;button&#34;));
  const slice_minus = container.appendChild(document.createElement(&#34;button&#34;));
  
  const vec_div = container.appendChild(document.createElement(&#34;div&#34;));
  vec_div.id = id + &#34;_vec_div&#34;;

  async function redraw_vec() {
    latexize_vector(vector, vec_div.id, current_offset, AVAILABLE_DIMENSIONS[current_dims], num_selected);
    await MathJax.typesetPromise();
  }

  redraw_vec();


  // create +dimensions button
  dim_plus.textContent = &#34;dim+&#34;;
  dim_plus.onclick = () =&gt; {
    if (AVAILABLE_DIMENSIONS[current_dims + 1] &lt;= vector.length) {
      current_dims = current_dims + 1
      current_offset = Math.min(current_offset, AVAILABLE_DIMENSIONS[current_dims] - num_selected);
      redraw_vec();
    };
  };
  // create -dimensions button
  dim_minus.textContent = &#34;dim-&#34;;
  dim_minus.onclick = () =&gt; {
    current_dims = Math.max(0, current_dims - 1);
    current_offset = Math.min(current_offset, AVAILABLE_DIMENSIONS[current_dims] - num_selected);
    redraw_vec();
  }; 
  // create +slice button
  slice_plus.textContent = &#34;slice+&#34;;
  slice_plus.onclick = () =&gt; {
    current_offset = Math.min(AVAILABLE_DIMENSIONS[current_dims] - num_selected, current_offset + 1); 
    redraw_vec();
  };

  // create -slice button
  slice_minus.textContent = &#34;slice-&#34;;
  slice_minus.onclick = () =&gt; {
    current_offset = Math.max(0, current_offset - 1); 
    redraw_vec();
  };


}
  // hook buttons up to relevant plot callbacks

get_vector_widget(Array.from({length: 1000}, (v, i) =&gt; i), &#39;vector&#39;, 0, 0, 1);

&lt;/script&gt;</description>
      <content>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script type=&#34;text/javascript&#34; id=&#34;MathJax-script&#34; async
  src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34;&gt;
&lt;/script&gt;
&lt;script src=&#34;plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
&lt;div id=&#39;vector&#39;&gt;&lt;/div&gt;

&lt;script&gt;
const VEC_ELEMS_DISPLAYED = 8;
const AVAILABLE_DIMENSIONS = [1, 2, 3, 4, 5, 6, 10, 20, 50, 100, 1000];


function latexize_vector(vector, element_id, slice_offset, dimensions, num_selected) {
  if (dimensions &gt; vector.length) throw(&#34;Dimensions &gt; vector length&#34;);
  let latex_str = `
    \\[
    \\mathbf{
    \\begin{align}
\\vec{v_{${dimensions}}} = \\begin{bmatrix}`;

  const start = Math.max(0, Math.min(slice_offset, dimensions - VEC_ELEMS_DISPLAYED));
  const desired_stop = Math.min(dimensions, slice_offset + VEC_ELEMS_DISPLAYED);
    
  // Adding dots increases the size of the vector, so we need
  // this check to stop the vector increasing and decreasing
  // in length as we scroll through.
  const stop = (start &gt; 0 &amp;&amp; desired_stop &lt; dimensions) ? desired_stop - 1 : desired_stop;

  if (start &gt; 0) latex_str += `\\vdots \\\\`;
  for (let i = start; i &lt; stop; i++) {
    if ((i - slice_offset) &gt;= 0 &amp;&amp; (i - slice_offset) &lt; num_selected) {
      latex_str += `\\mathbf{${vector[i].toFixed(2)}} \\\\`
    } else {
      latex_str += `${vector[i].toFixed(2)} \\\\`
    }
  }
  if (stop &lt; dimensions) latex_str += `\\vdots \\\\`;

  latex_str += `\\end{bmatrix}
              \\end{align}
            }
            \\]`;
  document.getElementById(element_id).innerHTML = latex_str;
}

function get_vector_widget(vector, id, start_dims=0, start_offset=0, num_selected=2) {
  let current_dims = start_dims;
  let current_offset = start_offset;

  const container = document.getElementById(id);
  const dim_plus = container.appendChild(document.createElement(&#34;button&#34;));
  const dim_minus = container.appendChild(document.createElement(&#34;button&#34;));
  const slice_plus = container.appendChild(document.createElement(&#34;button&#34;));
  const slice_minus = container.appendChild(document.createElement(&#34;button&#34;));
  
  const vec_div = container.appendChild(document.createElement(&#34;div&#34;));
  vec_div.id = id + &#34;_vec_div&#34;;

  async function redraw_vec() {
    latexize_vector(vector, vec_div.id, current_offset, AVAILABLE_DIMENSIONS[current_dims], num_selected);
    await MathJax.typesetPromise();
  }

  redraw_vec();


  // create +dimensions button
  dim_plus.textContent = &#34;dim+&#34;;
  dim_plus.onclick = () =&gt; {
    if (AVAILABLE_DIMENSIONS[current_dims + 1] &lt;= vector.length) {
      current_dims = current_dims + 1
      current_offset = Math.min(current_offset, AVAILABLE_DIMENSIONS[current_dims] - num_selected);
      redraw_vec();
    };
  };
  // create -dimensions button
  dim_minus.textContent = &#34;dim-&#34;;
  dim_minus.onclick = () =&gt; {
    current_dims = Math.max(0, current_dims - 1);
    current_offset = Math.min(current_offset, AVAILABLE_DIMENSIONS[current_dims] - num_selected);
    redraw_vec();
  }; 
  // create +slice button
  slice_plus.textContent = &#34;slice+&#34;;
  slice_plus.onclick = () =&gt; {
    current_offset = Math.min(AVAILABLE_DIMENSIONS[current_dims] - num_selected, current_offset + 1); 
    redraw_vec();
  };

  // create -slice button
  slice_minus.textContent = &#34;slice-&#34;;
  slice_minus.onclick = () =&gt; {
    current_offset = Math.max(0, current_offset - 1); 
    redraw_vec();
  };


}
  // hook buttons up to relevant plot callbacks

get_vector_widget(Array.from({length: 1000}, (v, i) =&gt; i), &#39;vector&#39;, 0, 0, 1);

&lt;/script&gt;
</content>
    </item>
    
    <item>
      <title></title>
      <link>https://willsnell.com/drafts/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://willsnell.com/drafts/test/</guid>
      <description>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script src=&#34;./plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div id=&#34;plot&#34; style=&#34;width: 1000px; height: 600px;&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;benchmark&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import digamma from &#39;https://cdn.jsdelivr.net/gh/stdlib-js/math-base-special-digamma@esm/index.mjs&#39;;
// generate points
class Node {
    constructor(val, less_than, greater_than) {
        this.val = val;
        this.less_than = less_than;
        this.greater_than = greater_than;
    }
}

class KDTree {
    constructor(points) {
        this.n_dimensions = points[0].length;
        this.tree = this.build_tree(points, 0, this.n_dimensions);
    }
    build_tree(points, dim, n_dims) {
        if (points.length == 1) {
            return new Node(points[0], null, null);
        }
        // sort a subset of the points
        const n_subset = Math.min(points.length, Math.min(200, Math.max(10, parseInt(points.length / 10))));
        //const n_subset = points.length;
        // assume the area is homogeneous, so we can
        // just pick the first n_subset points.
        let subset = points.slice(0, Math.min(points.length, n_subset)).map((x, i) =&gt; x.concat([i]));
        subset.sort((a, b) =&gt; a[dim] - b[dim]);
        let midpoint = subset[parseInt(subset.length / 2)][subset[0].length - 1];
        let median = points[midpoint];
        let median_elem = median[dim];
        // Remove the median so we don&#39;t count it twice.
        points = points.slice(0, midpoint).concat(points.slice(midpoint + 1));
        
        let next_dim = (dim + 1) % n_dims;

        let points_leq = points.filter((x) =&gt; x[dim] &lt;= median_elem);
        let points_gt = points.filter((x) =&gt; x[dim] &gt; median_elem);

        let less_than, greater_than;
        
        if (points_leq.length &gt; 0) {
            less_than = this.build_tree(points_leq, next_dim, n_dims);
        }
        if (points_gt.length &gt; 0) {
            greater_than = this.build_tree(points_gt, next_dim, n_dims);
        }

        return new Node(median, less_than, greater_than);
    }

    knn(point, k, return_dist=false) {
        let closest_points = []; // [[distance, *point]]
        let n_dimensions = this.n_dimensions;

        function distance(x, y, norm=Math.inf) {
            if (norm == Math.inf) {
                return Math.max(...x.map((x, i) =&gt; Math.abs(x - y[i])));
            }
            return x.reduce((partial_sum, x, i) =&gt; partial_sum + (x-y[i])**norm, 0);
        }

        // find the point where the 

        function find_closest(node, dim=0) {
            let match = node.val;

            let gt = point[dim] &gt; node.val[dim];

            if (node.greater_than &amp;&amp; gt) {
                find_closest(node.greater_than, (dim + 1) % n_dimensions);
            } else if (node.less_than &amp;&amp; !gt) {
                find_closest(node.less_than, (dim + 1) % n_dimensions);
            }

            // At this point, we&#39;ve greedily explored on the 
            // &#34;best&#34; side of the tree.
                let dist = distance(point, match);

            if (closest_points.length &lt; k) {
                closest_points.push([dist].concat(match));
            } else if (dist &lt; closest_points[0][0]) {
                closest_points[0] = [dist].concat(match);
            }
            closest_points.sort((a, b) =&gt; b[0] - a[0]);

            // Check if the distance to the splitting plane
            // is less than the distance to the furthest
            // neighbor.
            if (closest_points[0][0] &gt; distance([point[dim]], [node.val[dim]]) || closest_points.length &lt; k) {
                // If so, traverse the opposite tree to last time.
                    if (node.greater_than &amp;&amp; !gt) {
                        find_closest(node.greater_than, (dim + 1) % n_dimensions);
                    } else if (node.less_than &amp;&amp; gt) {
                        find_closest(node.less_than, (dim + 1) % n_dimensions);
                    }
            }

            return node.val;
        }

        find_closest(this.tree);
        if (return_dist) {
            return [closest_points.map((x) =&gt; x.slice(1)), closest_points.map((x) =&gt; x[0])];
        }
        return closest_points.map((x) =&gt; x.slice(1));
    }

    /* Count the number of points bounded
    * by some range.
    *  bounds is an array of [d_min, d_max].
    *      e.g. for 3D, [[x_min, x_max], [y_min, y_max], [z_min, z_max]]
    */ 
    find_bounded(bounds) {
        let points = [];
        let n_dims = this.n_dimensions;

        function recursively_bound(node, depth=0) {
            let dim = depth % n_dims;

            let splitting_plane = node.val[dim];
            let [left_bound, right_bound] = bounds[dim];

            let lt = left_bound &lt;= splitting_plane;
            let gt = right_bound &gt; splitting_plane;

            if (lt &amp;&amp; gt) {
                // Check if the current point is bounded
                // on all sides
                let bounded = true;
                for (let i = 0; i &lt; bounds.length; i++) {
                    if (bounds[i][0] &gt; node.val[i] || bounds[i][1] &lt;= node.val[i]) {
                        bounded = false;
                        break;
                    }
                }
                if (bounded) { points.push(node.val) };

                // Continue refining on both sides.
                node.less_than ? recursively_bound(node.less_than, depth+1) : null;
                node.greater_than ? recursively_bound(node.greater_than, depth+1) : null;
            } else if (lt) {
                // bounding box is entirely on the 
                // less-than side of the tree
                node.less_than ? recursively_bound(node.less_than, depth + 1) : null;
            } else if (gt) {
                // bounding box is entirely on the greater-than
                // side of the tree.
               node.greater_than ? recursively_bound(node.greater_than, depth + 1) : null; 
            }
        }
        recursively_bound(this.tree);
        return points;
    }
}

// From https://stackoverflow.com/questions/27659675/get-next-smallest-nearest-number-to-a-decimal
function get_epsilon(n) {
  return Math.max( Number.MIN_VALUE, 2 ** Math.floor( Math.log2( n ) ) * Number.EPSILON ) 
}

function normalize(points) {
    let out = Array(points.length).fill(0).map(() =&gt; new Array(points[0].length).fill(0));

    for (let dim = 0; dim &lt; points[0].length; dim++) {
        let mean = points.reduce((partial_sum, x) =&gt; partial_sum + x[dim], 0) / points.length;
        let centred = points.map((x) =&gt; x[dim] - mean);
        let std = (centred.reduce((partial_sum, x) =&gt; partial_sum + x**2, 0) / points.length)**0.5;
        for (let i = 0; i &lt; points.length; i++) {
            out[i][dim] =  centred[i] / std;
        }
    }

    return out;
}


// As per https://arxiv.org/pdf/cond-mat/0305641 
function mutual_information(x_points, y_points, k=3) {
    // normalize points
    x_points = normalize(x_points);
    y_points = normalize(y_points);

    let xy_points = x_points.map((x, i) =&gt; [...x, ...y_points[i]]);
    let xy_tree = new KDTree(xy_points);

    let x_tree = new KDTree(x_points);
    let y_tree = new KDTree(y_points);

    let mean_psi_nx_ny = xy_points.reduce((partial_sum, x, i) =&gt; 
    {
            // We find k + 1 neighbors because the first neighbor is the point itself.
            let [neighbors, dists] = xy_tree.knn(x, k + 1, true);
            // We add an offset because we don&#39;t want a point on the wall of our hypercube
            // to be caught by our hyper rectangles.
            let bound_length = dists[0] - get_epsilon(dists[0]);

            // n_x, n_y = (length - 1) because we will always find the search point, and 
            // need to ignore it.
            let x_bounds = x_points[0].map((_, i) =&gt; [x[i] - bound_length, x[i] + bound_length]);
            let y_bounds = y_points[0].map((_, i) =&gt; [x[x_bounds.length + i] - bound_length, x[x_bounds.length + i] + bound_length]);
            let n_x = x_tree.find_bounded(x_bounds).length - 1;
            let n_y = y_tree.find_bounded(y_bounds).length - 1;
            return partial_sum + (digamma(n_x + 1) + digamma(n_y + 1));
        },
    0) / x_points.length;

    return digamma(k) - mean_psi_nx_ny + digamma(x_points.length);
}

/* Estimate the Mutual Information of a collection
   of signals.

   x_points: An [n x m] dimensional array, with
             m unique signals and n samples.

   returns: I(X1, X2, ... Xm)

*/ 
function mutual_information_n(x_points, k=3) {
    let joint_samples = normalize(x_points);

    let m = x_points[0].length;
    let n_samples = x_points.length;

    let joint_tree = new KDTree(joint_samples);

    let marginal_trees = [];

    for (let signal = 0; signal &lt; m; signal++) {
        marginal_trees.push(new KDTree(joint_samples.map((x, i) =&gt; [x[signal]])));
    }

    // Across all n_x[m], compute digamma(n_x[m] + 1), and then
    // take the mean.
    let mean_psi_nxm = joint_samples.reduce((partial_sum, x, i) =&gt; 
    {
            // We find k + 1 neighbors because the first neighbor is the point itself.
            let [neighbors, dists] = joint_tree.knn(x, k + 1, true);
            // We add an offset because we don&#39;t want a point on the wall of our hypercube
            // to be caught by our hyper rectangles.
            let bound_length = dists[0] - get_epsilon(dists[0]);

            let digamma_sum = 0;

            for (let signal = 0; signal &lt; m; signal++) {
                let bounds = [[x[signal] - bound_length, x[signal] + bound_length]];
                // n_xm = (length - 1) because we will always find the search point, and 
                // need to ignore it.
                let n_xm = marginal_trees[signal].find_bounded(bounds).length - 1;
                digamma_sum += digamma(n_xm + 1);
            }

            return partial_sum + digamma_sum;
        },
    0) / x_points.length;

    return Math.max(0, digamma(k) + (m - 1) * digamma(n_samples) - mean_psi_nxm);
}

function partial_mutual_information(x_points, y_points, z_points, k=3) {
    x_points = normalize(x_points.map((x) =&gt; [x]));
    y_points = normalize(y_points.map((x) =&gt; [x]));
    z_points = normalize(z_points.map((x) =&gt; [x]));

    let joint_samples = x_points.map((x, i) =&gt; [...x, ...y_points[i], ...z_points[i]]);

    let n_samples = x_points.length;

    let joint_tree = new KDTree(joint_samples);
    
    let xz_tree = new KDTree(x_points.map((x, i) =&gt; [...x, ...z_points[i]]));
    let yz_tree = new KDTree(y_points.map((y, i) =&gt; [...y, ...z_points[i]]));
    let z_tree = new KDTree(z_points);

    // Compute the mean of psi(n_xz) + psi(n_yz) - psi(n_z) 
    let mean_psi_nxm = joint_samples.reduce((partial_sum, point, i) =&gt; 
    {
            // We find k + 1 neighbors because the first neighbor is the point itself.
            let [neighbors, dists] = joint_tree.knn(point, k + 1, true);
            // We add an offset because we don&#39;t want a point on the wall of our hypercube
            // to be caught by our hyper rectangles.
            let bound_length = dists[0] - get_epsilon(dists[0]);

            let x_bounds = [point[0] - bound_length, point[0] + bound_length];
            let y_bounds = [point[1] - bound_length, point[1] + bound_length];
            let z_bounds = [point[2] - bound_length, point[2] + bound_length];

            let h_xz = digamma(xz_tree.find_bounded([x_bounds, z_bounds]).length)
            let h_yz = digamma(yz_tree.find_bounded([y_bounds, z_bounds]).length)
            let h_z = digamma(z_tree.find_bounded([z_bounds]).length)

            let digamma_sum = h_xz + h_yz - h_z;

            return partial_sum + digamma_sum;
        },
    0) / x_points.length;

    return Math.max(0, digamma(k) - mean_psi_nxm);
}

//////// Benchmarks /////////////////
let tree;

let n_points = 1_000;
let x = Array(n_points).fill(0).map((x) =&gt; Math.random() * 80);
let z = Array(n_points).fill(0).map((x) =&gt; (Math.random()) * 50);
// let z = Array(n_points).fill(0).map((x) =&gt; Math.random());
let y = x.map((x, i) =&gt; 0.05 * (Math.sin(x / 3) * Math.sin(z[i] / 3) * x * z[i] + Math.random() * 1));
//let z = x.map((x, i) =&gt; (x + y[i]) * (-1 + Math.floor((x / 4) %2) * 2));
//let z = x.map((x, i) =&gt; x + y[i]);


let points = x.map((x, i) =&gt; [x, y[i], z[i]]);
points = normalize(points);

const n_repeats = 1;

let start_build_tree = Date.now();
for (let i = 0; i &lt; n_repeats; i++) {
    tree = new KDTree(points);
}

let xy_tree = new KDTree(x.map((x, i) =&gt; [x, y[i]]));
let z_tree = new KDTree(z.map((z) =&gt; [z]));

let build_time = (Date.now() - start_build_tree) / n_repeats;

let [neighbors, dists] = tree.knn(points[0], 4, true);

let k = 3;

let start_knn_search = Date.now();
for (let i = 0; i &lt; n_repeats; i++) {
    points.map((x) =&gt; tree.knn(x, k + 1));
}

let search_time = (Date.now() - start_knn_search) / n_repeats;


// Test find_bounded //
//
//let b_points = [[1., 2., 3.], [4.,5.,6.], [7.,8.,9.], [10., 11., 12.]];
//let bounds = [[0.99, 7.01], [2.01, 11.01], [6.01, 9.01]];
//
//let bounds_tree = new KDTree(b_points);
//
//let true_bounded = [[7, 8, 9]];
//console.assert(bounds_tree.find_bounded(bounds).map((x, i) =&gt; x.map((xx, ii) =&gt; true_bounded[i][ii] == xx)));

let bound_length = dists[0] + -get_epsilon(dists[0]);
let bounded_x_points = tree.find_bounded([[points[0][0] - bound_length, points[0][0] + bound_length], 
                                          [Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY], 
                                          [points[0][2] - bound_length, points[0][2] + bound_length]]);

let bounded_y_points = tree.find_bounded([[Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY],
                                          [points[0][1] - bound_length, points[0][1] + bound_length],
                                          [points[0][2] - bound_length, points[0][2] + bound_length]]);

let bounded_z_points = tree.find_bounded([[Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY], 
                                          [Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY],
                                          [points[0][2] - bound_length, points[0][2] + bound_length]]);


console.log(`n_x = ${bounded_x_points.length}, n_y = ${bounded_y_points.length}, n_z = ${bounded_z_points.length}`);

let inf_bounds = [Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY];

// Estimate the mutual information
console.log(mutual_information(x.map((x) =&gt; [x]), y.map((x) =&gt; [x])));
console.log(&#34;I(X, Y): &#34;, mutual_information_n(x.map((x, i) =&gt; [x, y[i]])));
console.log(&#34;I(X, Z): &#34;, mutual_information_n(x.map((x, i) =&gt; [x, z[i]])));
console.log(&#34;I(Y, Z): &#34;, mutual_information_n(y.map((x, i) =&gt; [x, z[i]])));
console.log(&#34;I(X, Z | X): &#34;, partial_mutual_information(x, z, x));
console.log(&#34;I(X, Z | Y): &#34;, partial_mutual_information(x, z, y));
//console.log(&#34;I(X, Z): &#34;, mutual_information(x.map((x) =&gt; [x]), z.map((x) =&gt; [x])));
console.assert(mutual_information([[1],[2],[3],[4],[5],[6],[7]], [[1],[2],[3],[4],[5],[6],[7]]) == 0.9499999999999998);

///////////////////////// Plots for verification ////////////////////

// calculate the surface of a sphere for the nearest neighbors
function calc_sphere(cx, cy, cz, radius, n=30) {
    let x = [];
    let y = [];
    let z = [];
    // Create a hemisphere
    for (let i = 0; i &lt; 2 * Math.PI; i += 2 * Math.PI / n) {
        for (let j = 0; j &lt; Math.PI; j += 2 * Math.PI / n) {
            let cj = Math.cos(j);
            x.push(cx + radius * Math.sin(i) * cj);
            y.push(cy + radius * Math.cos(i) * cj);
            z.push(cz + radius * Math.sin(j));
        }
    }

    // Return the two hemispheres
    return [[x, y, z], [x, y, z.map((z) =&gt; 2 * cz -z)]];
}

function cube(cx, cy, cz, edge_length) {
    let l = edge_length;
    return {
        x: [cx - l, cx - l,  cx + l, cx + l, cx - l, cx - l, cx + l, cx + l],
        y: [cy - l, cy + l, cy + l, cy - l, cy - l, cy + l, cy + l, cy - l],
        z: [cz - l, cz - l, cz - l, cz - l, cz + l, cz + l, cz + l, cz + l],
        i: [7, 0, 0, 0, 4, 4, 6, 6, 4, 0, 3, 2],
        j: [3, 4, 1, 2, 5, 6, 5, 2, 0, 1, 6, 3],
        k: [0, 7, 2, 3, 6, 7, 1, 1, 5, 5, 7, 6],
    }
}

// let [[sx, sy, sz], [sx2, sy2, sz2]] = calc_sphere(points[0][0], points[0][1], points[0][2], dists[0]**0.5);
let surf = cube(points[0][0], points[0][1], points[0][2], dists[0]);
surf.opacity = 0.1;
surf.color = &#34;blue&#34;;
surf.type = &#34;mesh3d&#34;;

Plotly.newPlot(&#39;plot&#39;, [
    {
        x: points.map((x) =&gt; x[0]), 
        y: points.map((x) =&gt; x[1]), 
        z: points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 0.5,
            color: &#34;#061623&#34;,
        },
        type: &#39;scatter3d&#39;,
    },
    surf,
    {
        x: bounded_x_points.map((x) =&gt; x[0]),
        y: bounded_x_points.map((x) =&gt; x[1]),
        z: bounded_x_points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 2,
            color: &#34;#E15554&#34;
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: bounded_y_points.map((x) =&gt; x[0]),
        y: bounded_y_points.map((x) =&gt; x[1]),
        z: bounded_y_points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 2,
            color: &#34;#E1BC29&#34;
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: bounded_z_points.map((x) =&gt; x[0]),
        y: bounded_z_points.map((x) =&gt; x[1]),
        z: bounded_z_points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 2,
            color: &#34;#3BB273&#34;
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: neighbors.map((x) =&gt; x[0]),
        y: neighbors.map((x) =&gt; x[1]),
        z: neighbors.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 3,
            color: &#34;#7768AE&#34;,
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: [points[0][0]],
        y: [points[0][1]],
        z: [points[0][2]],
        mode: &#39;markers&#39;,
        marker: {
            size: 5,
            color: &#34;#0D1321&#34;,
        },
        type: &#39;scatter3d&#39;,
    },
],
    {
        width: 1200,
        height: 600,
        margin: {t: 0, l: 0, r: 0, b: 0},
        xaxis: {
            scaleanchor: &#39;y&#39;
        },
        zaxis: {
            scaleanchor: &#39;z&#39;
        },
        scene: {
            camera: {
                projection: {
                    type: &#34;orthographic&#34;,
                }
            }
        },
    }
);
document.getElementById(&#39;benchmark&#39;).textContent = `
Build: ${build_time}ms
KNN-search: ${search_time}ms
`;

&lt;/script&gt;

&lt;/body&gt;</description>
      <content>&lt;!DOCTYPE html&gt;
&lt;head&gt;
&lt;script src=&#34;./plotly-2.32.0.min.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div id=&#34;plot&#34; style=&#34;width: 1000px; height: 600px;&#34;&gt;&lt;/div&gt;
&lt;div id=&#34;benchmark&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;module&#34;&gt;
import digamma from &#39;https://cdn.jsdelivr.net/gh/stdlib-js/math-base-special-digamma@esm/index.mjs&#39;;
// generate points
class Node {
    constructor(val, less_than, greater_than) {
        this.val = val;
        this.less_than = less_than;
        this.greater_than = greater_than;
    }
}

class KDTree {
    constructor(points) {
        this.n_dimensions = points[0].length;
        this.tree = this.build_tree(points, 0, this.n_dimensions);
    }
    build_tree(points, dim, n_dims) {
        if (points.length == 1) {
            return new Node(points[0], null, null);
        }
        // sort a subset of the points
        const n_subset = Math.min(points.length, Math.min(200, Math.max(10, parseInt(points.length / 10))));
        //const n_subset = points.length;
        // assume the area is homogeneous, so we can
        // just pick the first n_subset points.
        let subset = points.slice(0, Math.min(points.length, n_subset)).map((x, i) =&gt; x.concat([i]));
        subset.sort((a, b) =&gt; a[dim] - b[dim]);
        let midpoint = subset[parseInt(subset.length / 2)][subset[0].length - 1];
        let median = points[midpoint];
        let median_elem = median[dim];
        // Remove the median so we don&#39;t count it twice.
        points = points.slice(0, midpoint).concat(points.slice(midpoint + 1));
        
        let next_dim = (dim + 1) % n_dims;

        let points_leq = points.filter((x) =&gt; x[dim] &lt;= median_elem);
        let points_gt = points.filter((x) =&gt; x[dim] &gt; median_elem);

        let less_than, greater_than;
        
        if (points_leq.length &gt; 0) {
            less_than = this.build_tree(points_leq, next_dim, n_dims);
        }
        if (points_gt.length &gt; 0) {
            greater_than = this.build_tree(points_gt, next_dim, n_dims);
        }

        return new Node(median, less_than, greater_than);
    }

    knn(point, k, return_dist=false) {
        let closest_points = []; // [[distance, *point]]
        let n_dimensions = this.n_dimensions;

        function distance(x, y, norm=Math.inf) {
            if (norm == Math.inf) {
                return Math.max(...x.map((x, i) =&gt; Math.abs(x - y[i])));
            }
            return x.reduce((partial_sum, x, i) =&gt; partial_sum + (x-y[i])**norm, 0);
        }

        // find the point where the 

        function find_closest(node, dim=0) {
            let match = node.val;

            let gt = point[dim] &gt; node.val[dim];

            if (node.greater_than &amp;&amp; gt) {
                find_closest(node.greater_than, (dim + 1) % n_dimensions);
            } else if (node.less_than &amp;&amp; !gt) {
                find_closest(node.less_than, (dim + 1) % n_dimensions);
            }

            // At this point, we&#39;ve greedily explored on the 
            // &#34;best&#34; side of the tree.
                let dist = distance(point, match);

            if (closest_points.length &lt; k) {
                closest_points.push([dist].concat(match));
            } else if (dist &lt; closest_points[0][0]) {
                closest_points[0] = [dist].concat(match);
            }
            closest_points.sort((a, b) =&gt; b[0] - a[0]);

            // Check if the distance to the splitting plane
            // is less than the distance to the furthest
            // neighbor.
            if (closest_points[0][0] &gt; distance([point[dim]], [node.val[dim]]) || closest_points.length &lt; k) {
                // If so, traverse the opposite tree to last time.
                    if (node.greater_than &amp;&amp; !gt) {
                        find_closest(node.greater_than, (dim + 1) % n_dimensions);
                    } else if (node.less_than &amp;&amp; gt) {
                        find_closest(node.less_than, (dim + 1) % n_dimensions);
                    }
            }

            return node.val;
        }

        find_closest(this.tree);
        if (return_dist) {
            return [closest_points.map((x) =&gt; x.slice(1)), closest_points.map((x) =&gt; x[0])];
        }
        return closest_points.map((x) =&gt; x.slice(1));
    }

    /* Count the number of points bounded
    * by some range.
    *  bounds is an array of [d_min, d_max].
    *      e.g. for 3D, [[x_min, x_max], [y_min, y_max], [z_min, z_max]]
    */ 
    find_bounded(bounds) {
        let points = [];
        let n_dims = this.n_dimensions;

        function recursively_bound(node, depth=0) {
            let dim = depth % n_dims;

            let splitting_plane = node.val[dim];
            let [left_bound, right_bound] = bounds[dim];

            let lt = left_bound &lt;= splitting_plane;
            let gt = right_bound &gt; splitting_plane;

            if (lt &amp;&amp; gt) {
                // Check if the current point is bounded
                // on all sides
                let bounded = true;
                for (let i = 0; i &lt; bounds.length; i++) {
                    if (bounds[i][0] &gt; node.val[i] || bounds[i][1] &lt;= node.val[i]) {
                        bounded = false;
                        break;
                    }
                }
                if (bounded) { points.push(node.val) };

                // Continue refining on both sides.
                node.less_than ? recursively_bound(node.less_than, depth+1) : null;
                node.greater_than ? recursively_bound(node.greater_than, depth+1) : null;
            } else if (lt) {
                // bounding box is entirely on the 
                // less-than side of the tree
                node.less_than ? recursively_bound(node.less_than, depth + 1) : null;
            } else if (gt) {
                // bounding box is entirely on the greater-than
                // side of the tree.
               node.greater_than ? recursively_bound(node.greater_than, depth + 1) : null; 
            }
        }
        recursively_bound(this.tree);
        return points;
    }
}

// From https://stackoverflow.com/questions/27659675/get-next-smallest-nearest-number-to-a-decimal
function get_epsilon(n) {
  return Math.max( Number.MIN_VALUE, 2 ** Math.floor( Math.log2( n ) ) * Number.EPSILON ) 
}

function normalize(points) {
    let out = Array(points.length).fill(0).map(() =&gt; new Array(points[0].length).fill(0));

    for (let dim = 0; dim &lt; points[0].length; dim++) {
        let mean = points.reduce((partial_sum, x) =&gt; partial_sum + x[dim], 0) / points.length;
        let centred = points.map((x) =&gt; x[dim] - mean);
        let std = (centred.reduce((partial_sum, x) =&gt; partial_sum + x**2, 0) / points.length)**0.5;
        for (let i = 0; i &lt; points.length; i++) {
            out[i][dim] =  centred[i] / std;
        }
    }

    return out;
}


// As per https://arxiv.org/pdf/cond-mat/0305641 
function mutual_information(x_points, y_points, k=3) {
    // normalize points
    x_points = normalize(x_points);
    y_points = normalize(y_points);

    let xy_points = x_points.map((x, i) =&gt; [...x, ...y_points[i]]);
    let xy_tree = new KDTree(xy_points);

    let x_tree = new KDTree(x_points);
    let y_tree = new KDTree(y_points);

    let mean_psi_nx_ny = xy_points.reduce((partial_sum, x, i) =&gt; 
    {
            // We find k + 1 neighbors because the first neighbor is the point itself.
            let [neighbors, dists] = xy_tree.knn(x, k + 1, true);
            // We add an offset because we don&#39;t want a point on the wall of our hypercube
            // to be caught by our hyper rectangles.
            let bound_length = dists[0] - get_epsilon(dists[0]);

            // n_x, n_y = (length - 1) because we will always find the search point, and 
            // need to ignore it.
            let x_bounds = x_points[0].map((_, i) =&gt; [x[i] - bound_length, x[i] + bound_length]);
            let y_bounds = y_points[0].map((_, i) =&gt; [x[x_bounds.length + i] - bound_length, x[x_bounds.length + i] + bound_length]);
            let n_x = x_tree.find_bounded(x_bounds).length - 1;
            let n_y = y_tree.find_bounded(y_bounds).length - 1;
            return partial_sum + (digamma(n_x + 1) + digamma(n_y + 1));
        },
    0) / x_points.length;

    return digamma(k) - mean_psi_nx_ny + digamma(x_points.length);
}

/* Estimate the Mutual Information of a collection
   of signals.

   x_points: An [n x m] dimensional array, with
             m unique signals and n samples.

   returns: I(X1, X2, ... Xm)

*/ 
function mutual_information_n(x_points, k=3) {
    let joint_samples = normalize(x_points);

    let m = x_points[0].length;
    let n_samples = x_points.length;

    let joint_tree = new KDTree(joint_samples);

    let marginal_trees = [];

    for (let signal = 0; signal &lt; m; signal++) {
        marginal_trees.push(new KDTree(joint_samples.map((x, i) =&gt; [x[signal]])));
    }

    // Across all n_x[m], compute digamma(n_x[m] + 1), and then
    // take the mean.
    let mean_psi_nxm = joint_samples.reduce((partial_sum, x, i) =&gt; 
    {
            // We find k + 1 neighbors because the first neighbor is the point itself.
            let [neighbors, dists] = joint_tree.knn(x, k + 1, true);
            // We add an offset because we don&#39;t want a point on the wall of our hypercube
            // to be caught by our hyper rectangles.
            let bound_length = dists[0] - get_epsilon(dists[0]);

            let digamma_sum = 0;

            for (let signal = 0; signal &lt; m; signal++) {
                let bounds = [[x[signal] - bound_length, x[signal] + bound_length]];
                // n_xm = (length - 1) because we will always find the search point, and 
                // need to ignore it.
                let n_xm = marginal_trees[signal].find_bounded(bounds).length - 1;
                digamma_sum += digamma(n_xm + 1);
            }

            return partial_sum + digamma_sum;
        },
    0) / x_points.length;

    return Math.max(0, digamma(k) + (m - 1) * digamma(n_samples) - mean_psi_nxm);
}

function partial_mutual_information(x_points, y_points, z_points, k=3) {
    x_points = normalize(x_points.map((x) =&gt; [x]));
    y_points = normalize(y_points.map((x) =&gt; [x]));
    z_points = normalize(z_points.map((x) =&gt; [x]));

    let joint_samples = x_points.map((x, i) =&gt; [...x, ...y_points[i], ...z_points[i]]);

    let n_samples = x_points.length;

    let joint_tree = new KDTree(joint_samples);
    
    let xz_tree = new KDTree(x_points.map((x, i) =&gt; [...x, ...z_points[i]]));
    let yz_tree = new KDTree(y_points.map((y, i) =&gt; [...y, ...z_points[i]]));
    let z_tree = new KDTree(z_points);

    // Compute the mean of psi(n_xz) + psi(n_yz) - psi(n_z) 
    let mean_psi_nxm = joint_samples.reduce((partial_sum, point, i) =&gt; 
    {
            // We find k + 1 neighbors because the first neighbor is the point itself.
            let [neighbors, dists] = joint_tree.knn(point, k + 1, true);
            // We add an offset because we don&#39;t want a point on the wall of our hypercube
            // to be caught by our hyper rectangles.
            let bound_length = dists[0] - get_epsilon(dists[0]);

            let x_bounds = [point[0] - bound_length, point[0] + bound_length];
            let y_bounds = [point[1] - bound_length, point[1] + bound_length];
            let z_bounds = [point[2] - bound_length, point[2] + bound_length];

            let h_xz = digamma(xz_tree.find_bounded([x_bounds, z_bounds]).length)
            let h_yz = digamma(yz_tree.find_bounded([y_bounds, z_bounds]).length)
            let h_z = digamma(z_tree.find_bounded([z_bounds]).length)

            let digamma_sum = h_xz + h_yz - h_z;

            return partial_sum + digamma_sum;
        },
    0) / x_points.length;

    return Math.max(0, digamma(k) - mean_psi_nxm);
}

//////// Benchmarks /////////////////
let tree;

let n_points = 1_000;
let x = Array(n_points).fill(0).map((x) =&gt; Math.random() * 80);
let z = Array(n_points).fill(0).map((x) =&gt; (Math.random()) * 50);
// let z = Array(n_points).fill(0).map((x) =&gt; Math.random());
let y = x.map((x, i) =&gt; 0.05 * (Math.sin(x / 3) * Math.sin(z[i] / 3) * x * z[i] + Math.random() * 1));
//let z = x.map((x, i) =&gt; (x + y[i]) * (-1 + Math.floor((x / 4) %2) * 2));
//let z = x.map((x, i) =&gt; x + y[i]);


let points = x.map((x, i) =&gt; [x, y[i], z[i]]);
points = normalize(points);

const n_repeats = 1;

let start_build_tree = Date.now();
for (let i = 0; i &lt; n_repeats; i++) {
    tree = new KDTree(points);
}

let xy_tree = new KDTree(x.map((x, i) =&gt; [x, y[i]]));
let z_tree = new KDTree(z.map((z) =&gt; [z]));

let build_time = (Date.now() - start_build_tree) / n_repeats;

let [neighbors, dists] = tree.knn(points[0], 4, true);

let k = 3;

let start_knn_search = Date.now();
for (let i = 0; i &lt; n_repeats; i++) {
    points.map((x) =&gt; tree.knn(x, k + 1));
}

let search_time = (Date.now() - start_knn_search) / n_repeats;


// Test find_bounded //
//
//let b_points = [[1., 2., 3.], [4.,5.,6.], [7.,8.,9.], [10., 11., 12.]];
//let bounds = [[0.99, 7.01], [2.01, 11.01], [6.01, 9.01]];
//
//let bounds_tree = new KDTree(b_points);
//
//let true_bounded = [[7, 8, 9]];
//console.assert(bounds_tree.find_bounded(bounds).map((x, i) =&gt; x.map((xx, ii) =&gt; true_bounded[i][ii] == xx)));

let bound_length = dists[0] + -get_epsilon(dists[0]);
let bounded_x_points = tree.find_bounded([[points[0][0] - bound_length, points[0][0] + bound_length], 
                                          [Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY], 
                                          [points[0][2] - bound_length, points[0][2] + bound_length]]);

let bounded_y_points = tree.find_bounded([[Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY],
                                          [points[0][1] - bound_length, points[0][1] + bound_length],
                                          [points[0][2] - bound_length, points[0][2] + bound_length]]);

let bounded_z_points = tree.find_bounded([[Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY], 
                                          [Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY],
                                          [points[0][2] - bound_length, points[0][2] + bound_length]]);


console.log(`n_x = ${bounded_x_points.length}, n_y = ${bounded_y_points.length}, n_z = ${bounded_z_points.length}`);

let inf_bounds = [Number.NEGATIVE_INFINITY, Number.POSITIVE_INFINITY];

// Estimate the mutual information
console.log(mutual_information(x.map((x) =&gt; [x]), y.map((x) =&gt; [x])));
console.log(&#34;I(X, Y): &#34;, mutual_information_n(x.map((x, i) =&gt; [x, y[i]])));
console.log(&#34;I(X, Z): &#34;, mutual_information_n(x.map((x, i) =&gt; [x, z[i]])));
console.log(&#34;I(Y, Z): &#34;, mutual_information_n(y.map((x, i) =&gt; [x, z[i]])));
console.log(&#34;I(X, Z | X): &#34;, partial_mutual_information(x, z, x));
console.log(&#34;I(X, Z | Y): &#34;, partial_mutual_information(x, z, y));
//console.log(&#34;I(X, Z): &#34;, mutual_information(x.map((x) =&gt; [x]), z.map((x) =&gt; [x])));
console.assert(mutual_information([[1],[2],[3],[4],[5],[6],[7]], [[1],[2],[3],[4],[5],[6],[7]]) == 0.9499999999999998);

///////////////////////// Plots for verification ////////////////////

// calculate the surface of a sphere for the nearest neighbors
function calc_sphere(cx, cy, cz, radius, n=30) {
    let x = [];
    let y = [];
    let z = [];
    // Create a hemisphere
    for (let i = 0; i &lt; 2 * Math.PI; i += 2 * Math.PI / n) {
        for (let j = 0; j &lt; Math.PI; j += 2 * Math.PI / n) {
            let cj = Math.cos(j);
            x.push(cx + radius * Math.sin(i) * cj);
            y.push(cy + radius * Math.cos(i) * cj);
            z.push(cz + radius * Math.sin(j));
        }
    }

    // Return the two hemispheres
    return [[x, y, z], [x, y, z.map((z) =&gt; 2 * cz -z)]];
}

function cube(cx, cy, cz, edge_length) {
    let l = edge_length;
    return {
        x: [cx - l, cx - l,  cx + l, cx + l, cx - l, cx - l, cx + l, cx + l],
        y: [cy - l, cy + l, cy + l, cy - l, cy - l, cy + l, cy + l, cy - l],
        z: [cz - l, cz - l, cz - l, cz - l, cz + l, cz + l, cz + l, cz + l],
        i: [7, 0, 0, 0, 4, 4, 6, 6, 4, 0, 3, 2],
        j: [3, 4, 1, 2, 5, 6, 5, 2, 0, 1, 6, 3],
        k: [0, 7, 2, 3, 6, 7, 1, 1, 5, 5, 7, 6],
    }
}

// let [[sx, sy, sz], [sx2, sy2, sz2]] = calc_sphere(points[0][0], points[0][1], points[0][2], dists[0]**0.5);
let surf = cube(points[0][0], points[0][1], points[0][2], dists[0]);
surf.opacity = 0.1;
surf.color = &#34;blue&#34;;
surf.type = &#34;mesh3d&#34;;

Plotly.newPlot(&#39;plot&#39;, [
    {
        x: points.map((x) =&gt; x[0]), 
        y: points.map((x) =&gt; x[1]), 
        z: points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 0.5,
            color: &#34;#061623&#34;,
        },
        type: &#39;scatter3d&#39;,
    },
    surf,
    {
        x: bounded_x_points.map((x) =&gt; x[0]),
        y: bounded_x_points.map((x) =&gt; x[1]),
        z: bounded_x_points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 2,
            color: &#34;#E15554&#34;
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: bounded_y_points.map((x) =&gt; x[0]),
        y: bounded_y_points.map((x) =&gt; x[1]),
        z: bounded_y_points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 2,
            color: &#34;#E1BC29&#34;
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: bounded_z_points.map((x) =&gt; x[0]),
        y: bounded_z_points.map((x) =&gt; x[1]),
        z: bounded_z_points.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 2,
            color: &#34;#3BB273&#34;
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: neighbors.map((x) =&gt; x[0]),
        y: neighbors.map((x) =&gt; x[1]),
        z: neighbors.map((x) =&gt; x[2]),
        mode: &#39;markers&#39;,
        marker: {
            size: 3,
            color: &#34;#7768AE&#34;,
        },
        type: &#39;scatter3d&#39;,
    },
    {
        x: [points[0][0]],
        y: [points[0][1]],
        z: [points[0][2]],
        mode: &#39;markers&#39;,
        marker: {
            size: 5,
            color: &#34;#0D1321&#34;,
        },
        type: &#39;scatter3d&#39;,
    },
],
    {
        width: 1200,
        height: 600,
        margin: {t: 0, l: 0, r: 0, b: 0},
        xaxis: {
            scaleanchor: &#39;y&#39;
        },
        zaxis: {
            scaleanchor: &#39;z&#39;
        },
        scene: {
            camera: {
                projection: {
                    type: &#34;orthographic&#34;,
                }
            }
        },
    }
);
document.getElementById(&#39;benchmark&#39;).textContent = `
Build: ${build_time}ms
KNN-search: ${search_time}ms
`;

&lt;/script&gt;

&lt;/body&gt;
</content>
    </item>
    
    <item>
      <title>About me</title>
      <link>https://willsnell.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://willsnell.com/about/</guid>
      <description>&lt;p&gt;Hi, I&amp;rsquo;m Will!&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m an engineer living in Auckland. I have a Master&amp;rsquo;s in Mechanical and Aerospace engineering,
but I write about programming and machine learning, mostly.&lt;/p&gt;
&lt;p&gt;Things I&amp;rsquo;ve done (so far):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Helped develop a &lt;a href=&#34;https://www.youtube.com/live/LtvMiivrxxA?si=-F8PH2Z62zVpUlsi&amp;t=1930&#34;&gt;rocket engine and send a satellite to the moon.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lead the analysis of several propellant systems for the &lt;a href=&#34;https://www.rocketlabusa.com/launch/neutron/&#34;&gt;reusable Neutron rocket.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lead the development and early testing of Neutron&amp;rsquo;s &lt;a href=&#34;https://en.wikipedia.org/wiki/Reaction_control_system&#34;&gt;RCS system.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Developed internal tools for modelling, data analysis, and configuration management at &lt;a href=&#34;https://www.rocketlabusa.com/&#34;&gt;Rocket Lab.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learnt Rust (and accidentally learnt JavaScript and some web-dev along the way) by developing &lt;strong&gt;&lt;a href=&#34;https://www.playhexchess.com&#34;&gt;playhexchess.com&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.linkedin.com/in/william-snell-818159171&#34;&gt;linkedin&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;</description>
      <content>&lt;p&gt;Hi, I&amp;rsquo;m Will!&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m an engineer living in Auckland. I have a Master&amp;rsquo;s in Mechanical and Aerospace engineering,
but I write about programming and machine learning, mostly.&lt;/p&gt;
&lt;p&gt;Things I&amp;rsquo;ve done (so far):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Helped develop a &lt;a href=&#34;https://www.youtube.com/live/LtvMiivrxxA?si=-F8PH2Z62zVpUlsi&amp;t=1930&#34;&gt;rocket engine and send a satellite to the moon.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lead the analysis of several propellant systems for the &lt;a href=&#34;https://www.rocketlabusa.com/launch/neutron/&#34;&gt;reusable Neutron rocket.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lead the development and early testing of Neutron&amp;rsquo;s &lt;a href=&#34;https://en.wikipedia.org/wiki/Reaction_control_system&#34;&gt;RCS system.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Developed internal tools for modelling, data analysis, and configuration management at &lt;a href=&#34;https://www.rocketlabusa.com/&#34;&gt;Rocket Lab.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Learnt Rust (and accidentally learnt JavaScript and some web-dev along the way) by developing &lt;strong&gt;&lt;a href=&#34;https://www.playhexchess.com&#34;&gt;playhexchess.com&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://www.linkedin.com/in/william-snell-818159171&#34;&gt;linkedin&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/williamsnell&#34;&gt;github&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
</content>
    </item>
    
  </channel>
</rss>
