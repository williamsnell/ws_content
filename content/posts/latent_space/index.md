+++
title = "Navigating Hyperspace"
date = 2024-07-25T12:19:22+12:00
image = "routeburn.jpg"
cover = "routeburn.jpg"
+++

# Why explore hyperspace?

Hyperspace is actually very commonly used in real world applications. A common, but not exclusive
use, is in neural networks. The motivating
example for this article comes from the sub-field of [Generative Adversarial Networks](https://developers.google.com/machine-learning/gan).

The following portraits were generated by Nvidia's StyleGAN:

---
<div style="display: flex; justify-content: space-around;">
<img src="./near_origin_scale/degen_near_origin_with_scalelerp_0.00.jpg"
alt="A painting of a woman, looking to the left" style="box-sizing: border-box; width: calc(min(45%, 400px))"/>
<img src="./near_origin_scale/degen_near_origin_with_scalelerp_1.00.jpg"
alt="A painting of a man, looking to the right" style="box-sizing: border-box; width: calc(min(45%, 400px))"/>
</div>

---

To dramatically oversimplify, these neural networks take an input vector, 
do some transformations on it, and produce an image. The input vector 
is typically random noise, and the vector is often quite long - hundreds or thousands of elements long.

These vectors make up the **latent space** of the model. Because these
vectors are long, the latent space is high dimensional.
Manipulating the outputs of these models relies on us
being able to chart paths through their latent space.

For example, if we want to smoothly blend from the first painting above to the second, 
we need a way to traverse from the vector representing one image
to the vector representing the other. 

<script src="./plotly-2.32.0.min.js" charset="utf-8"></script>
<script src="math_lib.js"></script>
<script src="charts.js"></script>
<script src="vector_math.js"></script>
<script src="interp.js"></script>


## The obvious answer (is wrong)

To get from point A to point B, the obvious answer is to go in as straight a 
line as possible. The simplest answer here is also the shortest. 
Indeed, when working with latent spaces, going in a straight line does generally work, 
with varying degrees of success. This is known as linear interpolation (lerp), and 
would be written something like this:

```python
    def lerp(fraction, start_vec, stop_vec):
        return start_vec + fraction * (stop_vec - start_vec)
```

In 3D-space, this looks like:

<div id="3d_lerp"></div>
<script>
const demo_start = [-0.5012528962436638, -0.9103151253007502, 0.5048315888047492];
const demo_stop = [0.905189016060779, -0.28742159270964684, -0.0913802767988876];
const vec_space_1000 = rand(10000, 1000);
let redraw_3d_lerp = get_interpolated_chart(vec_space_1000, "3d_lerp", lerp, demo_start, demo_stop,
                                          identity_transform);
redraw_3d_lerp(3, 0, identity_transform);
</script>

> Note: Most of the plots on this page are interactive! Have a play!

While exploring this topic, I came across a [befuddling thread](https://github.com/soumith/dcgan.torch/issues/14) 
which suggested that the best path was **not, in fact, a straight line**. Rather, a function called
`slerp`, or "spherical linear interpolation", was suggested. This has the rather complicated
functional form:

```python
    def slerp(fraction, start_vec, stop_vec):
        omega = np.arccos(np.clip(np.dot(start_vec/np.linalg.norm(start_vec), stop_vec/np.linalg.norm(stop_vec)), -1, 1))
        so = np.sin(omega)
        # Revert to linear interpolation if the two vectors are pi radians apart
        if so == 0:
            return (1.0 - fraction) * start_vec + fraction * stop_vec # L'Hopital's rule/LERP

        return np.sin((1.0-fraction)*omega) / so * start_vec + np.sin(fraction*omega) / so * stop_vec
```

Even more confusingly, when plotted in 3D space, this function gives a path that looks like
this:

<div id="3d_slerp"></div>
<script>
let redraw_3d_slerp = get_interpolated_chart(vec_space_1000, "3d_slerp", slerp, demo_start, demo_stop,
                                          identity_transform);
redraw_3d_slerp(3, 0, identity_transform);
</script>

When thinking about what a "good" interpolation path might look like, a few
different ideas come to mind. We want it to be:
- *Smooth* - in my experience, jagged, jerky paths do not work well
    for blending between two latent vectors.
- *Relatively short*, since we care about capturing the changes 
    between two specific points, rather than going sightseeing
    to irrelevant destinations
- *Well-trodden* - We've trained our neural net on a limited set of data.
    If our interpolation takes us far outside anything the neural net 
    has ever seen, it's unlikely to perform well.

Looking at slerp, we can see:
- It is *smooth*
- It doesn't look particularly short. In fact, it's much *longer*
     than our straight-line path.
- It doesn't seem to stick particularly closely to the data we've
    trained the network on. In fact, it sometimes goes **outside
    of our (-1, 1) domain** entirely! 

In 2D and 3D space, linear interpolation simply doesn't have the issues
that slerp does. **Yet, slerp is consistently recommended.**

Clearly, something about hyperspace behaves very non-intuitively!

Strap in... because it's time to go exploring.

# Windows into Hyperspace

Let's start with the concept of vectors. 

A vector is just a collection of numbers,
arranged in a single column or row, like so:

\[
\begin{align}
    \vec{v}_{3} = \begin{bmatrix}
        1.9 \\
        4.7 \\
        -3.1 \\
    \end{bmatrix}
\end{align}
\]

An n-dimensional vector is \(n\) items long:

\[
\begin{align}
    \vec{v}_{n} = \begin{bmatrix}
        x_{1} \\
        \vdots \\
        x_{n}
    \end{bmatrix}
\end{align}
\]

Vectors can be used to represent all sorts of things, but here we're
going to use them to represent *cartesian coordinates*.

## 1-space

If we had only 1 spatial dimension to play with, we could represent every 
possible position with a 1-dimensional vector:

\[
\begin{align}
    \vec{v}_{1} = \begin{bmatrix}
        x_{1} \\
    \end{bmatrix}
\end{align}
\]

If we were to fill our space with lots of random points, uniformly 
distributed from -1 to 1, it would look like this: 


<div id="1d_space_chart" class="plotly"></div>

<script>
const vec_space = rand(1000, 1);
get_2d_chart(vec_space, "1d_space_chart", 0, ["", "", ""]);
</script>


Hopefully, this result is pretty unsurprising. 


## 2-space
If we extend our vectors into two dimensions, and perform the same exercise, we'll get
something like this: 

<div id="2d_space_chart" class="plotly"></div>

<script>
const vec_space_2 = rand(1_000, 2);
get_2d_chart(vec_space_2, "2d_space_chart", 0, ["", "", ""]);
</script>

For every possible location in this space, we can
define an exact point through something like:

\[
\begin{align}
    \vec{v}_{2} = \begin{bmatrix}
        -0.85 \\
        0.24 \\
    \end{bmatrix}
\end{align}
\]

## 3-space
Extending up to 3D is quite straightforward, where we 
now have 3-long vectors like this:

<div id="3_vec">
\[
\begin{align}
    \vec{v}_{3} = \begin{bmatrix}
        0.26 \\
        -0.88 \\
        -0.9 \\
    \end{bmatrix}
\end{align}
\]
</div>

Let's again scatter some points uniformly between -1 and 1, 
this time in 3 dimensions:

<div id="3d_space_chart" style="width: 100%;"></div>

<script>
const vec_space_3 = rand(10_000, 3);
get_3d_chart(vec_space_3, "3d_space_chart", 0, ["", "", ""]);
</script>

We're very used to looking at 3D space through these kinds of visualizations, where 
our brain can reconstruct a series of 2D images into a 3D representation.

## Flattening Space

What if we wanted to look at **this 4D** vector
inside its vector space:

\[
\begin{align}
    \vec{v}_{4} = \begin{bmatrix}
        0.93  \\
        -0.43 \\
        0.67  \\
        0.12  \\
    \end{bmatrix}
\end{align}
\]

We could *try* using time as an extra dimension,
but we've already run out of spatial dimensions. 

Of course, we want to go far beyond a mere *four* dimensions. 
Even if we used 
How would we visualize something like this?

\[
\begin{align}
    \vec{v}_{1000} = \begin{bmatrix}
        x_{1}      \\
        x_{2}      \\
        \vdots     \\
        x_{1000}   \\
    \end{bmatrix}
\end{align}
\]

## Projecting 

To glimpse higher dimensions, we're
necessarily going to need to make compromises. 
With *up to* 3 dimensions to play with, any given 
viewport will need to choose what information to show and what to hide. 

A natural way to project higher dimensions is to just take
the first \(n\) dimensions we can display, and ignore the rest.

We can visualize what this looks like by creating a vector space
in three dimensions, and visualizing it with two. 

If we want to display the vector:

\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        0.21   \\
        -0.85  \\
        -0.32  \\
    \end{bmatrix}
\end{align}
\]

We can display the first 2 elements, i.e.:

\[
\begin{align}
    \vec{c}_2 = \begin{bmatrix}
        0.21  \\
        -0.85 \\
    \end{bmatrix}
\end{align}
\]

Where \(\vec{c}_2\) represents a **cartesian projection**
down to 2 dimensions.

We can write this as an equation:

\[
    \vec{v}_3 \mapsto \vec{c}_2
\]

Where the arrow \(\mapsto\) means
"maps to".

Visualized, it looks like so:

<div id="3d_into_2d" style="width: 100%;"></div>

<script>
get_2d_3d_chart(vec_space_3, "3d_into_2d");
</script>

We can pick any 2 elements to display, of course. 
Representing our 3-space in 2 dimensions could 
be done equally validly by picking two different
elements, such as the last element \(x_{3}\)
and the second element \(x_{2}\):

\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        -0.32 \\
        -0.85 \\
    \end{bmatrix}
\end{align}
\]

What does our 2D projection tell us about the 3D space?
Well, we effectively get the same view as if we rotated 
our 3D view until we were just looking at one face. 

If we're plotting, say, \(x_{1}\) and \(x_{2}\),
we get a perfect understanding of how our points are
distributed in those two dimensions. 

Should we want to know
what portion of points have \(x_{1}\) > 0
and \(x_{2}\) < 0, we can
look at the 2D chart and easily see the answer is
~25%.

However, we get absolutely no information about the
rest of our vector. It wouldn't matter if we were
plotting a vector of length 3 or a vector of length 
3000 - from this viewpoint, they all look the same.

## Different Projections

So far, we've been exploring space with *cartesian* coordinates.

Without completely justifying it, I'm going to introduce
a completely different coordinate system - [spherical coordinates](https://en.wikipedia.org/wiki/Spherical_coordinate_system).

Most people are used to "cartesian" coordinates. In the following
image, it seems natural to define the position of the red cross based
on two distances, which we typically call x and y.
<img src="xy.svg">

We could represent this point as a vector:

\[
\begin{align}
    \vec{v}_2 = \begin{bmatrix}
        x \\
        y \\
    \end{bmatrix}
\end{align}
\]

In higher dimensions, we can add more directions, provided they are
perpendicular to all the other directions. Hence, for 3d, we might
use (x, y, z).

In a spherical coordinate system, however, a point in space is defined
not by \(n\) orthogonal coordinates (e.g. x, y, and z), but rather 
as a *radial distance* \(r\), and then a series of angles.

To fully describe any point in 2D-space, we need two coordinates. 
Since we already have one (the distance from the origin \(r\)), 
we need one more. Hence, a 2D spherical coordinate system would have
one angle, \(\theta_1\).

<img src="radial.svg">

We can also represent this point as a vector:

\[
\begin{align}
    \vec{s}_2 = \begin{bmatrix}
        r          \\
        \theta_{1} \\
    \end{bmatrix}
\end{align}
\]

Notice that **both \(\vec{v}_2\) and \(\vec{s}_2\)** refer to 
the exact same point in space. The actual numbers inside the vectors,
and the coordinate **system** used are very different, but the point 
in space is the same.

### Adding Dimensions

In 3-space, we need a third coordinate. For cartesian coordinates, we add z 
to our existing x and y. For spherical coordinates, we add 
another angle \(\theta_2\). 

These two vectors represent the same position:

\[
\begin{align}
    \vec{v} = \begin{bmatrix}
        0.54  \\
        -0.87 \\
        0.26  \\
    \end{bmatrix}_{[x,y,z]}
    = \vec{s} = \begin{bmatrix}
        1.06  \\
        -1.02 \\
        1.32  \\
    \end{bmatrix}_{[r, \theta_1, \theta_2]}
\end{align}
\]

### Why bother with spherical coordinates?
How does this help us? After all, you still
need an n-length vector to represent a point in n-space.

What's interesting, however, is when you start looking at 
higher dimensions. Since the length \(r\) takes into account
the entire vector, plotting the first 2 or 3 elements in the 
spherical vector gives us a different view on higher dimensions.

Importantly, **we always keep the magnitude of the full vector** 
when using spherical coordinates.

We then get to select 1 angle (for a 2D plot) or 2 angles (for 
a 3D plot). These angles represent the relative positioning
between **some, but not all** elements of the vector.

[Earlier, we projected higher-dimensional space](#projecting) into 2D and 3D
cartesian plots. We got to pick 2 elements from our larger vector, and had to 
throw away the rest.

We have to do a similar thing in spherical coordinates. However, we *always* 
keep the magnitude. This means that we're left with the ability to pick 
one angle (for a 2d plot) or 2 angles (for a 3d plot) from our larger
vector.

>Below, you can increase the dimensionality of the space being
>visualized.
>
>**Before you do**, make a guess about what you think
>will happen as the number of dimensions increases.
>
>Remember, we're keeping the *vector magnitude*, but
>can only keep one angle (for the 2D plot) or 2 
>angles (for the 3D plot).
>
>How many dimensions do you think we can plot before
>the spherical projection will start to look different
>to the cartesian projection?

<div id="spherical" style="width: 100%;"></div>
<div id="spherical_vec"></div>
<div id="tooltip-1space" style="display: none;">

>  // 1-space
>
> 1-space is boring as ever... 
>
> Jump to the next space with the "Dimensions (+)" button.
</div>
<div id="tooltip-2space" style="display: none;">

>// 2-space
>
>In 2-space, both the 2D and the 3D plot display the same 
>thing. This is also the exact same view we would get if we were
>using cartesian coordinates. Because any 2-length vector losslessly
>describes this space, we can freely switch between them without issue.
</div>
<div id="tooltip-3space" style="display: none;">

> **Important**: understanding the 2D and 3D plots at for a 3D space 
> is critical to understanding the rest of this article. Take the time
> to try and wrap your head around the link between these two plots.
>
> // 3-space
>
>Our **3D plot** still holds enough
>dimensionality to perfectly represent our vector, and so our view is
>identical to the cartesian plot we had earlier. That is,
>our mapping \(\vec{v} \mapsto \vec{s}\) is lossless.
>
>The **2D plot**, however, is different. We're fundamentally 
>losing some information when projecting from \(\vec{v}_3\) to \(\vec{s}_2\). 
>Notably, even though our points are randomly
>distributed between -1 and 1, we are starting to see points shift outside
>of that range.
>
>Remember that the distance from the origin (0, 0) in our 2D plot now
>represents the absolute distance from the origin in **n-space**. 

> **Questions**
>
>Looking at the 3D view of the cube, which points do you think
>have a distance to 
>the origin (a *vector magnitude*) greater than 1?
>
>Interestingly, a hole has started to appear in the centre of the plot. 
>Why do you think this is? 
>
>What might you expect to see happen as we continue to increase the dimensionality
>of our space?
</div>
<div id="tooltip-4space" style="display: none;">

>// 4-space
>
>This is the first space that cannot be fully represented by the
>spatial dimensions we have at hand. If you've been watching the 2D 
>plot over the last few dimensionalities, you should be able to guess
>what's coming for our 3-space plot.
>
>This is also the first dimensionality where we get multiple 3D and 2D 
>plots to hop between. By pressing the "Elements (-)" or "Elements (+)"
>buttons, we can move through the vector, choosing different elements
>to act as the "direction" component of our spherical projection.
</div>

<div id="tooltip-5space" style="display: none;">

>// 5-space and beyond
>
>I'll leave you be as you explore the next few dimensions.
>
>Have a play around, and try and build an intuition for 
>what these charts are telling you about the spaces.
>
>Remember, the **Dimensions** buttons change the dimensionality
>of the underlying vector space, and the **Elements** buttons
>change which elements of \(\vec{v}\) we're using to calculate
>\(\theta_1\) and \(\theta_2\).
</div>

<script>
let dims_with_text = [1, 2, 3, 4, 5];
let redraw_spherical = get_projected_chart(vec_space_1000, 'spherical', ["", "", ""], vecs_to_spherical);
let callback = (dimensions, slice_offset) => {
    for (let dim of dims_with_text) {
        if (dim == dimensions) {
            document.getElementById(`tooltip-${dimensions}space`).style.display = "block";
        } else if (dimensions > dims_with_text[dims_with_text.length - 1]) {
            document.getElementById(`tooltip-${dims_with_text[dims_with_text.length - 1]}space`).style.display = "block";
        } else {
            document.getElementById(`tooltip-${dim}space`).style.display = "none";
        }
    }
    redraw_spherical(dimensions, slice_offset);
}
let widget = get_vector_widget(vec_space_1000[0], 'spherical_vec', callback, 1);
</script>

## What's going on?

Our projection has shown us an unintuitive, but true, fact about
hyperspace - as the dimensionality increases, our points converge
to a hyperspherical shell. The radius of this shell scales with
the square root of our initial distribution's variance, \(\sqrt{\sigma^2} = \sigma\), 
and with the square root of our dimensionality, \(\sqrt{n}\). 

The exact formula for the radius varies depending on the type of
noise used (results for a [uniform distribution](https://stats.stackexchange.com/questions/317095/expectation-of-square-root-of-sum-of-independent-squared-uniform-random-variable/317475#317475)
and this [great post with results for normal distributions](https://www.johndcook.com/blog/2011/09/01/multivariate-normal-shell/)).

For both uniform and normal distributions, the hyperspherical 
shell has a relatively constant thickness as the dimensionality
increases, leading to an increasingly shell-like distribution of points.


### What does this mean?
In lower dimension spaces (2D, 3D, etc.) the radius of our hypershell
is of the same order as the variance of the distribution. This means 
that, in general, there isn't much of a "hole" at the origin. However,
even in 3D (using our 2D plot), we start to see a gap open up near the 
origin. 

Let's consider two different interpretations of how to interpret the 
existence of a hyperspherical shell.

### Geometric Interpretation

As explained in [John D. Cook's post](https://www.johndcook.com/blog/2011/09/01/multivariate-normal-shell/),
volume **grows faster** in higher dimensions. 
For our uniform distribution, our probability density is constant between its bounds of (-1, 1),
and so we can pretty much ignore it.

Volume, however, is proportional to \(r^n\), where \(r\) is the distance 
from the origin and \(n\) is the dimensionality of our space. 
If \(n = 1000\) dimensions, the difference between a sphere of radius 
0.999 and radius 1.000 is 

\[
1.000^{1000} - 0.99^{1000} \approx 0.9999
\]

In other words, >99% of all of our volume is contained in an outer shell, with 
thickness of 1% the radius of our space. 
The reason this collosal growth of volume with radius is not intuitive, is because
in 3D, the same calculation would give around 3% of the volume in the outermost
shell of our sphere:

\[
1.000^3 - 0.99^3 \approx 0.03 
\]

Hence, even though our probability density function is constant in space, 
when we go to higher dimensions, **the amount of space near the origin is astronomically
low, and the amount at the outer perimeter is astronomically high.** 

Because so much space is so far out, our points will inevitably "cluster"
there.


### Statistical Interpretation

We can also think about this result statistically.

All the elements in our vectors are independent and identically distributed. 
The more elements we have, the more we will expect to see strong statistical
trends in the overall properties of our vector, even while individual
elements remain random.

Let's imagine we're rolling a fair die, with sides labelled 0, 1, 2, 3, 4, and 5.
The expected value of our roll is 2.5, but we wouldn't be surprised with a 0
or a 5.

If we now roll 2 dice, make a graph, and plot our first roll on the x axis
and our second on the y axis, we again get a fairly even distribution.

However, if we instead added the total of our two dice together, we
would be looking at a score between 0 and 10, with 5 being our expected value. 
Already, our sum is starting to cluster, with 5 much more likely than
either 0 or 10.

The more dice we roll:

1) The bigger we expect our total score to be, and
2) The less and less likely we are to have a sum near 0 (or near the absolute
    highest possible score of \(5 \times n\) rolls.)

The same process, roughly, is going on with the magnitude of our vectors. 
Instead of just summing our rolls, we're squaring each roll, summing the
squares, and then taking the square root. These functions warp and 
compress space a bit, but our intuition should generally still hold.

We should intuitively expect that the more dice we roll, 

1) The bigger our square-root sum of squares is, and
2) The less and less likely we are to have a point near the origin
    (or in the corners of our hypercube.)


# Tracing Lines Through Hyperspace

Hopefully, you now have a solid grip on the spherical projections 
we'll be using from this point onwards. Remember, the distance
from a point to the origin in each plot represents the vector magnitude of 
the *full vector*. 

Under this lens, what does linear interpolation (our `lerp` function from earlier)
look like?

<div id="spherical_lerp"></div>
<div id="lerp_vec"></div>
<script>
let redraw_chart = get_interpolated_chart(vec_space_1000, "spherical_lerp", lerp, vec_space_1000[0], vec_space_1000[1],
                                          vecs_to_spherical);
let widget2 = get_vector_widget(vec_space_1000[0], "lerp_vec", redraw_chart, 1);
</script>

At low dimensions, lerp behaves exactly how we expect it to. But by the time we reach
around 20 dimensions, there's a clear problem. Our linear path is well outside 
the bounds of all the points in our vector space. 

As we increase the dimensionality of our space, the problem gets worse. At 1000 dimensions,
lerp spends almost the entirety of its path completely outside of the hyperspherical shell 
that makes up the points in our vector space.

In a machine learning context, this would mean that the interpolation is feeding in data 
well outside the bounds of anything the model has been trained on. 

## Why Does Lerp Behave Like This in Higher Dimensional Spaces?


# Slerp

<div id="spherical_slerp"></div>
<div id="slerp_vec"></div>
<script>
let redraw_slerp = get_interpolated_chart(vec_space_1000, "spherical_slerp", slerp, vec_space_1000[0], vec_space_1000[1],
                                          vecs_to_spherical);
let widget3 = get_vector_widget(vec_space_1000[0], "slerp_vec", redraw_slerp, 1);
</script>

# Slerp_2
<div id="spherical_slerp2"></div>
<div id="slerp_vec2"></div>
<script>
let redraw_slerp2 = get_interpolated_chart(vec_space_1000, "spherical_slerp2", slerp2, vec_space_1000[0], vec_space_1000[1],
                                          vecs_to_spherical);
let widget3_2 = get_vector_widget(vec_space_1000[0], "slerp_vec2", redraw_slerp2, 1);
</script>



# Using it in practice

## Degenerate Case 1: (Almost) passing through the origin

## Degenerate Case 2: (Almost) passing through the origin with elevation changes

## Comparing the 'lerps with real vectors

<div id="through_origin"></div>
<script>
let stylegan_space = randn(10000, 512);
fetch("vecs.json")
    .then(response => response.json())
    .then(jvecs => {
    start_through_origin = jvecs.z;
    stop_through_origin = add(mult(jvecs.z, -1), 1e-4);
    let redraw = get_interpolated_chart(stylegan_space, "through_origin", lerp, start_through_origin, stop_through_origin,
                                        vecs_to_spherical);
    redraw(512, 0);
    });
</script>

<div id="through_origin_with_scale"></div>
<script>
fetch("vecs.json")
    .then(response => response.json())
    .then(jvecs => {
    start_scale = mult(jvecs.z, 0.9999);
    stop_scale = add(mult(jvecs.z, -1.0001), 1e-4);
    let redraw_scale = get_interpolated_chart(stylegan_space, "through_origin_with_scale", slerp2, start_scale, stop_scale,
                                        vecs_to_spherical);
    redraw_scale(512, 0);
    });
</script>
# Interpretations

Geometric:


Great Post! https://www.johndcook.com/blog/2011/09/01/multivariate-normal-shell/

Think about what we saw as we increased the number of dimensions of our space, 
keeping the number of points constant. If you'd like, jump back to [the interactive
plots](#why_bother_with_spherical_coordinates) and hop between 1, 2, and 3 dimensions.

We start with a line, very densely packed. Then we have a square, which
is already less dense. Both dimensions are still, of course, uniformly 
distributed between -1 and 1, but already our distance between any two
points has increased. 

Next, we have a cube, and already, the points are so far apart that the 
10,000 or so points plotted don't look particularly dense. Even though
we can't see it, when we next jump to a hypercube, 
we can expect our space to decrease in density once again.

The extra dimensions 

Statistical:

The law of large numbers says that as our number of dimensions increases, our
vectors will begin to strongly exhibit properties of the underlying distribution.

In particular, the variance of our distribution tells us the expected distance
away from our mean, which in this case is the origin. 


# What's next?
- other measures (density / mean distance to neighbours)
- skewness
- exploring distributions (slerp keeps the vector magnitude right, but skews the variance of 
    the intermediate vectors.)


Sources:

https://github.com/NVlabs/stylegan2-ada-pytorch/tree/main
and
https://arxiv.org/pdf/2006.06676

https://github.com/soumith/dcgan.torch/issues/14

Shoemake
https://dl.acm.org/doi/pdf/10.1145/325334.325242


